{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 7, "column": 0}, "map": {"version":3,"file":"odata.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/odata.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nfunction formatNullAndUndefined(input: unknown): string | unknown {\n  if (input === null || input === undefined) {\n    return \"null\";\n  }\n\n  return input;\n}\n\nfunction escapeQuotesIfString(input: unknown, previous: string): string | unknown {\n  let result = input;\n\n  if (typeof input === \"string\") {\n    result = input.replace(/'/g, \"''\");\n    // check if we need to escape this literal\n    if (!previous.trim().endsWith(\"'\")) {\n      result = `'${result}'`;\n    }\n  }\n\n  return result;\n}\n\n/**\n * Escapes an odata filter expression to avoid errors with quoting string literals.\n * Example usage:\n * ```ts\n * const baseRateMax = 200;\n * const ratingMin = 4;\n * const filter = odata`Rooms/any(room: room/BaseRate lt ${baseRateMax}) and Rating ge ${ratingMin}`;\n * ```\n * For more information on supported syntax see: https://docs.microsoft.com/en-us/azure/search/search-query-odata-filter\n * @param strings - Array of strings for the expression\n * @param values - Array of values for the expression\n */\nexport function odata(strings: TemplateStringsArray, ...values: unknown[]): string {\n  const results = [];\n  for (let i = 0; i < strings.length; i++) {\n    results.push(strings[i]);\n    if (i < values.length) {\n      if (values[i] === null || values[i] === undefined) {\n        results.push(formatNullAndUndefined(values[i]));\n      } else {\n        results.push(escapeQuotesIfString(values[i], strings[i]));\n      }\n    }\n  }\n  return results.join(\"\");\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;AAElC,SAAS,sBAAsB,CAAC,KAAc;IAC5C,IAAI,KAAK,KAAK,IAAI,IAAI,KAAK,KAAK,SAAS,EAAE,CAAC;QAC1C,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,OAAO,KAAK,CAAC;AACf,CAAC;AAED,SAAS,oBAAoB,CAAC,KAAc,EAAE,QAAgB;IAC5D,IAAI,MAAM,GAAG,KAAK,CAAC;IAEnB,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,CAAC;QAC9B,MAAM,GAAG,KAAK,CAAC,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;QACnC,0CAA0C;QAC1C,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC,QAAQ,CAAC,GAAG,CAAC,EAAE,CAAC;YACnC,MAAM,GAAG,CAAA,CAAA,EAAI,MAAM,CAAA,CAAA,CAAG,CAAC;QACzB,CAAC;IACH,CAAC;IAED,OAAO,MAAM,CAAC;AAChB,CAAC;AAcK,SAAU,KAAK,CAAC,OAA6B,EAAE,GAAG,MAAiB;IACvE,MAAM,OAAO,GAAG,EAAE,CAAC;IACnB,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE,CAAC;QACxC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QACzB,IAAI,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC;YACtB,IAAI,MAAM,CAAC,CAAC,CAAC,KAAK,IAAI,IAAI,MAAM,CAAC,CAAC,CAAC,KAAK,SAAS,EAAE,CAAC;gBAClD,OAAO,CAAC,IAAI,CAAC,sBAAsB,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YAClD,CAAC,MAAM,CAAC;gBACN,OAAO,CAAC,IAAI,CAAC,oBAAoB,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YAC5D,CAAC;QACH,CAAC;IACH,CAAC;IACD,OAAO,OAAO,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;AAC1B,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 49, "column": 0}, "map": {"version":3,"file":"base64.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/base64.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/**\n * Encodes a string in base64 format.\n * @param value - The string to encode.\n */\nexport function encode(value: string): string {\n  return Buffer.from(value).toString(\"base64\");\n}\n\n/**\n * Decodes a base64 string into a regular string.\n * @param value - The base64 string to decode.\n */\nexport function decode(value: string): string {\n  return Buffer.from(value, \"base64\").toString();\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;AAElC;;;GAGG;;;;AACG,SAAU,MAAM,CAAC,KAAa;IAClC,OAAO,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAC;AAC/C,CAAC;AAMK,SAAU,MAAM,CAAC,KAAa;IAClC,OAAO,MAAM,CAAC,IAAI,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC,QAAQ,EAAE,CAAC;AACjD,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 70, "column": 0}, "map": {"version":3,"file":"mappers.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/generated/data/models/mappers.ts"],"sourcesContent":["/*\n * Copyright (c) Microsoft Corporation.\n * Licensed under the MIT License.\n *\n * Code generated by Microsoft (R) AutoRest Code Generator.\n * Changes may cause incorrect behavior and will be lost if the code is regenerated.\n */\n\nimport * as coreClient from \"@azure/core-client\";\n\nexport const ErrorResponse: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"ErrorResponse\",\n    modelProperties: {\n      error: {\n        serializedName: \"error\",\n        type: {\n          name: \"Composite\",\n          className: \"ErrorDetail\",\n        },\n      },\n    },\n  },\n};\n\nexport const ErrorDetail: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"ErrorDetail\",\n    modelProperties: {\n      code: {\n        serializedName: \"code\",\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      message: {\n        serializedName: \"message\",\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      target: {\n        serializedName: \"target\",\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      details: {\n        serializedName: \"details\",\n        readOnly: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"ErrorDetail\",\n            },\n          },\n        },\n      },\n      additionalInfo: {\n        serializedName: \"additionalInfo\",\n        readOnly: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"ErrorAdditionalInfo\",\n            },\n          },\n        },\n      },\n    },\n  },\n};\n\nexport const ErrorAdditionalInfo: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"ErrorAdditionalInfo\",\n    modelProperties: {\n      type: {\n        serializedName: \"type\",\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      info: {\n        serializedName: \"info\",\n        readOnly: true,\n        type: {\n          name: \"Dictionary\",\n          value: { type: { name: \"any\" } },\n        },\n      },\n    },\n  },\n};\n\nexport const SearchDocumentsResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"SearchDocumentsResult\",\n    modelProperties: {\n      count: {\n        serializedName: \"@odata\\\\.count\",\n        readOnly: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n      coverage: {\n        serializedName: \"@search\\\\.coverage\",\n        readOnly: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n      facets: {\n        serializedName: \"@search\\\\.facets\",\n        readOnly: true,\n        type: {\n          name: \"Dictionary\",\n          value: {\n            type: {\n              name: \"Sequence\",\n              element: {\n                type: { name: \"Composite\", className: \"FacetResult\" },\n              },\n            },\n          },\n        },\n      },\n      answers: {\n        serializedName: \"@search\\\\.answers\",\n        readOnly: true,\n        nullable: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"QueryAnswerResult\",\n            },\n          },\n        },\n      },\n      nextPageParameters: {\n        serializedName: \"@search\\\\.nextPageParameters\",\n        type: {\n          name: \"Composite\",\n          className: \"SearchRequest\",\n        },\n      },\n      results: {\n        serializedName: \"value\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"SearchResult\",\n            },\n          },\n        },\n      },\n      nextLink: {\n        serializedName: \"@odata\\\\.nextLink\",\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      semanticPartialResponseReason: {\n        serializedName: \"@search\\\\.semanticPartialResponseReason\",\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      semanticPartialResponseType: {\n        serializedName: \"@search\\\\.semanticPartialResponseType\",\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n};\n\nexport const FacetResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"FacetResult\",\n    additionalProperties: { type: { name: \"Object\" } },\n    modelProperties: {\n      count: {\n        serializedName: \"count\",\n        readOnly: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n    },\n  },\n};\n\nexport const QueryAnswerResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"QueryAnswerResult\",\n    additionalProperties: { type: { name: \"Object\" } },\n    modelProperties: {\n      score: {\n        serializedName: \"score\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n      key: {\n        serializedName: \"key\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      text: {\n        serializedName: \"text\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      highlights: {\n        serializedName: \"highlights\",\n        readOnly: true,\n        nullable: true,\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n};\n\nexport const SearchRequest: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"SearchRequest\",\n    modelProperties: {\n      includeTotalResultCount: {\n        serializedName: \"count\",\n        type: {\n          name: \"Boolean\",\n        },\n      },\n      facets: {\n        serializedName: \"facets\",\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"String\",\n            },\n          },\n        },\n      },\n      filter: {\n        serializedName: \"filter\",\n        type: {\n          name: \"String\",\n        },\n      },\n      highlightFields: {\n        serializedName: \"highlight\",\n        type: {\n          name: \"String\",\n        },\n      },\n      highlightPostTag: {\n        serializedName: \"highlightPostTag\",\n        type: {\n          name: \"String\",\n        },\n      },\n      highlightPreTag: {\n        serializedName: \"highlightPreTag\",\n        type: {\n          name: \"String\",\n        },\n      },\n      minimumCoverage: {\n        serializedName: \"minimumCoverage\",\n        type: {\n          name: \"Number\",\n        },\n      },\n      orderBy: {\n        serializedName: \"orderby\",\n        type: {\n          name: \"String\",\n        },\n      },\n      queryType: {\n        serializedName: \"queryType\",\n        type: {\n          name: \"Enum\",\n          allowedValues: [\"simple\", \"full\", \"semantic\"],\n        },\n      },\n      scoringStatistics: {\n        serializedName: \"scoringStatistics\",\n        type: {\n          name: \"Enum\",\n          allowedValues: [\"local\", \"global\"],\n        },\n      },\n      sessionId: {\n        serializedName: \"sessionId\",\n        type: {\n          name: \"String\",\n        },\n      },\n      scoringParameters: {\n        serializedName: \"scoringParameters\",\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"String\",\n            },\n          },\n        },\n      },\n      scoringProfile: {\n        serializedName: \"scoringProfile\",\n        type: {\n          name: \"String\",\n        },\n      },\n      searchText: {\n        serializedName: \"search\",\n        type: {\n          name: \"String\",\n        },\n      },\n      searchFields: {\n        serializedName: \"searchFields\",\n        type: {\n          name: \"String\",\n        },\n      },\n      searchMode: {\n        serializedName: \"searchMode\",\n        type: {\n          name: \"Enum\",\n          allowedValues: [\"any\", \"all\"],\n        },\n      },\n      select: {\n        serializedName: \"select\",\n        type: {\n          name: \"String\",\n        },\n      },\n      skip: {\n        serializedName: \"skip\",\n        type: {\n          name: \"Number\",\n        },\n      },\n      top: {\n        serializedName: \"top\",\n        type: {\n          name: \"Number\",\n        },\n      },\n      semanticConfigurationName: {\n        serializedName: \"semanticConfiguration\",\n        type: {\n          name: \"String\",\n        },\n      },\n      semanticErrorHandling: {\n        serializedName: \"semanticErrorHandling\",\n        type: {\n          name: \"String\",\n        },\n      },\n      semanticMaxWaitInMilliseconds: {\n        constraints: {\n          InclusiveMinimum: 700,\n        },\n        serializedName: \"semanticMaxWaitInMilliseconds\",\n        nullable: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n      semanticQuery: {\n        serializedName: \"semanticQuery\",\n        type: {\n          name: \"String\",\n        },\n      },\n      answers: {\n        serializedName: \"answers\",\n        type: {\n          name: \"String\",\n        },\n      },\n      captions: {\n        serializedName: \"captions\",\n        type: {\n          name: \"String\",\n        },\n      },\n      vectorQueries: {\n        serializedName: \"vectorQueries\",\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"VectorQuery\",\n            },\n          },\n        },\n      },\n      vectorFilterMode: {\n        serializedName: \"vectorFilterMode\",\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n};\n\nexport const VectorQuery: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"VectorQuery\",\n    uberParent: \"VectorQuery\",\n    polymorphicDiscriminator: {\n      serializedName: \"kind\",\n      clientName: \"kind\",\n    },\n    modelProperties: {\n      kind: {\n        serializedName: \"kind\",\n        required: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      kNearestNeighborsCount: {\n        serializedName: \"k\",\n        type: {\n          name: \"Number\",\n        },\n      },\n      fields: {\n        serializedName: \"fields\",\n        type: {\n          name: \"String\",\n        },\n      },\n      exhaustive: {\n        serializedName: \"exhaustive\",\n        type: {\n          name: \"Boolean\",\n        },\n      },\n      oversampling: {\n        serializedName: \"oversampling\",\n        type: {\n          name: \"Number\",\n        },\n      },\n      weight: {\n        serializedName: \"weight\",\n        type: {\n          name: \"Number\",\n        },\n      },\n    },\n  },\n};\n\nexport const SearchResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"SearchResult\",\n    additionalProperties: { type: { name: \"Object\" } },\n    modelProperties: {\n      _score: {\n        serializedName: \"@search\\\\.score\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n      _rerankerScore: {\n        serializedName: \"@search\\\\.rerankerScore\",\n        readOnly: true,\n        nullable: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n      _highlights: {\n        serializedName: \"@search\\\\.highlights\",\n        readOnly: true,\n        type: {\n          name: \"Dictionary\",\n          value: {\n            type: { name: \"Sequence\", element: { type: { name: \"String\" } } },\n          },\n        },\n      },\n      _captions: {\n        serializedName: \"@search\\\\.captions\",\n        readOnly: true,\n        nullable: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"QueryCaptionResult\",\n            },\n          },\n        },\n      },\n    },\n  },\n};\n\nexport const QueryCaptionResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"QueryCaptionResult\",\n    additionalProperties: { type: { name: \"Object\" } },\n    modelProperties: {\n      text: {\n        serializedName: \"text\",\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      highlights: {\n        serializedName: \"highlights\",\n        readOnly: true,\n        nullable: true,\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n};\n\nexport const SuggestDocumentsResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"SuggestDocumentsResult\",\n    modelProperties: {\n      results: {\n        serializedName: \"value\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"SuggestResult\",\n            },\n          },\n        },\n      },\n      coverage: {\n        serializedName: \"@search\\\\.coverage\",\n        readOnly: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n    },\n  },\n};\n\nexport const SuggestResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"SuggestResult\",\n    additionalProperties: { type: { name: \"Object\" } },\n    modelProperties: {\n      _text: {\n        serializedName: \"@search\\\\.text\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n};\n\nexport const SuggestRequest: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"SuggestRequest\",\n    modelProperties: {\n      filter: {\n        serializedName: \"filter\",\n        type: {\n          name: \"String\",\n        },\n      },\n      useFuzzyMatching: {\n        serializedName: \"fuzzy\",\n        type: {\n          name: \"Boolean\",\n        },\n      },\n      highlightPostTag: {\n        serializedName: \"highlightPostTag\",\n        type: {\n          name: \"String\",\n        },\n      },\n      highlightPreTag: {\n        serializedName: \"highlightPreTag\",\n        type: {\n          name: \"String\",\n        },\n      },\n      minimumCoverage: {\n        serializedName: \"minimumCoverage\",\n        type: {\n          name: \"Number\",\n        },\n      },\n      orderBy: {\n        serializedName: \"orderby\",\n        type: {\n          name: \"String\",\n        },\n      },\n      searchText: {\n        serializedName: \"search\",\n        required: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      searchFields: {\n        serializedName: \"searchFields\",\n        type: {\n          name: \"String\",\n        },\n      },\n      select: {\n        serializedName: \"select\",\n        type: {\n          name: \"String\",\n        },\n      },\n      suggesterName: {\n        serializedName: \"suggesterName\",\n        required: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      top: {\n        serializedName: \"top\",\n        type: {\n          name: \"Number\",\n        },\n      },\n    },\n  },\n};\n\nexport const IndexBatch: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"IndexBatch\",\n    modelProperties: {\n      actions: {\n        serializedName: \"value\",\n        required: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"IndexAction\",\n            },\n          },\n        },\n      },\n    },\n  },\n};\n\nexport const IndexAction: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"IndexAction\",\n    additionalProperties: { type: { name: \"Object\" } },\n    modelProperties: {\n      __actionType: {\n        serializedName: \"@search\\\\.action\",\n        required: true,\n        type: {\n          name: \"Enum\",\n          allowedValues: [\"upload\", \"merge\", \"mergeOrUpload\", \"delete\"],\n        },\n      },\n    },\n  },\n};\n\nexport const IndexDocumentsResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"IndexDocumentsResult\",\n    modelProperties: {\n      results: {\n        serializedName: \"value\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"IndexingResult\",\n            },\n          },\n        },\n      },\n    },\n  },\n};\n\nexport const IndexingResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"IndexingResult\",\n    modelProperties: {\n      key: {\n        serializedName: \"key\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      errorMessage: {\n        serializedName: \"errorMessage\",\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      succeeded: {\n        serializedName: \"status\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"Boolean\",\n        },\n      },\n      statusCode: {\n        serializedName: \"statusCode\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n    },\n  },\n};\n\nexport const AutocompleteResult: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"AutocompleteResult\",\n    modelProperties: {\n      coverage: {\n        serializedName: \"@search\\\\.coverage\",\n        readOnly: true,\n        type: {\n          name: \"Number\",\n        },\n      },\n      results: {\n        serializedName: \"value\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Composite\",\n              className: \"AutocompleteItem\",\n            },\n          },\n        },\n      },\n    },\n  },\n};\n\nexport const AutocompleteItem: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"AutocompleteItem\",\n    modelProperties: {\n      text: {\n        serializedName: \"text\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      queryPlusText: {\n        serializedName: \"queryPlusText\",\n        required: true,\n        readOnly: true,\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n};\n\nexport const AutocompleteRequest: coreClient.CompositeMapper = {\n  type: {\n    name: \"Composite\",\n    className: \"AutocompleteRequest\",\n    modelProperties: {\n      searchText: {\n        serializedName: \"search\",\n        required: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      autocompleteMode: {\n        serializedName: \"autocompleteMode\",\n        type: {\n          name: \"Enum\",\n          allowedValues: [\"oneTerm\", \"twoTerms\", \"oneTermWithContext\"],\n        },\n      },\n      filter: {\n        serializedName: \"filter\",\n        type: {\n          name: \"String\",\n        },\n      },\n      useFuzzyMatching: {\n        serializedName: \"fuzzy\",\n        type: {\n          name: \"Boolean\",\n        },\n      },\n      highlightPostTag: {\n        serializedName: \"highlightPostTag\",\n        type: {\n          name: \"String\",\n        },\n      },\n      highlightPreTag: {\n        serializedName: \"highlightPreTag\",\n        type: {\n          name: \"String\",\n        },\n      },\n      minimumCoverage: {\n        serializedName: \"minimumCoverage\",\n        type: {\n          name: \"Number\",\n        },\n      },\n      searchFields: {\n        serializedName: \"searchFields\",\n        type: {\n          name: \"String\",\n        },\n      },\n      suggesterName: {\n        serializedName: \"suggesterName\",\n        required: true,\n        type: {\n          name: \"String\",\n        },\n      },\n      top: {\n        serializedName: \"top\",\n        type: {\n          name: \"Number\",\n        },\n      },\n    },\n  },\n};\n\nexport const VectorizedQuery: coreClient.CompositeMapper = {\n  serializedName: \"vector\",\n  type: {\n    name: \"Composite\",\n    className: \"VectorizedQuery\",\n    uberParent: \"VectorQuery\",\n    polymorphicDiscriminator: VectorQuery.type.polymorphicDiscriminator,\n    modelProperties: {\n      ...VectorQuery.type.modelProperties,\n      vector: {\n        serializedName: \"vector\",\n        required: true,\n        type: {\n          name: \"Sequence\",\n          element: {\n            type: {\n              name: \"Number\",\n            },\n          },\n        },\n      },\n    },\n  },\n};\n\nexport const VectorizableTextQuery: coreClient.CompositeMapper = {\n  serializedName: \"text\",\n  type: {\n    name: \"Composite\",\n    className: \"VectorizableTextQuery\",\n    uberParent: \"VectorQuery\",\n    polymorphicDiscriminator: VectorQuery.type.polymorphicDiscriminator,\n    modelProperties: {\n      ...VectorQuery.type.modelProperties,\n      text: {\n        serializedName: \"text\",\n        required: true,\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n};\n\nexport let discriminators = {\n  VectorQuery: VectorQuery,\n  \"VectorQuery.vector\": VectorizedQuery,\n  \"VectorQuery.text\": VectorizableTextQuery,\n};\n"],"names":[],"mappings":"AAAA;;;;;;GAMG;;;;;;;;;;;;;;;;;;;;;;;;;AAII,MAAM,aAAa,GAA+B;IACvD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,eAAe;QAC1B,eAAe,EAAE;YACf,KAAK,EAAE;gBACL,cAAc,EAAE,OAAO;gBACvB,IAAI,EAAE;oBACJ,IAAI,EAAE,WAAW;oBACjB,SAAS,EAAE,aAAa;iBACzB;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,WAAW,GAA+B;IACrD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,aAAa;QACxB,eAAe,EAAE;YACf,IAAI,EAAE;gBACJ,cAAc,EAAE,MAAM;gBACtB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,OAAO,EAAE;gBACP,cAAc,EAAE,SAAS;gBACzB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,OAAO,EAAE;gBACP,cAAc,EAAE,SAAS;gBACzB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,aAAa;yBACzB;qBACF;iBACF;aACF;YACD,cAAc,EAAE;gBACd,cAAc,EAAE,gBAAgB;gBAChC,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,qBAAqB;yBACjC;qBACF;iBACF;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,mBAAmB,GAA+B;IAC7D,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,qBAAqB;QAChC,eAAe,EAAE;YACf,IAAI,EAAE;gBACJ,cAAc,EAAE,MAAM;gBACtB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,IAAI,EAAE;gBACJ,cAAc,EAAE,MAAM;gBACtB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,YAAY;oBAClB,KAAK,EAAE;wBAAE,IAAI,EAAE;4BAAE,IAAI,EAAE,KAAK;wBAAA,CAAE;oBAAA,CAAE;iBACjC;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,qBAAqB,GAA+B;IAC/D,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,uBAAuB;QAClC,eAAe,EAAE;YACf,KAAK,EAAE;gBACL,cAAc,EAAE,gBAAgB;gBAChC,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,QAAQ,EAAE;gBACR,cAAc,EAAE,oBAAoB;gBACpC,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,MAAM,EAAE;gBACN,cAAc,EAAE,kBAAkB;gBAClC,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,YAAY;oBAClB,KAAK,EAAE;wBACL,IAAI,EAAE;4BACJ,IAAI,EAAE,UAAU;4BAChB,OAAO,EAAE;gCACP,IAAI,EAAE;oCAAE,IAAI,EAAE,WAAW;oCAAE,SAAS,EAAE,aAAa;gCAAA,CAAE;6BACtD;yBACF;qBACF;iBACF;aACF;YACD,OAAO,EAAE;gBACP,cAAc,EAAE,mBAAmB;gBACnC,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,mBAAmB;yBAC/B;qBACF;iBACF;aACF;YACD,kBAAkB,EAAE;gBAClB,cAAc,EAAE,8BAA8B;gBAC9C,IAAI,EAAE;oBACJ,IAAI,EAAE,WAAW;oBACjB,SAAS,EAAE,eAAe;iBAC3B;aACF;YACD,OAAO,EAAE;gBACP,cAAc,EAAE,OAAO;gBACvB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,cAAc;yBAC1B;qBACF;iBACF;aACF;YACD,QAAQ,EAAE;gBACR,cAAc,EAAE,mBAAmB;gBACnC,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,6BAA6B,EAAE;gBAC7B,cAAc,EAAE,yCAAyC;gBACzD,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,2BAA2B,EAAE;gBAC3B,cAAc,EAAE,uCAAuC;gBACvD,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,WAAW,GAA+B;IACrD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,aAAa;QACxB,oBAAoB,EAAE;YAAE,IAAI,EAAE;gBAAE,IAAI,EAAE,QAAQ;YAAA,CAAE;QAAA,CAAE;QAClD,eAAe,EAAE;YACf,KAAK,EAAE;gBACL,cAAc,EAAE,OAAO;gBACvB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,iBAAiB,GAA+B;IAC3D,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,mBAAmB;QAC9B,oBAAoB,EAAE;YAAE,IAAI,EAAE;gBAAE,IAAI,EAAE,QAAQ;YAAA,CAAE;QAAA,CAAE;QAClD,eAAe,EAAE;YACf,KAAK,EAAE;gBACL,cAAc,EAAE,OAAO;gBACvB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,GAAG,EAAE;gBACH,cAAc,EAAE,KAAK;gBACrB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,IAAI,EAAE;gBACJ,cAAc,EAAE,MAAM;gBACtB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,UAAU,EAAE;gBACV,cAAc,EAAE,YAAY;gBAC5B,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,aAAa,GAA+B;IACvD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,eAAe;QAC1B,eAAe,EAAE;YACf,uBAAuB,EAAE;gBACvB,cAAc,EAAE,OAAO;gBACvB,IAAI,EAAE;oBACJ,IAAI,EAAE,SAAS;iBAChB;aACF;YACD,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,QAAQ;yBACf;qBACF;iBACF;aACF;YACD,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,eAAe,EAAE;gBACf,cAAc,EAAE,WAAW;gBAC3B,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,gBAAgB,EAAE;gBAChB,cAAc,EAAE,kBAAkB;gBAClC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,eAAe,EAAE;gBACf,cAAc,EAAE,iBAAiB;gBACjC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,eAAe,EAAE;gBACf,cAAc,EAAE,iBAAiB;gBACjC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,OAAO,EAAE;gBACP,cAAc,EAAE,SAAS;gBACzB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,SAAS,EAAE;gBACT,cAAc,EAAE,WAAW;gBAC3B,IAAI,EAAE;oBACJ,IAAI,EAAE,MAAM;oBACZ,aAAa,EAAE;wBAAC,QAAQ;wBAAE,MAAM;wBAAE,UAAU;qBAAC;iBAC9C;aACF;YACD,iBAAiB,EAAE;gBACjB,cAAc,EAAE,mBAAmB;gBACnC,IAAI,EAAE;oBACJ,IAAI,EAAE,MAAM;oBACZ,aAAa,EAAE;wBAAC,OAAO;wBAAE,QAAQ;qBAAC;iBACnC;aACF;YACD,SAAS,EAAE;gBACT,cAAc,EAAE,WAAW;gBAC3B,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,iBAAiB,EAAE;gBACjB,cAAc,EAAE,mBAAmB;gBACnC,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,QAAQ;yBACf;qBACF;iBACF;aACF;YACD,cAAc,EAAE;gBACd,cAAc,EAAE,gBAAgB;gBAChC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,UAAU,EAAE;gBACV,cAAc,EAAE,QAAQ;gBACxB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,YAAY,EAAE;gBACZ,cAAc,EAAE,cAAc;gBAC9B,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,UAAU,EAAE;gBACV,cAAc,EAAE,YAAY;gBAC5B,IAAI,EAAE;oBACJ,IAAI,EAAE,MAAM;oBACZ,aAAa,EAAE;wBAAC,KAAK;wBAAE,KAAK;qBAAC;iBAC9B;aACF;YACD,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,IAAI,EAAE;gBACJ,cAAc,EAAE,MAAM;gBACtB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,GAAG,EAAE;gBACH,cAAc,EAAE,KAAK;gBACrB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,yBAAyB,EAAE;gBACzB,cAAc,EAAE,uBAAuB;gBACvC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,qBAAqB,EAAE;gBACrB,cAAc,EAAE,uBAAuB;gBACvC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,6BAA6B,EAAE;gBAC7B,WAAW,EAAE;oBACX,gBAAgB,EAAE,GAAG;iBACtB;gBACD,cAAc,EAAE,+BAA+B;gBAC/C,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,aAAa,EAAE;gBACb,cAAc,EAAE,eAAe;gBAC/B,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,OAAO,EAAE;gBACP,cAAc,EAAE,SAAS;gBACzB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,QAAQ,EAAE;gBACR,cAAc,EAAE,UAAU;gBAC1B,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,aAAa,EAAE;gBACb,cAAc,EAAE,eAAe;gBAC/B,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,aAAa;yBACzB;qBACF;iBACF;aACF;YACD,gBAAgB,EAAE;gBAChB,cAAc,EAAE,kBAAkB;gBAClC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,WAAW,GAA+B;IACrD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,aAAa;QACxB,UAAU,EAAE,aAAa;QACzB,wBAAwB,EAAE;YACxB,cAAc,EAAE,MAAM;YACtB,UAAU,EAAE,MAAM;SACnB;QACD,eAAe,EAAE;YACf,IAAI,EAAE;gBACJ,cAAc,EAAE,MAAM;gBACtB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,sBAAsB,EAAE;gBACtB,cAAc,EAAE,GAAG;gBACnB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,UAAU,EAAE;gBACV,cAAc,EAAE,YAAY;gBAC5B,IAAI,EAAE;oBACJ,IAAI,EAAE,SAAS;iBAChB;aACF;YACD,YAAY,EAAE;gBACZ,cAAc,EAAE,cAAc;gBAC9B,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,YAAY,GAA+B;IACtD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,cAAc;QACzB,oBAAoB,EAAE;YAAE,IAAI,EAAE;gBAAE,IAAI,EAAE,QAAQ;YAAA,CAAE;QAAA,CAAE;QAClD,eAAe,EAAE;YACf,MAAM,EAAE;gBACN,cAAc,EAAE,iBAAiB;gBACjC,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,cAAc,EAAE;gBACd,cAAc,EAAE,yBAAyB;gBACzC,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,WAAW,EAAE;gBACX,cAAc,EAAE,sBAAsB;gBACtC,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,YAAY;oBAClB,KAAK,EAAE;wBACL,IAAI,EAAE;4BAAE,IAAI,EAAE,UAAU;4BAAE,OAAO,EAAE;gCAAE,IAAI,EAAE;oCAAE,IAAI,EAAE,QAAQ;gCAAA,CAAE;4BAAA,CAAE;wBAAA,CAAE;qBAClE;iBACF;aACF;YACD,SAAS,EAAE;gBACT,cAAc,EAAE,oBAAoB;gBACpC,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,oBAAoB;yBAChC;qBACF;iBACF;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,kBAAkB,GAA+B;IAC5D,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,oBAAoB;QAC/B,oBAAoB,EAAE;YAAE,IAAI,EAAE;gBAAE,IAAI,EAAE,QAAQ;YAAA,CAAE;QAAA,CAAE;QAClD,eAAe,EAAE;YACf,IAAI,EAAE;gBACJ,cAAc,EAAE,MAAM;gBACtB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,UAAU,EAAE;gBACV,cAAc,EAAE,YAAY;gBAC5B,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,sBAAsB,GAA+B;IAChE,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,wBAAwB;QACnC,eAAe,EAAE;YACf,OAAO,EAAE;gBACP,cAAc,EAAE,OAAO;gBACvB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,eAAe;yBAC3B;qBACF;iBACF;aACF;YACD,QAAQ,EAAE;gBACR,cAAc,EAAE,oBAAoB;gBACpC,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,aAAa,GAA+B;IACvD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,eAAe;QAC1B,oBAAoB,EAAE;YAAE,IAAI,EAAE;gBAAE,IAAI,EAAE,QAAQ;YAAA,CAAE;QAAA,CAAE;QAClD,eAAe,EAAE;YACf,KAAK,EAAE;gBACL,cAAc,EAAE,gBAAgB;gBAChC,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,cAAc,GAA+B;IACxD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,gBAAgB;QAC3B,eAAe,EAAE;YACf,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,gBAAgB,EAAE;gBAChB,cAAc,EAAE,OAAO;gBACvB,IAAI,EAAE;oBACJ,IAAI,EAAE,SAAS;iBAChB;aACF;YACD,gBAAgB,EAAE;gBAChB,cAAc,EAAE,kBAAkB;gBAClC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,eAAe,EAAE;gBACf,cAAc,EAAE,iBAAiB;gBACjC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,eAAe,EAAE;gBACf,cAAc,EAAE,iBAAiB;gBACjC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,OAAO,EAAE;gBACP,cAAc,EAAE,SAAS;gBACzB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,UAAU,EAAE;gBACV,cAAc,EAAE,QAAQ;gBACxB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,YAAY,EAAE;gBACZ,cAAc,EAAE,cAAc;gBAC9B,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,aAAa,EAAE;gBACb,cAAc,EAAE,eAAe;gBAC/B,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,GAAG,EAAE;gBACH,cAAc,EAAE,KAAK;gBACrB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,UAAU,GAA+B;IACpD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,YAAY;QACvB,eAAe,EAAE;YACf,OAAO,EAAE;gBACP,cAAc,EAAE,OAAO;gBACvB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,aAAa;yBACzB;qBACF;iBACF;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,WAAW,GAA+B;IACrD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,aAAa;QACxB,oBAAoB,EAAE;YAAE,IAAI,EAAE;gBAAE,IAAI,EAAE,QAAQ;YAAA,CAAE;QAAA,CAAE;QAClD,eAAe,EAAE;YACf,YAAY,EAAE;gBACZ,cAAc,EAAE,kBAAkB;gBAClC,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,MAAM;oBACZ,aAAa,EAAE;wBAAC,QAAQ;wBAAE,OAAO;wBAAE,eAAe;wBAAE,QAAQ;qBAAC;iBAC9D;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,oBAAoB,GAA+B;IAC9D,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,sBAAsB;QACjC,eAAe,EAAE;YACf,OAAO,EAAE;gBACP,cAAc,EAAE,OAAO;gBACvB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,gBAAgB;yBAC5B;qBACF;iBACF;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,cAAc,GAA+B;IACxD,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,gBAAgB;QAC3B,eAAe,EAAE;YACf,GAAG,EAAE;gBACH,cAAc,EAAE,KAAK;gBACrB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,YAAY,EAAE;gBACZ,cAAc,EAAE,cAAc;gBAC9B,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,SAAS,EAAE;gBACT,cAAc,EAAE,QAAQ;gBACxB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,SAAS;iBAChB;aACF;YACD,UAAU,EAAE;gBACV,cAAc,EAAE,YAAY;gBAC5B,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,kBAAkB,GAA+B;IAC5D,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,oBAAoB;QAC/B,eAAe,EAAE;YACf,QAAQ,EAAE;gBACR,cAAc,EAAE,oBAAoB;gBACpC,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,OAAO,EAAE;gBACP,cAAc,EAAE,OAAO;gBACvB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,WAAW;4BACjB,SAAS,EAAE,kBAAkB;yBAC9B;qBACF;iBACF;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,gBAAgB,GAA+B;IAC1D,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,kBAAkB;QAC7B,eAAe,EAAE;YACf,IAAI,EAAE;gBACJ,cAAc,EAAE,MAAM;gBACtB,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,aAAa,EAAE;gBACb,cAAc,EAAE,eAAe;gBAC/B,QAAQ,EAAE,IAAI;gBACd,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,mBAAmB,GAA+B;IAC7D,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,qBAAqB;QAChC,eAAe,EAAE;YACf,UAAU,EAAE;gBACV,cAAc,EAAE,QAAQ;gBACxB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,gBAAgB,EAAE;gBAChB,cAAc,EAAE,kBAAkB;gBAClC,IAAI,EAAE;oBACJ,IAAI,EAAE,MAAM;oBACZ,aAAa,EAAE;wBAAC,SAAS;wBAAE,UAAU;wBAAE,oBAAoB;qBAAC;iBAC7D;aACF;YACD,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,gBAAgB,EAAE;gBAChB,cAAc,EAAE,OAAO;gBACvB,IAAI,EAAE;oBACJ,IAAI,EAAE,SAAS;iBAChB;aACF;YACD,gBAAgB,EAAE;gBAChB,cAAc,EAAE,kBAAkB;gBAClC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,eAAe,EAAE;gBACf,cAAc,EAAE,iBAAiB;gBACjC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,eAAe,EAAE;gBACf,cAAc,EAAE,iBAAiB;gBACjC,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,YAAY,EAAE;gBACZ,cAAc,EAAE,cAAc;gBAC9B,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,aAAa,EAAE;gBACb,cAAc,EAAE,eAAe;gBAC/B,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;YACD,GAAG,EAAE;gBACH,cAAc,EAAE,KAAK;gBACrB,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;CACF,CAAC;AAEK,MAAM,eAAe,GAA+B;IACzD,cAAc,EAAE,QAAQ;IACxB,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,iBAAiB;QAC5B,UAAU,EAAE,aAAa;QACzB,wBAAwB,EAAE,WAAW,CAAC,IAAI,CAAC,wBAAwB;QACnE,eAAe,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACV,WAAW,CAAC,IAAI,CAAC,eAAe,GAAA;YACnC,MAAM,EAAE;gBACN,cAAc,EAAE,QAAQ;gBACxB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,UAAU;oBAChB,OAAO,EAAE;wBACP,IAAI,EAAE;4BACJ,IAAI,EAAE,QAAQ;yBACf;qBACF;iBACF;aACF;QAAA,EACF;KACF;CACF,CAAC;AAEK,MAAM,qBAAqB,GAA+B;IAC/D,cAAc,EAAE,MAAM;IACtB,IAAI,EAAE;QACJ,IAAI,EAAE,WAAW;QACjB,SAAS,EAAE,uBAAuB;QAClC,UAAU,EAAE,aAAa;QACzB,wBAAwB,EAAE,WAAW,CAAC,IAAI,CAAC,wBAAwB;QACnE,eAAe,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACV,WAAW,CAAC,IAAI,CAAC,eAAe,GAAA;YACnC,IAAI,EAAE;gBACJ,cAAc,EAAE,MAAM;gBACtB,QAAQ,EAAE,IAAI;gBACd,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;QAAA,EACF;KACF;CACF,CAAC;AAEK,IAAI,cAAc,GAAG;IAC1B,WAAW,EAAE,WAAW;IACxB,oBAAoB,EAAE,eAAe;IACrC,kBAAkB,EAAE,qBAAqB;CAC1C,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1114, "column": 0}, "map": {"version":3,"file":"parameters.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/generated/data/models/parameters.ts"],"sourcesContent":["/*\n * Copyright (c) Microsoft Corporation.\n * Licensed under the MIT License.\n *\n * Code generated by Microsoft (R) AutoRest Code Generator.\n * Changes may cause incorrect behavior and will be lost if the code is regenerated.\n */\n\nimport {\n  OperationParameter,\n  OperationURLParameter,\n  OperationQueryParameter,\n} from \"@azure/core-client\";\nimport {\n  SearchRequest as SearchRequestMapper,\n  SuggestRequest as SuggestRequestMapper,\n  IndexBatch as IndexBatchMapper,\n  AutocompleteRequest as AutocompleteRequestMapper,\n} from \"../models/mappers\";\n\nexport const accept: OperationParameter = {\n  parameterPath: \"accept\",\n  mapper: {\n    defaultValue: \"application/json\",\n    isConstant: true,\n    serializedName: \"Accept\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const endpoint: OperationURLParameter = {\n  parameterPath: \"endpoint\",\n  mapper: {\n    serializedName: \"endpoint\",\n    required: true,\n    type: {\n      name: \"String\",\n    },\n  },\n  skipEncoding: true,\n};\n\nexport const indexName: OperationURLParameter = {\n  parameterPath: \"indexName\",\n  mapper: {\n    serializedName: \"indexName\",\n    required: true,\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const apiVersion: OperationQueryParameter = {\n  parameterPath: \"apiVersion\",\n  mapper: {\n    serializedName: \"api-version\",\n    required: true,\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const searchText: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchText\"],\n  mapper: {\n    serializedName: \"search\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const includeTotalResultCount: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"includeTotalResultCount\"],\n  mapper: {\n    serializedName: \"$count\",\n    type: {\n      name: \"Boolean\",\n    },\n  },\n};\n\nexport const facets: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"facets\"],\n  mapper: {\n    serializedName: \"facet\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"Multi\",\n};\n\nexport const filter: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"filter\"],\n  mapper: {\n    serializedName: \"$filter\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const highlightFields: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"highlightFields\"],\n  mapper: {\n    serializedName: \"highlight\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"CSV\",\n};\n\nexport const highlightPostTag: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"highlightPostTag\"],\n  mapper: {\n    serializedName: \"highlightPostTag\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const highlightPreTag: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"highlightPreTag\"],\n  mapper: {\n    serializedName: \"highlightPreTag\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const minimumCoverage: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"minimumCoverage\"],\n  mapper: {\n    serializedName: \"minimumCoverage\",\n    type: {\n      name: \"Number\",\n    },\n  },\n};\n\nexport const orderBy: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"orderBy\"],\n  mapper: {\n    serializedName: \"$orderby\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"CSV\",\n};\n\nexport const queryType: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"queryType\"],\n  mapper: {\n    serializedName: \"queryType\",\n    type: {\n      name: \"Enum\",\n      allowedValues: [\"simple\", \"full\", \"semantic\"],\n    },\n  },\n};\n\nexport const scoringParameters: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"scoringParameters\"],\n  mapper: {\n    serializedName: \"scoringParameter\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"Multi\",\n};\n\nexport const scoringProfile: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"scoringProfile\"],\n  mapper: {\n    serializedName: \"scoringProfile\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const searchFields: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"searchFields\"],\n  mapper: {\n    serializedName: \"searchFields\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"CSV\",\n};\n\nexport const searchMode: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"searchMode\"],\n  mapper: {\n    serializedName: \"searchMode\",\n    type: {\n      name: \"Enum\",\n      allowedValues: [\"any\", \"all\"],\n    },\n  },\n};\n\nexport const scoringStatistics: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"scoringStatistics\"],\n  mapper: {\n    serializedName: \"scoringStatistics\",\n    type: {\n      name: \"Enum\",\n      allowedValues: [\"local\", \"global\"],\n    },\n  },\n};\n\nexport const sessionId: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"sessionId\"],\n  mapper: {\n    serializedName: \"sessionId\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const select: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"select\"],\n  mapper: {\n    serializedName: \"$select\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"CSV\",\n};\n\nexport const skip: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"skip\"],\n  mapper: {\n    serializedName: \"$skip\",\n    type: {\n      name: \"Number\",\n    },\n  },\n};\n\nexport const top: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"top\"],\n  mapper: {\n    serializedName: \"$top\",\n    type: {\n      name: \"Number\",\n    },\n  },\n};\n\nexport const semanticConfiguration: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"semanticConfiguration\"],\n  mapper: {\n    serializedName: \"semanticConfiguration\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const semanticErrorHandling: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"semanticErrorHandling\"],\n  mapper: {\n    serializedName: \"semanticErrorHandling\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const semanticMaxWaitInMilliseconds: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"semanticMaxWaitInMilliseconds\"],\n  mapper: {\n    constraints: {\n      InclusiveMinimum: 700,\n    },\n    serializedName: \"semanticMaxWaitInMilliseconds\",\n    type: {\n      name: \"Number\",\n    },\n  },\n};\n\nexport const answers: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"answers\"],\n  mapper: {\n    serializedName: \"answers\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const captions: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"captions\"],\n  mapper: {\n    serializedName: \"captions\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const semanticQuery: OperationQueryParameter = {\n  parameterPath: [\"options\", \"searchOptions\", \"semanticQuery\"],\n  mapper: {\n    serializedName: \"semanticQuery\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const contentType: OperationParameter = {\n  parameterPath: [\"options\", \"contentType\"],\n  mapper: {\n    defaultValue: \"application/json\",\n    isConstant: true,\n    serializedName: \"Content-Type\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const searchRequest: OperationParameter = {\n  parameterPath: \"searchRequest\",\n  mapper: SearchRequestMapper,\n};\n\nexport const key: OperationURLParameter = {\n  parameterPath: \"key\",\n  mapper: {\n    serializedName: \"key\",\n    required: true,\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const selectedFields: OperationQueryParameter = {\n  parameterPath: [\"options\", \"selectedFields\"],\n  mapper: {\n    serializedName: \"$select\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"CSV\",\n};\n\nexport const searchText1: OperationQueryParameter = {\n  parameterPath: \"searchText\",\n  mapper: {\n    serializedName: \"search\",\n    required: true,\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const suggesterName: OperationQueryParameter = {\n  parameterPath: \"suggesterName\",\n  mapper: {\n    serializedName: \"suggesterName\",\n    required: true,\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const filter1: OperationQueryParameter = {\n  parameterPath: [\"options\", \"suggestOptions\", \"filter\"],\n  mapper: {\n    serializedName: \"$filter\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const useFuzzyMatching: OperationQueryParameter = {\n  parameterPath: [\"options\", \"suggestOptions\", \"useFuzzyMatching\"],\n  mapper: {\n    serializedName: \"fuzzy\",\n    type: {\n      name: \"Boolean\",\n    },\n  },\n};\n\nexport const highlightPostTag1: OperationQueryParameter = {\n  parameterPath: [\"options\", \"suggestOptions\", \"highlightPostTag\"],\n  mapper: {\n    serializedName: \"highlightPostTag\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const highlightPreTag1: OperationQueryParameter = {\n  parameterPath: [\"options\", \"suggestOptions\", \"highlightPreTag\"],\n  mapper: {\n    serializedName: \"highlightPreTag\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const minimumCoverage1: OperationQueryParameter = {\n  parameterPath: [\"options\", \"suggestOptions\", \"minimumCoverage\"],\n  mapper: {\n    serializedName: \"minimumCoverage\",\n    type: {\n      name: \"Number\",\n    },\n  },\n};\n\nexport const orderBy1: OperationQueryParameter = {\n  parameterPath: [\"options\", \"suggestOptions\", \"orderBy\"],\n  mapper: {\n    serializedName: \"$orderby\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"CSV\",\n};\n\nexport const searchFields1: OperationQueryParameter = {\n  parameterPath: [\"options\", \"suggestOptions\", \"searchFields\"],\n  mapper: {\n    serializedName: \"searchFields\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"CSV\",\n};\n\nexport const select1: OperationQueryParameter = {\n  parameterPath: [\"options\", \"suggestOptions\", \"select\"],\n  mapper: {\n    serializedName: \"$select\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"CSV\",\n};\n\nexport const top1: OperationQueryParameter = {\n  parameterPath: [\"options\", \"suggestOptions\", \"top\"],\n  mapper: {\n    serializedName: \"$top\",\n    type: {\n      name: \"Number\",\n    },\n  },\n};\n\nexport const suggestRequest: OperationParameter = {\n  parameterPath: \"suggestRequest\",\n  mapper: SuggestRequestMapper,\n};\n\nexport const batch: OperationParameter = {\n  parameterPath: \"batch\",\n  mapper: IndexBatchMapper,\n};\n\nexport const autocompleteMode: OperationQueryParameter = {\n  parameterPath: [\"options\", \"autocompleteOptions\", \"autocompleteMode\"],\n  mapper: {\n    serializedName: \"autocompleteMode\",\n    type: {\n      name: \"Enum\",\n      allowedValues: [\"oneTerm\", \"twoTerms\", \"oneTermWithContext\"],\n    },\n  },\n};\n\nexport const filter2: OperationQueryParameter = {\n  parameterPath: [\"options\", \"autocompleteOptions\", \"filter\"],\n  mapper: {\n    serializedName: \"$filter\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const useFuzzyMatching1: OperationQueryParameter = {\n  parameterPath: [\"options\", \"autocompleteOptions\", \"useFuzzyMatching\"],\n  mapper: {\n    serializedName: \"fuzzy\",\n    type: {\n      name: \"Boolean\",\n    },\n  },\n};\n\nexport const highlightPostTag2: OperationQueryParameter = {\n  parameterPath: [\"options\", \"autocompleteOptions\", \"highlightPostTag\"],\n  mapper: {\n    serializedName: \"highlightPostTag\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const highlightPreTag2: OperationQueryParameter = {\n  parameterPath: [\"options\", \"autocompleteOptions\", \"highlightPreTag\"],\n  mapper: {\n    serializedName: \"highlightPreTag\",\n    type: {\n      name: \"String\",\n    },\n  },\n};\n\nexport const minimumCoverage2: OperationQueryParameter = {\n  parameterPath: [\"options\", \"autocompleteOptions\", \"minimumCoverage\"],\n  mapper: {\n    serializedName: \"minimumCoverage\",\n    type: {\n      name: \"Number\",\n    },\n  },\n};\n\nexport const searchFields2: OperationQueryParameter = {\n  parameterPath: [\"options\", \"autocompleteOptions\", \"searchFields\"],\n  mapper: {\n    serializedName: \"searchFields\",\n    type: {\n      name: \"Sequence\",\n      element: {\n        type: {\n          name: \"String\",\n        },\n      },\n    },\n  },\n  collectionFormat: \"CSV\",\n};\n\nexport const top2: OperationQueryParameter = {\n  parameterPath: [\"options\", \"autocompleteOptions\", \"top\"],\n  mapper: {\n    serializedName: \"$top\",\n    type: {\n      name: \"Number\",\n    },\n  },\n};\n\nexport const autocompleteRequest: OperationParameter = {\n  parameterPath: \"autocompleteRequest\",\n  mapper: AutocompleteRequestMapper,\n};\n"],"names":[],"mappings":"AAAA;;;;;;GAMG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAOH,OAAO,EACL,aAAa,IAAI,mBAAmB,EACpC,cAAc,IAAI,oBAAoB,EACtC,UAAU,IAAI,gBAAgB,EAC9B,mBAAmB,IAAI,yBAAyB,GACjD,MAAM,mBAAmB,CAAC;;AAEpB,MAAM,MAAM,GAAuB;IACxC,aAAa,EAAE,QAAQ;IACvB,MAAM,EAAE;QACN,YAAY,EAAE,kBAAkB;QAChC,UAAU,EAAE,IAAI;QAChB,cAAc,EAAE,QAAQ;QACxB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,QAAQ,GAA0B;IAC7C,aAAa,EAAE,UAAU;IACzB,MAAM,EAAE;QACN,cAAc,EAAE,UAAU;QAC1B,QAAQ,EAAE,IAAI;QACd,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;IACD,YAAY,EAAE,IAAI;CACnB,CAAC;AAEK,MAAM,SAAS,GAA0B;IAC9C,aAAa,EAAE,WAAW;IAC1B,MAAM,EAAE;QACN,cAAc,EAAE,WAAW;QAC3B,QAAQ,EAAE,IAAI;QACd,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,UAAU,GAA4B;IACjD,aAAa,EAAE,YAAY;IAC3B,MAAM,EAAE;QACN,cAAc,EAAE,aAAa;QAC7B,QAAQ,EAAE,IAAI;QACd,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,UAAU,GAA4B;IACjD,aAAa,EAAE;QAAC,SAAS;QAAE,YAAY;KAAC;IACxC,MAAM,EAAE;QACN,cAAc,EAAE,QAAQ;QACxB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,uBAAuB,GAA4B;IAC9D,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,yBAAyB;KAAC;IACtE,MAAM,EAAE;QACN,cAAc,EAAE,QAAQ;QACxB,IAAI,EAAE;YACJ,IAAI,EAAE,SAAS;SAChB;KACF;CACF,CAAC;AAEK,MAAM,MAAM,GAA4B;IAC7C,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,QAAQ;KAAC;IACrD,MAAM,EAAE;QACN,cAAc,EAAE,OAAO;QACvB,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,OAAO;CAC1B,CAAC;AAEK,MAAM,MAAM,GAA4B;IAC7C,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,QAAQ;KAAC;IACrD,MAAM,EAAE;QACN,cAAc,EAAE,SAAS;QACzB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,eAAe,GAA4B;IACtD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,iBAAiB;KAAC;IAC9D,MAAM,EAAE;QACN,cAAc,EAAE,WAAW;QAC3B,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,KAAK;CACxB,CAAC;AAEK,MAAM,gBAAgB,GAA4B;IACvD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,kBAAkB;KAAC;IAC/D,MAAM,EAAE;QACN,cAAc,EAAE,kBAAkB;QAClC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,eAAe,GAA4B;IACtD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,iBAAiB;KAAC;IAC9D,MAAM,EAAE;QACN,cAAc,EAAE,iBAAiB;QACjC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,eAAe,GAA4B;IACtD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,iBAAiB;KAAC;IAC9D,MAAM,EAAE;QACN,cAAc,EAAE,iBAAiB;QACjC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,OAAO,GAA4B;IAC9C,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,SAAS;KAAC;IACtD,MAAM,EAAE;QACN,cAAc,EAAE,UAAU;QAC1B,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,KAAK;CACxB,CAAC;AAEK,MAAM,SAAS,GAA4B;IAChD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,WAAW;KAAC;IACxD,MAAM,EAAE;QACN,cAAc,EAAE,WAAW;QAC3B,IAAI,EAAE;YACJ,IAAI,EAAE,MAAM;YACZ,aAAa,EAAE;gBAAC,QAAQ;gBAAE,MAAM;gBAAE,UAAU;aAAC;SAC9C;KACF;CACF,CAAC;AAEK,MAAM,iBAAiB,GAA4B;IACxD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,mBAAmB;KAAC;IAChE,MAAM,EAAE;QACN,cAAc,EAAE,kBAAkB;QAClC,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,OAAO;CAC1B,CAAC;AAEK,MAAM,cAAc,GAA4B;IACrD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,gBAAgB;KAAC;IAC7D,MAAM,EAAE;QACN,cAAc,EAAE,gBAAgB;QAChC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,YAAY,GAA4B;IACnD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,cAAc;KAAC;IAC3D,MAAM,EAAE;QACN,cAAc,EAAE,cAAc;QAC9B,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,KAAK;CACxB,CAAC;AAEK,MAAM,UAAU,GAA4B;IACjD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,YAAY;KAAC;IACzD,MAAM,EAAE;QACN,cAAc,EAAE,YAAY;QAC5B,IAAI,EAAE;YACJ,IAAI,EAAE,MAAM;YACZ,aAAa,EAAE;gBAAC,KAAK;gBAAE,KAAK;aAAC;SAC9B;KACF;CACF,CAAC;AAEK,MAAM,iBAAiB,GAA4B;IACxD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,mBAAmB;KAAC;IAChE,MAAM,EAAE;QACN,cAAc,EAAE,mBAAmB;QACnC,IAAI,EAAE;YACJ,IAAI,EAAE,MAAM;YACZ,aAAa,EAAE;gBAAC,OAAO;gBAAE,QAAQ;aAAC;SACnC;KACF;CACF,CAAC;AAEK,MAAM,SAAS,GAA4B;IAChD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,WAAW;KAAC;IACxD,MAAM,EAAE;QACN,cAAc,EAAE,WAAW;QAC3B,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,MAAM,GAA4B;IAC7C,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,QAAQ;KAAC;IACrD,MAAM,EAAE;QACN,cAAc,EAAE,SAAS;QACzB,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,KAAK;CACxB,CAAC;AAEK,MAAM,IAAI,GAA4B;IAC3C,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,MAAM;KAAC;IACnD,MAAM,EAAE;QACN,cAAc,EAAE,OAAO;QACvB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,GAAG,GAA4B;IAC1C,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,KAAK;KAAC;IAClD,MAAM,EAAE;QACN,cAAc,EAAE,MAAM;QACtB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,qBAAqB,GAA4B;IAC5D,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,uBAAuB;KAAC;IACpE,MAAM,EAAE;QACN,cAAc,EAAE,uBAAuB;QACvC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,qBAAqB,GAA4B;IAC5D,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,uBAAuB;KAAC;IACpE,MAAM,EAAE;QACN,cAAc,EAAE,uBAAuB;QACvC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,6BAA6B,GAA4B;IACpE,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,+BAA+B;KAAC;IAC5E,MAAM,EAAE;QACN,WAAW,EAAE;YACX,gBAAgB,EAAE,GAAG;SACtB;QACD,cAAc,EAAE,+BAA+B;QAC/C,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,OAAO,GAA4B;IAC9C,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,SAAS;KAAC;IACtD,MAAM,EAAE;QACN,cAAc,EAAE,SAAS;QACzB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,QAAQ,GAA4B;IAC/C,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,UAAU;KAAC;IACvD,MAAM,EAAE;QACN,cAAc,EAAE,UAAU;QAC1B,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,aAAa,GAA4B;IACpD,aAAa,EAAE;QAAC,SAAS;QAAE,eAAe;QAAE,eAAe;KAAC;IAC5D,MAAM,EAAE;QACN,cAAc,EAAE,eAAe;QAC/B,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,WAAW,GAAuB;IAC7C,aAAa,EAAE;QAAC,SAAS;QAAE,aAAa;KAAC;IACzC,MAAM,EAAE;QACN,YAAY,EAAE,kBAAkB;QAChC,UAAU,EAAE,IAAI;QAChB,cAAc,EAAE,cAAc;QAC9B,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,aAAa,GAAuB;IAC/C,aAAa,EAAE,eAAe;IAC9B,MAAM,mNAAE,gBAAmB;CAC5B,CAAC;AAEK,MAAM,GAAG,GAA0B;IACxC,aAAa,EAAE,KAAK;IACpB,MAAM,EAAE;QACN,cAAc,EAAE,KAAK;QACrB,QAAQ,EAAE,IAAI;QACd,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,cAAc,GAA4B;IACrD,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;KAAC;IAC5C,MAAM,EAAE;QACN,cAAc,EAAE,SAAS;QACzB,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,KAAK;CACxB,CAAC;AAEK,MAAM,WAAW,GAA4B;IAClD,aAAa,EAAE,YAAY;IAC3B,MAAM,EAAE;QACN,cAAc,EAAE,QAAQ;QACxB,QAAQ,EAAE,IAAI;QACd,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,aAAa,GAA4B;IACpD,aAAa,EAAE,eAAe;IAC9B,MAAM,EAAE;QACN,cAAc,EAAE,eAAe;QAC/B,QAAQ,EAAE,IAAI;QACd,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,OAAO,GAA4B;IAC9C,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;QAAE,QAAQ;KAAC;IACtD,MAAM,EAAE;QACN,cAAc,EAAE,SAAS;QACzB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,gBAAgB,GAA4B;IACvD,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;QAAE,kBAAkB;KAAC;IAChE,MAAM,EAAE;QACN,cAAc,EAAE,OAAO;QACvB,IAAI,EAAE;YACJ,IAAI,EAAE,SAAS;SAChB;KACF;CACF,CAAC;AAEK,MAAM,iBAAiB,GAA4B;IACxD,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;QAAE,kBAAkB;KAAC;IAChE,MAAM,EAAE;QACN,cAAc,EAAE,kBAAkB;QAClC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,gBAAgB,GAA4B;IACvD,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;QAAE,iBAAiB;KAAC;IAC/D,MAAM,EAAE;QACN,cAAc,EAAE,iBAAiB;QACjC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,gBAAgB,GAA4B;IACvD,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;QAAE,iBAAiB;KAAC;IAC/D,MAAM,EAAE;QACN,cAAc,EAAE,iBAAiB;QACjC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,QAAQ,GAA4B;IAC/C,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;QAAE,SAAS;KAAC;IACvD,MAAM,EAAE;QACN,cAAc,EAAE,UAAU;QAC1B,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,KAAK;CACxB,CAAC;AAEK,MAAM,aAAa,GAA4B;IACpD,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;QAAE,cAAc;KAAC;IAC5D,MAAM,EAAE;QACN,cAAc,EAAE,cAAc;QAC9B,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,KAAK;CACxB,CAAC;AAEK,MAAM,OAAO,GAA4B;IAC9C,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;QAAE,QAAQ;KAAC;IACtD,MAAM,EAAE;QACN,cAAc,EAAE,SAAS;QACzB,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,KAAK;CACxB,CAAC;AAEK,MAAM,IAAI,GAA4B;IAC3C,aAAa,EAAE;QAAC,SAAS;QAAE,gBAAgB;QAAE,KAAK;KAAC;IACnD,MAAM,EAAE;QACN,cAAc,EAAE,MAAM;QACtB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,cAAc,GAAuB;IAChD,aAAa,EAAE,gBAAgB;IAC/B,MAAM,mNAAE,iBAAoB;CAC7B,CAAC;AAEK,MAAM,KAAK,GAAuB;IACvC,aAAa,EAAE,OAAO;IACtB,MAAM,mNAAE,aAAgB;CACzB,CAAC;AAEK,MAAM,gBAAgB,GAA4B;IACvD,aAAa,EAAE;QAAC,SAAS;QAAE,qBAAqB;QAAE,kBAAkB;KAAC;IACrE,MAAM,EAAE;QACN,cAAc,EAAE,kBAAkB;QAClC,IAAI,EAAE;YACJ,IAAI,EAAE,MAAM;YACZ,aAAa,EAAE;gBAAC,SAAS;gBAAE,UAAU;gBAAE,oBAAoB;aAAC;SAC7D;KACF;CACF,CAAC;AAEK,MAAM,OAAO,GAA4B;IAC9C,aAAa,EAAE;QAAC,SAAS;QAAE,qBAAqB;QAAE,QAAQ;KAAC;IAC3D,MAAM,EAAE;QACN,cAAc,EAAE,SAAS;QACzB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,iBAAiB,GAA4B;IACxD,aAAa,EAAE;QAAC,SAAS;QAAE,qBAAqB;QAAE,kBAAkB;KAAC;IACrE,MAAM,EAAE;QACN,cAAc,EAAE,OAAO;QACvB,IAAI,EAAE;YACJ,IAAI,EAAE,SAAS;SAChB;KACF;CACF,CAAC;AAEK,MAAM,iBAAiB,GAA4B;IACxD,aAAa,EAAE;QAAC,SAAS;QAAE,qBAAqB;QAAE,kBAAkB;KAAC;IACrE,MAAM,EAAE;QACN,cAAc,EAAE,kBAAkB;QAClC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,gBAAgB,GAA4B;IACvD,aAAa,EAAE;QAAC,SAAS;QAAE,qBAAqB;QAAE,iBAAiB;KAAC;IACpE,MAAM,EAAE;QACN,cAAc,EAAE,iBAAiB;QACjC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,gBAAgB,GAA4B;IACvD,aAAa,EAAE;QAAC,SAAS;QAAE,qBAAqB;QAAE,iBAAiB;KAAC;IACpE,MAAM,EAAE;QACN,cAAc,EAAE,iBAAiB;QACjC,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,aAAa,GAA4B;IACpD,aAAa,EAAE;QAAC,SAAS;QAAE,qBAAqB;QAAE,cAAc;KAAC;IACjE,MAAM,EAAE;QACN,cAAc,EAAE,cAAc;QAC9B,IAAI,EAAE;YACJ,IAAI,EAAE,UAAU;YAChB,OAAO,EAAE;gBACP,IAAI,EAAE;oBACJ,IAAI,EAAE,QAAQ;iBACf;aACF;SACF;KACF;IACD,gBAAgB,EAAE,KAAK;CACxB,CAAC;AAEK,MAAM,IAAI,GAA4B;IAC3C,aAAa,EAAE;QAAC,SAAS;QAAE,qBAAqB;QAAE,KAAK;KAAC;IACxD,MAAM,EAAE;QACN,cAAc,EAAE,MAAM;QACtB,IAAI,EAAE;YACJ,IAAI,EAAE,QAAQ;SACf;KACF;CACF,CAAC;AAEK,MAAM,mBAAmB,GAAuB;IACrD,aAAa,EAAE,qBAAqB;IACpC,MAAM,mNAAE,sBAAyB;CAClC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1931, "column": 0}, "map": {"version":3,"file":"documents.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/generated/data/operations/documents.ts"],"sourcesContent":["/*\n * Copyright (c) Microsoft Corporation.\n * Licensed under the MIT License.\n *\n * Code generated by Microsoft (R) AutoRest Code Generator.\n * Changes may cause incorrect behavior and will be lost if the code is regenerated.\n */\n\nimport { Documents } from \"../operationsInterfaces\";\nimport * as coreClient from \"@azure/core-client\";\nimport * as Mappers from \"../models/mappers\";\nimport * as Parameters from \"../models/parameters\";\nimport { SearchClient } from \"../searchClient\";\nimport {\n  DocumentsCountOptionalParams,\n  DocumentsCountResponse,\n  DocumentsSearchGetOptionalParams,\n  DocumentsSearchGetResponse,\n  SearchRequest,\n  DocumentsSearchPostOptionalParams,\n  DocumentsSearchPostResponse,\n  DocumentsGetOptionalParams,\n  DocumentsGetResponse,\n  DocumentsSuggestGetOptionalParams,\n  DocumentsSuggestGetResponse,\n  SuggestRequest,\n  DocumentsSuggestPostOptionalParams,\n  DocumentsSuggestPostResponse,\n  IndexBatch,\n  DocumentsIndexOptionalParams,\n  DocumentsIndexResponse,\n  DocumentsAutocompleteGetOptionalParams,\n  DocumentsAutocompleteGetResponse,\n  AutocompleteRequest,\n  DocumentsAutocompletePostOptionalParams,\n  DocumentsAutocompletePostResponse,\n} from \"../models\";\n\n/** Class containing Documents operations. */\nexport class DocumentsImpl implements Documents {\n  private readonly client: SearchClient;\n\n  /**\n   * Initialize a new instance of the class Documents class.\n   * @param client Reference to the service client\n   */\n  constructor(client: SearchClient) {\n    this.client = client;\n  }\n\n  /**\n   * Queries the number of documents in the index.\n   * @param options The options parameters.\n   */\n  count(\n    options?: DocumentsCountOptionalParams,\n  ): Promise<DocumentsCountResponse> {\n    return this.client.sendOperationRequest({ options }, countOperationSpec);\n  }\n\n  /**\n   * Searches for documents in the index.\n   * @param options The options parameters.\n   */\n  searchGet(\n    options?: DocumentsSearchGetOptionalParams,\n  ): Promise<DocumentsSearchGetResponse> {\n    return this.client.sendOperationRequest(\n      { options },\n      searchGetOperationSpec,\n    );\n  }\n\n  /**\n   * Searches for documents in the index.\n   * @param searchRequest The definition of the Search request.\n   * @param options The options parameters.\n   */\n  searchPost(\n    searchRequest: SearchRequest,\n    options?: DocumentsSearchPostOptionalParams,\n  ): Promise<DocumentsSearchPostResponse> {\n    return this.client.sendOperationRequest(\n      { searchRequest, options },\n      searchPostOperationSpec,\n    );\n  }\n\n  /**\n   * Retrieves a document from the index.\n   * @param key The key of the document to retrieve.\n   * @param options The options parameters.\n   */\n  get(\n    key: string,\n    options?: DocumentsGetOptionalParams,\n  ): Promise<DocumentsGetResponse> {\n    return this.client.sendOperationRequest({ key, options }, getOperationSpec);\n  }\n\n  /**\n   * Suggests documents in the index that match the given partial query text.\n   * @param searchText The search text to use to suggest documents. Must be at least 1 character, and no\n   *                   more than 100 characters.\n   * @param suggesterName The name of the suggester as specified in the suggesters collection that's part\n   *                      of the index definition.\n   * @param options The options parameters.\n   */\n  suggestGet(\n    searchText: string,\n    suggesterName: string,\n    options?: DocumentsSuggestGetOptionalParams,\n  ): Promise<DocumentsSuggestGetResponse> {\n    return this.client.sendOperationRequest(\n      { searchText, suggesterName, options },\n      suggestGetOperationSpec,\n    );\n  }\n\n  /**\n   * Suggests documents in the index that match the given partial query text.\n   * @param suggestRequest The Suggest request.\n   * @param options The options parameters.\n   */\n  suggestPost(\n    suggestRequest: SuggestRequest,\n    options?: DocumentsSuggestPostOptionalParams,\n  ): Promise<DocumentsSuggestPostResponse> {\n    return this.client.sendOperationRequest(\n      { suggestRequest, options },\n      suggestPostOperationSpec,\n    );\n  }\n\n  /**\n   * Sends a batch of document write actions to the index.\n   * @param batch The batch of index actions.\n   * @param options The options parameters.\n   */\n  index(\n    batch: IndexBatch,\n    options?: DocumentsIndexOptionalParams,\n  ): Promise<DocumentsIndexResponse> {\n    return this.client.sendOperationRequest(\n      { batch, options },\n      indexOperationSpec,\n    );\n  }\n\n  /**\n   * Autocompletes incomplete query terms based on input text and matching terms in the index.\n   * @param searchText The incomplete term which should be auto-completed.\n   * @param suggesterName The name of the suggester as specified in the suggesters collection that's part\n   *                      of the index definition.\n   * @param options The options parameters.\n   */\n  autocompleteGet(\n    searchText: string,\n    suggesterName: string,\n    options?: DocumentsAutocompleteGetOptionalParams,\n  ): Promise<DocumentsAutocompleteGetResponse> {\n    return this.client.sendOperationRequest(\n      { searchText, suggesterName, options },\n      autocompleteGetOperationSpec,\n    );\n  }\n\n  /**\n   * Autocompletes incomplete query terms based on input text and matching terms in the index.\n   * @param autocompleteRequest The definition of the Autocomplete request.\n   * @param options The options parameters.\n   */\n  autocompletePost(\n    autocompleteRequest: AutocompleteRequest,\n    options?: DocumentsAutocompletePostOptionalParams,\n  ): Promise<DocumentsAutocompletePostResponse> {\n    return this.client.sendOperationRequest(\n      { autocompleteRequest, options },\n      autocompletePostOperationSpec,\n    );\n  }\n}\n// Operation Specifications\nconst serializer = coreClient.createSerializer(Mappers, /* isXml */ false);\n\nconst countOperationSpec: coreClient.OperationSpec = {\n  path: \"/docs/$count\",\n  httpMethod: \"GET\",\n  responses: {\n    200: {\n      bodyMapper: { type: { name: \"Number\" } },\n    },\n    default: {\n      bodyMapper: Mappers.ErrorResponse,\n    },\n  },\n  queryParameters: [Parameters.apiVersion],\n  urlParameters: [Parameters.endpoint, Parameters.indexName],\n  headerParameters: [Parameters.accept],\n  serializer,\n};\nconst searchGetOperationSpec: coreClient.OperationSpec = {\n  path: \"/docs\",\n  httpMethod: \"GET\",\n  responses: {\n    200: {\n      bodyMapper: Mappers.SearchDocumentsResult,\n    },\n    default: {\n      bodyMapper: Mappers.ErrorResponse,\n    },\n  },\n  queryParameters: [\n    Parameters.apiVersion,\n    Parameters.searchText,\n    Parameters.includeTotalResultCount,\n    Parameters.facets,\n    Parameters.filter,\n    Parameters.highlightFields,\n    Parameters.highlightPostTag,\n    Parameters.highlightPreTag,\n    Parameters.minimumCoverage,\n    Parameters.orderBy,\n    Parameters.queryType,\n    Parameters.scoringParameters,\n    Parameters.scoringProfile,\n    Parameters.searchFields,\n    Parameters.searchMode,\n    Parameters.scoringStatistics,\n    Parameters.sessionId,\n    Parameters.select,\n    Parameters.skip,\n    Parameters.top,\n    Parameters.semanticConfiguration,\n    Parameters.semanticErrorHandling,\n    Parameters.semanticMaxWaitInMilliseconds,\n    Parameters.answers,\n    Parameters.captions,\n    Parameters.semanticQuery,\n  ],\n  urlParameters: [Parameters.endpoint, Parameters.indexName],\n  headerParameters: [Parameters.accept],\n  serializer,\n};\nconst searchPostOperationSpec: coreClient.OperationSpec = {\n  path: \"/docs/search.post.search\",\n  httpMethod: \"POST\",\n  responses: {\n    200: {\n      bodyMapper: Mappers.SearchDocumentsResult,\n    },\n    default: {\n      bodyMapper: Mappers.ErrorResponse,\n    },\n  },\n  requestBody: Parameters.searchRequest,\n  queryParameters: [Parameters.apiVersion],\n  urlParameters: [Parameters.endpoint, Parameters.indexName],\n  headerParameters: [Parameters.accept, Parameters.contentType],\n  mediaType: \"json\",\n  serializer,\n};\nconst getOperationSpec: coreClient.OperationSpec = {\n  path: \"/docs('{key}')\",\n  httpMethod: \"GET\",\n  responses: {\n    200: {\n      bodyMapper: {\n        type: { name: \"Dictionary\", value: { type: { name: \"any\" } } },\n      },\n    },\n    default: {\n      bodyMapper: Mappers.ErrorResponse,\n    },\n  },\n  queryParameters: [Parameters.apiVersion, Parameters.selectedFields],\n  urlParameters: [Parameters.endpoint, Parameters.indexName, Parameters.key],\n  headerParameters: [Parameters.accept],\n  serializer,\n};\nconst suggestGetOperationSpec: coreClient.OperationSpec = {\n  path: \"/docs/search.suggest\",\n  httpMethod: \"GET\",\n  responses: {\n    200: {\n      bodyMapper: Mappers.SuggestDocumentsResult,\n    },\n    default: {\n      bodyMapper: Mappers.ErrorResponse,\n    },\n  },\n  queryParameters: [\n    Parameters.apiVersion,\n    Parameters.searchText1,\n    Parameters.suggesterName,\n    Parameters.filter1,\n    Parameters.useFuzzyMatching,\n    Parameters.highlightPostTag1,\n    Parameters.highlightPreTag1,\n    Parameters.minimumCoverage1,\n    Parameters.orderBy1,\n    Parameters.searchFields1,\n    Parameters.select1,\n    Parameters.top1,\n  ],\n  urlParameters: [Parameters.endpoint, Parameters.indexName],\n  headerParameters: [Parameters.accept],\n  serializer,\n};\nconst suggestPostOperationSpec: coreClient.OperationSpec = {\n  path: \"/docs/search.post.suggest\",\n  httpMethod: \"POST\",\n  responses: {\n    200: {\n      bodyMapper: Mappers.SuggestDocumentsResult,\n    },\n    default: {\n      bodyMapper: Mappers.ErrorResponse,\n    },\n  },\n  requestBody: Parameters.suggestRequest,\n  queryParameters: [Parameters.apiVersion],\n  urlParameters: [Parameters.endpoint, Parameters.indexName],\n  headerParameters: [Parameters.accept, Parameters.contentType],\n  mediaType: \"json\",\n  serializer,\n};\nconst indexOperationSpec: coreClient.OperationSpec = {\n  path: \"/docs/search.index\",\n  httpMethod: \"POST\",\n  responses: {\n    200: {\n      bodyMapper: Mappers.IndexDocumentsResult,\n    },\n    207: {\n      bodyMapper: Mappers.IndexDocumentsResult,\n    },\n    default: {\n      bodyMapper: Mappers.ErrorResponse,\n    },\n  },\n  requestBody: Parameters.batch,\n  queryParameters: [Parameters.apiVersion],\n  urlParameters: [Parameters.endpoint, Parameters.indexName],\n  headerParameters: [Parameters.accept, Parameters.contentType],\n  mediaType: \"json\",\n  serializer,\n};\nconst autocompleteGetOperationSpec: coreClient.OperationSpec = {\n  path: \"/docs/search.autocomplete\",\n  httpMethod: \"GET\",\n  responses: {\n    200: {\n      bodyMapper: Mappers.AutocompleteResult,\n    },\n    default: {\n      bodyMapper: Mappers.ErrorResponse,\n    },\n  },\n  queryParameters: [\n    Parameters.apiVersion,\n    Parameters.searchText1,\n    Parameters.suggesterName,\n    Parameters.autocompleteMode,\n    Parameters.filter2,\n    Parameters.useFuzzyMatching1,\n    Parameters.highlightPostTag2,\n    Parameters.highlightPreTag2,\n    Parameters.minimumCoverage2,\n    Parameters.searchFields2,\n    Parameters.top2,\n  ],\n  urlParameters: [Parameters.endpoint, Parameters.indexName],\n  headerParameters: [Parameters.accept],\n  serializer,\n};\nconst autocompletePostOperationSpec: coreClient.OperationSpec = {\n  path: \"/docs/search.post.autocomplete\",\n  httpMethod: \"POST\",\n  responses: {\n    200: {\n      bodyMapper: Mappers.AutocompleteResult,\n    },\n    default: {\n      bodyMapper: Mappers.ErrorResponse,\n    },\n  },\n  requestBody: Parameters.autocompleteRequest,\n  queryParameters: [Parameters.apiVersion],\n  urlParameters: [Parameters.endpoint, Parameters.indexName],\n  headerParameters: [Parameters.accept, Parameters.contentType],\n  mediaType: \"json\",\n  serializer,\n};\n"],"names":[],"mappings":"AAAA;;;;;;GAMG;;;AAGH,OAAO,KAAK,UAAU,MAAM,oBAAoB,CAAC;;AACjD,OAAO,KAAK,OAAO,MAAM,mBAAmB,CAAC;AAC7C,OAAO,KAAK,UAAU,MAAM,sBAAsB,CAAC;;;;AA4B7C,MAAO,aAAa;IAGxB;;;OAGG,CACH,YAAY,MAAoB,CAAA;QAC9B,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;IACvB,CAAC;IAED;;;OAGG,CACH,KAAK,CACH,OAAsC,EAAA;QAEtC,OAAO,IAAI,CAAC,MAAM,CAAC,oBAAoB,CAAC;YAAE,OAAO;QAAA,CAAE,EAAE,kBAAkB,CAAC,CAAC;IAC3E,CAAC;IAED;;;OAGG,CACH,SAAS,CACP,OAA0C,EAAA;QAE1C,OAAO,IAAI,CAAC,MAAM,CAAC,oBAAoB,CACrC;YAAE,OAAO;QAAA,CAAE,EACX,sBAAsB,CACvB,CAAC;IACJ,CAAC;IAED;;;;OAIG,CACH,UAAU,CACR,aAA4B,EAC5B,OAA2C,EAAA;QAE3C,OAAO,IAAI,CAAC,MAAM,CAAC,oBAAoB,CACrC;YAAE,aAAa;YAAE,OAAO;QAAA,CAAE,EAC1B,uBAAuB,CACxB,CAAC;IACJ,CAAC;IAED;;;;OAIG,CACH,GAAG,CACD,GAAW,EACX,OAAoC,EAAA;QAEpC,OAAO,IAAI,CAAC,MAAM,CAAC,oBAAoB,CAAC;YAAE,GAAG;YAAE,OAAO;QAAA,CAAE,EAAE,gBAAgB,CAAC,CAAC;IAC9E,CAAC;IAED;;;;;;;OAOG,CACH,UAAU,CACR,UAAkB,EAClB,aAAqB,EACrB,OAA2C,EAAA;QAE3C,OAAO,IAAI,CAAC,MAAM,CAAC,oBAAoB,CACrC;YAAE,UAAU;YAAE,aAAa;YAAE,OAAO;QAAA,CAAE,EACtC,uBAAuB,CACxB,CAAC;IACJ,CAAC;IAED;;;;OAIG,CACH,WAAW,CACT,cAA8B,EAC9B,OAA4C,EAAA;QAE5C,OAAO,IAAI,CAAC,MAAM,CAAC,oBAAoB,CACrC;YAAE,cAAc;YAAE,OAAO;QAAA,CAAE,EAC3B,wBAAwB,CACzB,CAAC;IACJ,CAAC;IAED;;;;OAIG,CACH,KAAK,CACH,KAAiB,EACjB,OAAsC,EAAA;QAEtC,OAAO,IAAI,CAAC,MAAM,CAAC,oBAAoB,CACrC;YAAE,KAAK;YAAE,OAAO;QAAA,CAAE,EAClB,kBAAkB,CACnB,CAAC;IACJ,CAAC;IAED;;;;;;OAMG,CACH,eAAe,CACb,UAAkB,EAClB,aAAqB,EACrB,OAAgD,EAAA;QAEhD,OAAO,IAAI,CAAC,MAAM,CAAC,oBAAoB,CACrC;YAAE,UAAU;YAAE,aAAa;YAAE,OAAO;QAAA,CAAE,EACtC,4BAA4B,CAC7B,CAAC;IACJ,CAAC;IAED;;;;OAIG,CACH,gBAAgB,CACd,mBAAwC,EACxC,OAAiD,EAAA;QAEjD,OAAO,IAAI,CAAC,MAAM,CAAC,oBAAoB,CACrC;YAAE,mBAAmB;YAAE,OAAO;QAAA,CAAE,EAChC,6BAA6B,CAC9B,CAAC;IACJ,CAAC;CACF;AACD,2BAA2B;AAC3B,MAAM,UAAU,gLAAG,UAAU,CAAC,QAAA,AAAgB,EAAC,OAAO,2MAAE,SAAA,EAAW,CAAC,KAAK,CAAC,CAAC;AAE3E,MAAM,kBAAkB,GAA6B;IACnD,IAAI,EAAE,cAAc;IACpB,UAAU,EAAE,KAAK;IACjB,SAAS,EAAE;QACT,GAAG,EAAE;YACH,UAAU,EAAE;gBAAE,IAAI,EAAE;oBAAE,IAAI,EAAE,QAAQ;gBAAA,CAAE;YAAA,CAAE;SACzC;QACD,OAAO,EAAE;YACP,UAAU,EAAE,OAAO,0MAAC,aAAa;SAClC;KACF;IACD,eAAe,EAAE;4NAAC,UAAU,CAAC,EAAU;KAAC;IACxC,aAAa,EAAE;4NAAC,UAAU,CAAC,AAAQ;4NAAE,UAAU,CAAC,CAAS;KAAC;IAC1D,gBAAgB,EAAE;2NAAC,UAAiB,AAAP,CAAC;KAAO;IACrC,UAAU;CACX,CAAC;AACF,MAAM,sBAAsB,GAA6B;IACvD,IAAI,EAAE,OAAO;IACb,UAAU,EAAE,KAAK;IACjB,SAAS,EAAE;QACT,GAAG,EAAE;YACH,UAAU,EAAE,OAAO,0MAAC,qBAAqB;SAC1C;QACD,OAAO,EAAE;YACP,UAAU,EAAE,OAAO,0MAAC,aAAa;SAClC;KACF;IACD,eAAe,EAAE;QACf,UAAU,CAAC,sNAAU;4NACrB,UAAU,CAAC,EAAU;4NACrB,UAAU,CAAC,eAAuB;4NAClC,SAAiB,CAAP,CAAC;4NACX,SAAiB,CAAP,CAAC;QACX,UAAU,CAAC,2NAAe;4NAC1B,UAAU,CAAC,QAAgB;4NAC3B,UAAU,CAAC,OAAe;4NAC1B,UAAU,CAAC,OAAe;4NAC1B,UAAU,AAAQ,CAAP;4NACX,UAAU,CAAC,CAAS;4NACpB,UAAU,CAAC,SAAiB;4NAC5B,UAAU,CAAC,MAAc;4NACzB,UAAU,CAAC,IAAY;4NACvB,UAAU,CAAC,EAAU;QACrB,UAAU,CAAC,6NAAiB;4NAC5B,UAAU,CAAC,CAAS;4NACpB,SAAiB,CAAP,CAAC;4NACX,OAAe,GAAL,CAAC;4NACX,MAAc,IAAJ,CAAC;4NACX,UAAU,CAAC,aAAqB;4NAChC,UAAU,CAAC,aAAqB;4NAChC,UAAU,CAAC,qBAA6B;2NACxC,UAAU,CAAC,AAAO;4NAClB,UAAU,CAAC,AAAQ;4NACnB,UAAU,CAAC,KAAa;KACzB;IACD,aAAa,EAAE;4NAAC,UAAU,CAAC,AAAQ;4NAAE,UAAU,CAAC,CAAS;KAAC;IAC1D,gBAAgB,EAAE;4NAAC,SAAiB,CAAP,CAAC;KAAO;IACrC,UAAU;CACX,CAAC;AACF,MAAM,uBAAuB,GAA6B;IACxD,IAAI,EAAE,0BAA0B;IAChC,UAAU,EAAE,MAAM;IAClB,SAAS,EAAE;QACT,GAAG,EAAE;YACH,UAAU,EAAE,OAAO,0MAAC,qBAAqB;SAC1C;QACD,OAAO,EAAE;YACP,UAAU,EAAE,OAAO,0MAAC,aAAa;SAClC;KACF;IACD,WAAW,EAAE,UAAU,CAAC,yNAAa;IACrC,eAAe,EAAE;4NAAC,UAAU,CAAC,EAAU;KAAC;IACxC,aAAa,EAAE;4NAAC,UAAU,CAAC,AAAQ;4NAAE,UAAU,CAAC,CAAS;KAAC;IAC1D,gBAAgB,EAAE;QAAC,UAAU,CAAC,kNAAM;4NAAE,UAAU,CAAC,GAAW;KAAC;IAC7D,SAAS,EAAE,MAAM;IACjB,UAAU;CACX,CAAC;AACF,MAAM,gBAAgB,GAA6B;IACjD,IAAI,EAAE,gBAAgB;IACtB,UAAU,EAAE,KAAK;IACjB,SAAS,EAAE;QACT,GAAG,EAAE;YACH,UAAU,EAAE;gBACV,IAAI,EAAE;oBAAE,IAAI,EAAE,YAAY;oBAAE,KAAK,EAAE;wBAAE,IAAI,EAAE;4BAAE,IAAI,EAAE,KAAK;wBAAA,CAAE;oBAAA,CAAE;gBAAA,CAAE;aAC/D;SACF;QACD,OAAO,EAAE;YACP,UAAU,EAAE,OAAO,0MAAC,aAAa;SAClC;KACF;IACD,eAAe,EAAE;QAAC,UAAU,CAAC,sNAAU;QAAE,UAAU,CAAC,0NAAc;KAAC;IACnE,aAAa,EAAE;4NAAC,UAAU,CAAC,AAAQ;4NAAE,UAAU,CAAC,CAAS;QAAE,UAAU,CAAC,+MAAG;KAAC;IAC1E,gBAAgB,EAAE;4NAAC,SAAiB,CAAP,CAAC;KAAO;IACrC,UAAU;CACX,CAAC;AACF,MAAM,uBAAuB,GAA6B;IACxD,IAAI,EAAE,sBAAsB;IAC5B,UAAU,EAAE,KAAK;IACjB,SAAS,EAAE;QACT,GAAG,EAAE;YACH,UAAU,EAAE,OAAO,0MAAC,sBAAsB;SAC3C;QACD,OAAO,EAAE;YACP,UAAU,EAAE,OAAO,0MAAC,aAAa;SAClC;KACF;IACD,eAAe,EAAE;4NACf,UAAU,CAAC,EAAU;4NACrB,UAAU,CAAC,GAAW;4NACtB,UAAU,CAAC,KAAa;4NACxB,UAAU,AAAQ,CAAP;4NACX,UAAU,CAAC,QAAgB;4NAC3B,UAAU,CAAC,SAAiB;4NAC5B,UAAU,CAAC,QAAgB;4NAC3B,UAAU,CAAC,QAAgB;4NAC3B,UAAU,CAAC,AAAQ;4NACnB,UAAU,CAAC,KAAa;2NACxB,UAAU,CAAC,AAAO;4NAClB,OAAe,GAAL,CAAC;KACZ;IACD,aAAa,EAAE;4NAAC,UAAU,CAAC,AAAQ;4NAAE,UAAU,CAAC,CAAS;KAAC;IAC1D,gBAAgB,EAAE;4NAAC,SAAiB,CAAP,CAAC;KAAO;IACrC,UAAU;CACX,CAAC;AACF,MAAM,wBAAwB,GAA6B;IACzD,IAAI,EAAE,2BAA2B;IACjC,UAAU,EAAE,MAAM;IAClB,SAAS,EAAE;QACT,GAAG,EAAE;YACH,UAAU,EAAE,OAAO,0MAAC,sBAAsB;SAC3C;QACD,OAAO,EAAE;YACP,UAAU,EAAE,OAAO,0MAAC,aAAa;SAClC;KACF;IACD,WAAW,sNAAE,UAAU,CAAC,MAAc;IACtC,eAAe,EAAE;4NAAC,UAAU,CAAC,EAAU;KAAC;IACxC,aAAa,EAAE;4NAAC,UAAU,CAAC,AAAQ;4NAAE,UAAU,CAAC,CAAS;KAAC;IAC1D,gBAAgB,EAAE;4NAAC,SAAiB,CAAP,CAAC;QAAQ,UAAU,CAAC,uNAAW;KAAC;IAC7D,SAAS,EAAE,MAAM;IACjB,UAAU;CACX,CAAC;AACF,MAAM,kBAAkB,GAA6B;IACnD,IAAI,EAAE,oBAAoB;IAC1B,UAAU,EAAE,MAAM;IAClB,SAAS,EAAE;QACT,GAAG,EAAE;YACH,UAAU,EAAE,OAAO,0MAAC,oBAAoB;SACzC;QACD,GAAG,EAAE;YACH,UAAU,EAAE,OAAO,0MAAC,oBAAoB;SACzC;QACD,OAAO,EAAE;YACP,UAAU,EAAE,OAAO,0MAAC,aAAa;SAClC;KACF;IACD,WAAW,sNAAE,QAAgB,EAAN,CAAC;IACxB,eAAe,EAAE;QAAC,UAAU,CAAC,sNAAU;KAAC;IACxC,aAAa,EAAE;4NAAC,UAAU,CAAC,AAAQ;4NAAE,UAAU,CAAC,CAAS;KAAC;IAC1D,gBAAgB,EAAE;4NAAC,SAAiB,CAAP,CAAC;4NAAQ,UAAU,CAAC,GAAW;KAAC;IAC7D,SAAS,EAAE,MAAM;IACjB,UAAU;CACX,CAAC;AACF,MAAM,4BAA4B,GAA6B;IAC7D,IAAI,EAAE,2BAA2B;IACjC,UAAU,EAAE,KAAK;IACjB,SAAS,EAAE;QACT,GAAG,EAAE;YACH,UAAU,EAAE,OAAO,0MAAC,kBAAkB;SACvC;QACD,OAAO,EAAE;YACP,UAAU,EAAE,OAAO,0MAAC,aAAa;SAClC;KACF;IACD,eAAe,EAAE;4NACf,UAAU,CAAC,EAAU;4NACrB,UAAU,CAAC,GAAW;4NACtB,UAAU,CAAC,KAAa;4NACxB,UAAU,CAAC,QAAgB;4NAC3B,UAAkB,AAAR,CAAC;QACX,UAAU,CAAC,6NAAiB;4NAC5B,UAAU,CAAC,SAAiB;4NAC5B,UAAU,CAAC,QAAgB;4NAC3B,UAAU,CAAC,QAAgB;4NAC3B,UAAU,CAAC,KAAa;4NACxB,OAAe,GAAL,CAAC;KACZ;IACD,aAAa,EAAE;4NAAC,UAAU,CAAS,AAAR;4NAAU,UAAU,CAAC,CAAS;KAAC;IAC1D,gBAAgB,EAAE;4NAAC,SAAiB,CAAP,CAAC;KAAO;IACrC,UAAU;CACX,CAAC;AACF,MAAM,6BAA6B,GAA6B;IAC9D,IAAI,EAAE,gCAAgC;IACtC,UAAU,EAAE,MAAM;IAClB,SAAS,EAAE;QACT,GAAG,EAAE;YACH,UAAU,EAAE,OAAO,0MAAC,kBAAkB;SACvC;QACD,OAAO,EAAE;YACP,UAAU,EAAE,OAAO,0MAAC,aAAa;SAClC;KACF;IACD,WAAW,EAAE,UAAU,CAAC,+NAAmB;IAC3C,eAAe,EAAE;4NAAC,UAAU,CAAC,EAAU;KAAC;IACxC,aAAa,EAAE;4NAAC,UAAU,CAAC,AAAQ;4NAAE,UAAU,CAAC,CAAS;KAAC;IAC1D,gBAAgB,EAAE;4NAAC,SAAiB,CAAP,CAAC;4NAAQ,UAAU,CAAC,GAAW;KAAC;IAC7D,SAAS,EAAE,MAAM;IACjB,UAAU;CACX,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2339, "column": 0}, "map": {"version":3,"file":"searchClient.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/generated/data/searchClient.ts"],"sourcesContent":["/*\n * Copyright (c) Microsoft Corporation.\n * Licensed under the MIT License.\n *\n * Code generated by Microsoft (R) AutoRest Code Generator.\n * Changes may cause incorrect behavior and will be lost if the code is regenerated.\n */\n\nimport * as coreHttpCompat from \"@azure/core-http-compat\";\nimport {\n  PipelineRequest,\n  PipelineResponse,\n  SendRequest,\n} from \"@azure/core-rest-pipeline\";\nimport { DocumentsImpl } from \"./operations\";\nimport { Documents } from \"./operationsInterfaces\";\nimport { ApiVersion20240701, SearchClientOptionalParams } from \"./models\";\n\n/** @internal */\nexport class SearchClient extends coreHttpCompat.ExtendedServiceClient {\n  endpoint: string;\n  indexName: string;\n  apiVersion: ApiVersion20240701;\n\n  /**\n   * Initializes a new instance of the SearchClient class.\n   * @param endpoint The endpoint URL of the search service.\n   * @param indexName The name of the index.\n   * @param apiVersion Api Version\n   * @param options The parameter options\n   */\n  constructor(\n    endpoint: string,\n    indexName: string,\n    apiVersion: ApiVersion20240701,\n    options?: SearchClientOptionalParams,\n  ) {\n    if (endpoint === undefined) {\n      throw new Error(\"'endpoint' cannot be null\");\n    }\n    if (indexName === undefined) {\n      throw new Error(\"'indexName' cannot be null\");\n    }\n    if (apiVersion === undefined) {\n      throw new Error(\"'apiVersion' cannot be null\");\n    }\n\n    // Initializing default values for options\n    if (!options) {\n      options = {};\n    }\n    const defaults: SearchClientOptionalParams = {\n      requestContentType: \"application/json; charset=utf-8\",\n    };\n\n    const packageDetails = `azsdk-js-search-documents/12.1.0`;\n    const userAgentPrefix =\n      options.userAgentOptions && options.userAgentOptions.userAgentPrefix\n        ? `${options.userAgentOptions.userAgentPrefix} ${packageDetails}`\n        : `${packageDetails}`;\n\n    const optionsWithDefaults = {\n      ...defaults,\n      ...options,\n      userAgentOptions: {\n        userAgentPrefix,\n      },\n      endpoint:\n        options.endpoint ??\n        options.baseUri ??\n        \"{endpoint}/indexes('{indexName}')\",\n    };\n    super(optionsWithDefaults);\n    // Parameter assignments\n    this.endpoint = endpoint;\n    this.indexName = indexName;\n    this.apiVersion = apiVersion;\n    this.documents = new DocumentsImpl(this);\n    this.addCustomApiVersionPolicy(apiVersion);\n  }\n\n  /** A function that adds a policy that sets the api-version (or equivalent) to reflect the library version. */\n  private addCustomApiVersionPolicy(apiVersion?: string) {\n    if (!apiVersion) {\n      return;\n    }\n    const apiVersionPolicy = {\n      name: \"CustomApiVersionPolicy\",\n      async sendRequest(\n        request: PipelineRequest,\n        next: SendRequest,\n      ): Promise<PipelineResponse> {\n        const param = request.url.split(\"?\");\n        if (param.length > 1) {\n          const newParams = param[1].split(\"&\").map((item) => {\n            if (item.indexOf(\"api-version\") > -1) {\n              return \"api-version=\" + apiVersion;\n            } else {\n              return item;\n            }\n          });\n          request.url = param[0] + \"?\" + newParams.join(\"&\");\n        }\n        return next(request);\n      },\n    };\n    this.pipeline.addPolicy(apiVersionPolicy);\n  }\n\n  documents: Documents;\n}\n"],"names":[],"mappings":"AAAA;;;;;;GAMG;;;;AAEH,OAAO,KAAK,cAAc,MAAM,yBAAyB,CAAC;AAM1D,OAAO,EAAE,aAAa,EAAE,MAAM,cAAc,CAAC;;;AAKvC,MAAO,YAAa,8LAAQ,cAAc,CAAC,SAAqB;IAKpE;;;;;;OAMG,CACH,YACE,QAAgB,EAChB,SAAiB,EACjB,UAA8B,EAC9B,OAAoC,CAAA;;QAEpC,IAAI,QAAQ,KAAK,SAAS,EAAE,CAAC;YAC3B,MAAM,IAAI,KAAK,CAAC,2BAA2B,CAAC,CAAC;QAC/C,CAAC;QACD,IAAI,SAAS,KAAK,SAAS,EAAE,CAAC;YAC5B,MAAM,IAAI,KAAK,CAAC,4BAA4B,CAAC,CAAC;QAChD,CAAC;QACD,IAAI,UAAU,KAAK,SAAS,EAAE,CAAC;YAC7B,MAAM,IAAI,KAAK,CAAC,6BAA6B,CAAC,CAAC;QACjD,CAAC;QAED,0CAA0C;QAC1C,IAAI,CAAC,OAAO,EAAE,CAAC;YACb,OAAO,GAAG,CAAA,CAAE,CAAC;QACf,CAAC;QACD,MAAM,QAAQ,GAA+B;YAC3C,kBAAkB,EAAE,iCAAiC;SACtD,CAAC;QAEF,MAAM,cAAc,GAAG,CAAA,gCAAA,CAAkC,CAAC;QAC1D,MAAM,eAAe,GACnB,OAAO,CAAC,gBAAgB,IAAI,OAAO,CAAC,gBAAgB,CAAC,eAAe,GAChE,GAAG,OAAO,CAAC,gBAAgB,CAAC,eAAe,CAAA,CAAA,EAAI,cAAc,EAAE,GAC/D,GAAG,cAAc,EAAE,CAAC;QAE1B,MAAM,mBAAmB,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACpB,QAAQ,GACR,OAAO,GAAA;YACV,gBAAgB,EAAE;gBAChB,eAAe;aAChB;YACD,QAAQ,EACN,CAAA,KAAA,CAAA,KAAA,OAAO,CAAC,QAAQ,MAAA,QAAA,OAAA,KAAA,IAAA,KAChB,OAAO,CAAC,OAAO,MAAA,QAAA,OAAA,KAAA,IAAA,KACf,mCAAmC;QAAA,EACtC,CAAC;QACF,KAAK,CAAC,mBAAmB,CAAC,CAAC;QAC3B,wBAAwB;QACxB,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;QACzB,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;QAC3B,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;QAC7B,IAAI,CAAC,SAAS,GAAG,2NAAI,gBAAa,CAAC,IAAI,CAAC,CAAC;QACzC,IAAI,CAAC,yBAAyB,CAAC,UAAU,CAAC,CAAC;IAC7C,CAAC;IAED,4GAAA,EAA8G,CACtG,yBAAyB,CAAC,UAAmB,EAAA;QACnD,IAAI,CAAC,UAAU,EAAE,CAAC;YAChB,OAAO;QACT,CAAC;QACD,MAAM,gBAAgB,GAAG;YACvB,IAAI,EAAE,wBAAwB;YAC9B,KAAK,CAAC,WAAW,EACf,OAAwB,EACxB,IAAiB;gBAEjB,MAAM,KAAK,GAAG,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;gBACrC,IAAI,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;oBACrB,MAAM,SAAS,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE;wBACjD,IAAI,IAAI,CAAC,OAAO,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC;4BACrC,OAAO,cAAc,GAAG,UAAU,CAAC;wBACrC,CAAC,MAAM,CAAC;4BACN,OAAO,IAAI,CAAC;wBACd,CAAC;oBACH,CAAC,CAAC,CAAC;oBACH,OAAO,CAAC,GAAG,GAAG,KAAK,CAAC,CAAC,CAAC,GAAG,GAAG,GAAG,SAAS,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;gBACrD,CAAC;gBACD,OAAO,IAAI,CAAC,OAAO,CAAC,CAAC;YACvB,CAAC;SACF,CAAC;QACF,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,gBAAgB,CAAC,CAAC;IAC5C,CAAC;CAGF","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2424, "column": 0}, "map": {"version":3,"file":"indexDocumentsBatch.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/indexDocumentsBatch.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport { IndexDocumentsAction } from \"./indexModels\";\n\n/**\n * Class used to perform batch operations\n * with multiple documents to the index.\n */\nexport class IndexDocumentsBatch<TModel> {\n  /**\n   * The set of actions taken in this batch.\n   */\n  public readonly actions: IndexDocumentsAction<TModel>[];\n\n  constructor(actions: IndexDocumentsAction<TModel>[] = []) {\n    this.actions = actions;\n  }\n\n  /**\n   * Upload an array of documents to the index.\n   * @param documents - The documents to upload.\n   */\n  public upload(documents: TModel[]): void {\n    const batch = documents.map<IndexDocumentsAction<TModel>>((doc) => {\n      return {\n        ...doc,\n        __actionType: \"upload\",\n      };\n    });\n\n    this.actions.push(...batch);\n  }\n\n  /**\n   * Update a set of documents in the index.\n   * For more details about how merging works, see https://docs.microsoft.com/en-us/rest/api/searchservice/AddUpdate-or-Delete-Documents\n   * @param documents - The updated documents.\n   */\n  public merge(documents: TModel[]): void {\n    const batch = documents.map<IndexDocumentsAction<TModel>>((doc) => {\n      return {\n        ...doc,\n        __actionType: \"merge\",\n      };\n    });\n\n    this.actions.push(...batch);\n  }\n\n  /**\n   * Update a set of documents in the index or uploads them if they don't exist.\n   * For more details about how merging works, see https://docs.microsoft.com/en-us/rest/api/searchservice/AddUpdate-or-Delete-Documents\n   * @param documents - The new/updated documents.\n   */\n  public mergeOrUpload(documents: TModel[]): void {\n    const batch = documents.map<IndexDocumentsAction<TModel>>((doc) => {\n      return {\n        ...doc,\n        __actionType: \"mergeOrUpload\",\n      };\n    });\n\n    this.actions.push(...batch);\n  }\n\n  /**\n   * Delete a set of documents.\n   * @param keyName - The name of their primary key in the index.\n   * @param keyValues - The primary key values of documents to delete.\n   */\n  public delete(keyName: keyof TModel, keyValues: string[]): void;\n\n  /**\n   * Delete a set of documents.\n   * @param documents - Documents to be deleted.\n   */\n  public delete(documents: TModel[]): void;\n\n  public delete(keyNameOrDocuments: keyof TModel | TModel[], keyValues?: string[]): void {\n    if (keyValues) {\n      const keyName = keyNameOrDocuments as keyof TModel;\n\n      const batch = keyValues.map<IndexDocumentsAction<TModel>>((keyValue) => {\n        return {\n          __actionType: \"delete\",\n          [keyName]: keyValue,\n        } as IndexDocumentsAction<TModel>;\n      });\n\n      this.actions.push(...batch);\n    } else {\n      const documents = keyNameOrDocuments as TModel[];\n\n      const batch = documents.map<IndexDocumentsAction<TModel>>((document) => {\n        return {\n          __actionType: \"delete\",\n          ...document,\n        } as IndexDocumentsAction<TModel>;\n      });\n\n      this.actions.push(...batch);\n    }\n  }\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;AAIlC;;;GAGG;;;AACG,MAAO,mBAAmB;IAM9B,YAAY,UAA0C,EAAE,CAAA;QACtD,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;IACzB,CAAC;IAED;;;OAGG,CACI,MAAM,CAAC,SAAmB,EAAA;QAC/B,MAAM,KAAK,GAAG,SAAS,CAAC,GAAG,CAA+B,CAAC,GAAG,EAAE,EAAE;YAChE,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,GAAG,GAAA;gBACN,YAAY,EAAE,QAAQ;YAAA,GACtB;QACJ,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC,CAAC;IAC9B,CAAC;IAED;;;;OAIG,CACI,KAAK,CAAC,SAAmB,EAAA;QAC9B,MAAM,KAAK,GAAG,SAAS,CAAC,GAAG,CAA+B,CAAC,GAAG,EAAE,EAAE;YAChE,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,GAAG,GAAA;gBACN,YAAY,EAAE,OAAO;YAAA,GACrB;QACJ,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC,CAAC;IAC9B,CAAC;IAED;;;;OAIG,CACI,aAAa,CAAC,SAAmB,EAAA;QACtC,MAAM,KAAK,GAAG,SAAS,CAAC,GAAG,CAA+B,CAAC,GAAG,EAAE,EAAE;YAChE,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,GAAG,GAAA;gBACN,YAAY,EAAE,eAAe;YAAA,GAC7B;QACJ,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC,CAAC;IAC9B,CAAC;IAeM,MAAM,CAAC,kBAA2C,EAAE,SAAoB,EAAA;QAC7E,IAAI,SAAS,EAAE,CAAC;YACd,MAAM,OAAO,GAAG,kBAAkC,CAAC;YAEnD,MAAM,KAAK,GAAG,SAAS,CAAC,GAAG,CAA+B,CAAC,QAAQ,EAAE,EAAE;gBACrE,OAAO;oBACL,YAAY,EAAE,QAAQ;oBACtB,CAAC,OAAO,CAAC,EAAE,QAAQ;iBACY,CAAC;YACpC,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC,CAAC;QAC9B,CAAC,MAAM,CAAC;YACN,MAAM,SAAS,GAAG,kBAA8B,CAAC;YAEjD,MAAM,KAAK,GAAG,SAAS,CAAC,GAAG,CAA+B,CAAC,QAAQ,EAAE,EAAE;gBACrE,OAAO,OAAA,MAAA,CAAA;oBACL,YAAY,EAAE,QAAQ;gBAAA,GACnB,QAAQ,CACoB,CAAC;YACpC,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC,CAAC;QAC9B,CAAC;IACH,CAAC;CACF","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2498, "column": 0}, "map": {"version":3,"file":"logger.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/logger.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport { createClientLogger } from \"@azure/logger\";\n\n/**\n * The `@azure/logger` configuration for this package.\n */\nexport const logger = createClientLogger(\"search\");\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;AAElC,OAAO,EAAE,kBAAkB,EAAE,MAAM,eAAe,CAAC;;AAK5C,MAAM,MAAM,mKAAG,qBAAA,AAAkB,EAAC,QAAQ,CAAC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2512, "column": 0}, "map": {"version":3,"file":"odataMetadataPolicy.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/odataMetadataPolicy.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport {\n  PipelinePolicy,\n  PipelineRequest,\n  PipelineResponse,\n  SendRequest,\n} from \"@azure/core-rest-pipeline\";\n\nconst AcceptHeaderName = \"Accept\";\n\ntype MetadataLevel = \"none\" | \"minimal\";\nconst odataMetadataPolicy = \"OdataMetadataPolicy\";\n\n/**\n * A policy factory for setting the Accept header to ignore odata metadata\n * @internal\n */\nexport function createOdataMetadataPolicy(metadataLevel: MetadataLevel): PipelinePolicy {\n  return {\n    name: odataMetadataPolicy,\n    async sendRequest(request: PipelineRequest, next: SendRequest): Promise<PipelineResponse> {\n      request.headers.set(AcceptHeaderName, `application/json;odata.metadata=${metadataLevel}`);\n      return next(request);\n    },\n  };\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;AASlC,MAAM,gBAAgB,GAAG,QAAQ,CAAC;AAGlC,MAAM,mBAAmB,GAAG,qBAAqB,CAAC;AAM5C,SAAU,yBAAyB,CAAC,aAA4B;IACpE,OAAO;QACL,IAAI,EAAE,mBAAmB;QACzB,KAAK,CAAC,WAAW,EAAC,OAAwB,EAAE,IAAiB;YAC3D,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,gBAAgB,EAAE,CAAA,gCAAA,EAAmC,aAAa,EAAE,CAAC,CAAC;YAC1F,OAAO,IAAI,CAAC,OAAO,CAAC,CAAC;QACvB,CAAC;KACF,CAAC;AACJ,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2534, "column": 0}, "map": {"version":3,"file":"searchApiKeyCredentialPolicy.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/searchApiKeyCredentialPolicy.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport { KeyCredential } from \"@azure/core-auth\";\nimport {\n  PipelinePolicy,\n  PipelineRequest,\n  PipelineResponse,\n  SendRequest,\n} from \"@azure/core-rest-pipeline\";\n\nconst API_KEY_HEADER_NAME = \"api-key\";\nconst searchApiKeyCredentialPolicy = \"SearchApiKeyCredentialPolicy\";\n\n/**\n * Create an HTTP pipeline policy to authenticate a request\n * using an `AzureKeyCredential` for Azure Cognitive Search\n */\nexport function createSearchApiKeyCredentialPolicy(credential: KeyCredential): PipelinePolicy {\n  return {\n    name: searchApiKeyCredentialPolicy,\n    async sendRequest(request: PipelineRequest, next: SendRequest): Promise<PipelineResponse> {\n      if (!request.headers.has(API_KEY_HEADER_NAME)) {\n        request.headers.set(API_KEY_HEADER_NAME, credential.key);\n      }\n      return next(request);\n    },\n  };\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;AAUlC,MAAM,mBAAmB,GAAG,SAAS,CAAC;AACtC,MAAM,4BAA4B,GAAG,8BAA8B,CAAC;AAM9D,SAAU,kCAAkC,CAAC,UAAyB;IAC1E,OAAO;QACL,IAAI,EAAE,4BAA4B;QAClC,KAAK,CAAC,WAAW,EAAC,OAAwB,EAAE,IAAiB;YAC3D,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,mBAAmB,CAAC,EAAE,CAAC;gBAC9C,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,mBAAmB,EAAE,UAAU,CAAC,GAAG,CAAC,CAAC;YAC3D,CAAC;YACD,OAAO,IAAI,CAAC,OAAO,CAAC,CAAC;QACvB,CAAC;KACF,CAAC;AACJ,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2558, "column": 0}, "map": {"version":3,"file":"searchAudience.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/searchAudience.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/**\n * Known values for Search Audience\n */\nexport enum KnownSearchAudience {\n  /**\n   * Audience for Azure China\n   */\n  AzureChina = \"https://search.azure.cn\",\n  /**\n   * Audience for Azure Government\n   */\n  AzureGovernment = \"https://search.azure.us\",\n  /**\n   * Audience for Azure Public\n   */\n  AzurePublicCloud = \"https://search.azure.com\",\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;AAElC;;GAEG;;;AACH,IAAY,mBAaX;AAbD,CAAA,SAAY,mBAAmB;IAC7B;;OAEG,CACH,mBAAA,CAAA,aAAA,GAAA,yBAAsC,CAAA;IACtC;;OAEG,CACH,mBAAA,CAAA,kBAAA,GAAA,yBAA2C,CAAA;IAC3C;;OAEG,CACH,mBAAA,CAAA,mBAAA,GAAA,0BAA6C,CAAA;AAC/C,CAAC,EAbW,mBAAmB,IAAA,CAAnB,mBAAmB,GAAA,CAAA,CAAA,GAa9B","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2583, "column": 0}, "map": {"version":3,"file":"geographyPoint.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/geographyPoint.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nconst WorldGeodeticSystem1984 = \"EPSG:4326\"; // See https://epsg.io/4326\n\n/**\n * Represents a geographic point in global coordinates.\n */\nexport default class GeographyPoint {\n  /**\n   * The latitude in decimal.\n   */\n  public latitude: number;\n  /**\n   * The longitude in decimal.\n   */\n  public longitude: number;\n\n  /**\n   * Constructs a new instance of GeographyPoint given\n   * the specified coordinates.\n   * @param geographyPoint - object with longitude and latitude values in decimal\n   */\n  constructor(geographyPoint: { longitude: number; latitude: number }) {\n    this.longitude = geographyPoint.longitude;\n    this.latitude = geographyPoint.latitude;\n  }\n\n  /**\n   * Used to serialize to a GeoJSON Point.\n   */\n  public toJSON(): Record<string, unknown> {\n    return {\n      type: \"Point\",\n      coordinates: [this.longitude, this.latitude],\n      crs: { type: \"name\", properties: { name: WorldGeodeticSystem1984 } },\n    };\n  }\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;AAElC,MAAM,uBAAuB,GAAG,WAAW,CAAC,CAAC,2BAA2B;AAK1D,MAAO,cAAc;IAUjC;;;;OAIG,CACH,YAAY,cAAuD,CAAA;QACjE,IAAI,CAAC,SAAS,GAAG,cAAc,CAAC,SAAS,CAAC;QAC1C,IAAI,CAAC,QAAQ,GAAG,cAAc,CAAC,QAAQ,CAAC;IAC1C,CAAC;IAED;;OAEG,CACI,MAAM,GAAA;QACX,OAAO;YACL,IAAI,EAAE,OAAO;YACb,WAAW,EAAE;gBAAC,IAAI,CAAC,SAAS;gBAAE,IAAI,CAAC,QAAQ;aAAC;YAC5C,GAAG,EAAE;gBAAE,IAAI,EAAE,MAAM;gBAAE,UAAU,EAAE;oBAAE,IAAI,EAAE,uBAAuB;gBAAA,CAAE;YAAA,CAAE;SACrE,CAAC;IACJ,CAAC;CACF","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2622, "column": 0}, "map": {"version":3,"file":"walk.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/walk.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport { isDefined } from \"@azure/core-util\";\n\nexport function walk(v: unknown, fn: <T>(val: T) => unknown): unknown {\n  const seen = new Set();\n  const mutated = new Map();\n  deepLazyApply(v);\n  for (const value of mutated.values()) {\n    replaceChildren(value);\n  }\n  return mutated.get(v) ?? v;\n\n  function deepLazyApply(value: unknown): void {\n    if (seen.has(value)) {\n      return;\n    }\n    seen.add(value);\n\n    const children = getChildren(cachedApply(value) ?? value);\n    children?.forEach(deepLazyApply);\n    if (children?.some((node) => mutated.has(node))) {\n      mutated.set(value, mutated.get(value) ?? shallowCopy(value));\n    }\n  }\n\n  function cachedApply(value: unknown): unknown | undefined {\n    const cached = mutated.get(value);\n    if (isDefined(cached)) {\n      return cached;\n    }\n    const applied = fn(value);\n    if (value !== applied) {\n      mutated.set(value, applied);\n    }\n    return mutated.get(value);\n  }\n\n  function replaceChildren(applied: unknown): void {\n    if (!isComplex(applied)) {\n      return;\n    } else if (Array.isArray(applied)) {\n      applied.forEach((e, i) => {\n        applied[i] = mutated.get(e) ?? e;\n      });\n    } else if (typeof applied === \"object\" && applied !== null) {\n      Object.keys(applied).forEach((key) => {\n        (applied as any)[key] = mutated.get((applied as any)[key]) ?? (applied as any)[key];\n      });\n    }\n  }\n}\n\n/**\n * Array inputs SHOULD not have both complex and non-complex elements. This function determines\n * whether an array is complex based solely on the first element.\n */\nfunction isComplex(v: unknown): v is object {\n  return Array.isArray(v) ? isComplex(v[0]) : typeof v === \"object\" && v !== null;\n}\n\nfunction getChildren(v: unknown): unknown[] | undefined {\n  if (!isComplex(v)) {\n    return;\n  }\n\n  if (Array.isArray(v)) {\n    return v;\n  }\n\n  return Object.values(v);\n}\n\nfunction shallowCopy(value: unknown): unknown {\n  const maybeCopy = Array.isArray(value)\n    ? value.map((v) => v)\n    : typeof value === \"object\" && value !== null\n      ? { ...value }\n      : value;\n\n  return value === maybeCopy\n    ? value\n    : Object.setPrototypeOf(maybeCopy, Object.getPrototypeOf(value));\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;;AAElC,OAAO,EAAE,SAAS,EAAE,MAAM,kBAAkB,CAAC;;AAEvC,SAAU,IAAI,CAAC,CAAU,EAAE,EAA0B;;IACzD,MAAM,IAAI,GAAG,IAAI,GAAG,EAAE,CAAC;IACvB,MAAM,OAAO,GAAG,IAAI,GAAG,EAAE,CAAC;IAC1B,aAAa,CAAC,CAAC,CAAC,CAAC;IACjB,KAAK,MAAM,KAAK,IAAI,OAAO,CAAC,MAAM,EAAE,CAAE,CAAC;QACrC,eAAe,CAAC,KAAK,CAAC,CAAC;IACzB,CAAC;IACD,OAAO,CAAA,KAAA,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,CAAC,CAAC;;IAE3B,SAAS,aAAa,CAAC,KAAc;;QACnC,IAAI,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC;YACpB,OAAO;QACT,CAAC;QACD,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;QAEhB,MAAM,QAAQ,GAAG,WAAW,CAAC,CAAA,KAAA,WAAW,CAAC,KAAK,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK,CAAC,CAAC;QAC1D,QAAQ,KAAA,QAAR,QAAQ,KAAA,KAAA,IAAA,KAAA,IAAR,QAAQ,CAAE,OAAO,CAAC,aAAa,CAAC,CAAC;QACjC,IAAI,QAAQ,KAAA,QAAR,QAAQ,KAAA,KAAA,IAAA,KAAA,IAAR,QAAQ,CAAE,IAAI,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,MAAQ,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC;YAChD,OAAO,CAAC,GAAG,CAAC,KAAK,EAAE,CAAA,KAAA,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC;QAC/D,CAAC;IACH,CAAC;IAED,SAAS,WAAW,CAAC,KAAc;QACjC,MAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;QAClC,+KAAI,YAAA,AAAS,EAAC,MAAM,CAAC,EAAE,CAAC;YACtB,OAAO,MAAM,CAAC;QAChB,CAAC;QACD,MAAM,OAAO,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC;QAC1B,IAAI,KAAK,KAAK,OAAO,EAAE,CAAC;YACtB,OAAO,CAAC,GAAG,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;QAC9B,CAAC;QACD,OAAO,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;IAC5B,CAAC;IAED,SAAS,eAAe,CAAC,OAAgB;QACvC,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,EAAE,CAAC;YACxB,OAAO;QACT,CAAC,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE,CAAC;YAClC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;;gBACvB,OAAO,CAAC,CAAC,CAAC,GAAG,CAAA,KAAA,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,CAAC,CAAC;YACnC,CAAC,CAAC,CAAC;QACL,CAAC,MAAM,IAAI,OAAO,OAAO,KAAK,QAAQ,IAAI,OAAO,KAAK,IAAI,EAAE,CAAC;YAC3D,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,OAAO,CAAC,CAAC,GAAG,EAAE,EAAE;;gBAClC,OAAe,CAAC,GAAG,CAAC,GAAG,CAAA,KAAA,OAAO,CAAC,GAAG,CAAE,OAAe,CAAC,GAAG,CAAC,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAK,OAAe,CAAC,GAAG,CAAC,CAAC;YACtF,CAAC,CAAC,CAAC;QACL,CAAC;IACH,CAAC;AACH,CAAC;AAED;;;GAGG,CACH,SAAS,SAAS,CAAC,CAAU;IAC3B,OAAO,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,QAAQ,IAAI,CAAC,KAAK,IAAI,CAAC;AAClF,CAAC;AAED,SAAS,WAAW,CAAC,CAAU;IAC7B,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,EAAE,CAAC;QAClB,OAAO;IACT,CAAC;IAED,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC;QACrB,OAAO,CAAC,CAAC;IACX,CAAC;IAED,OAAO,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;AAC1B,CAAC;AAED,SAAS,WAAW,CAAC,KAAc;IACjC,MAAM,SAAS,GAAG,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,GAClC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAG,CAAD,AAAE,CAAC,GACnB,OAAO,KAAK,KAAK,QAAQ,IAAI,KAAK,KAAK,IAAI,GAC1C,OAAA,MAAA,CAAA,CAAA,GAAM,KAAK,EACZ,CAAC,CAAC,KAAK,CAAC;IAEZ,OAAO,KAAK,KAAK,SAAS,GACtB,KAAK,GACL,MAAM,CAAC,cAAc,CAAC,SAAS,EAAE,MAAM,CAAC,cAAc,CAAC,KAAK,CAAC,CAAC,CAAC;AACrE,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2704, "column": 0}, "map": {"version":3,"file":"serialization.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/serialization.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport GeographyPoint from \"./geographyPoint\";\nimport { walk } from \"./walk\";\n\nconst ISO8601DateRegex = /^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(\\.\\d{1,3})?Z$/i;\nconst GeoJSONPointTypeName = \"Point\";\nconst WorldGeodeticSystem1984 = \"EPSG:4326\"; // See https://epsg.io/4326\n\nconst [serializeValue, deserializeValue] = [\n  [serializeSpecialNumbers, serializeDates, serializeGeoPoint],\n  [deserializeSpecialNumbers, deserializeDates, deserializeGeoPoint],\n].map(\n  (fns) =>\n    (value: unknown): unknown =>\n      fns.reduceRight((acc, fn) => fn(acc), value),\n);\n\nexport function serialize<OutputT>(obj: unknown): OutputT {\n  return walk(obj, serializeValue) as OutputT;\n}\n\nexport function deserialize<OutputT>(obj: unknown): OutputT {\n  return walk(obj, deserializeValue) as OutputT;\n}\n\nfunction serializeSpecialNumbers(input: unknown): unknown {\n  if (typeof input === \"number\" && isNaN(input)) {\n    return \"NaN\";\n  } else if (input === Infinity) {\n    return \"INF\";\n  } else if (input === -Infinity) {\n    return \"-INF\";\n  } else {\n    return input;\n  }\n}\n\nfunction serializeDates(input: unknown): string | unknown {\n  return input instanceof Date ? input.toISOString() : input;\n}\n\nfunction serializeGeoPoint(input: unknown): object | unknown {\n  return input instanceof GeographyPoint ? input.toJSON() : input;\n}\n\nfunction deserializeSpecialNumbers(input: unknown): unknown {\n  switch (input) {\n    case \"NaN\":\n      return NaN;\n    case \"-INF\":\n      return -Infinity;\n    case \"INF\":\n      return Infinity;\n    default:\n      return input;\n  }\n}\n\nfunction deserializeDates(input: unknown): Date | unknown {\n  return typeof input === \"string\" && ISO8601DateRegex.test(input) ? new Date(input) : input;\n}\n\nfunction deserializeGeoPoint(input: unknown): GeographyPoint | unknown {\n  if (isGeoJSONPoint(input)) {\n    const [longitude, latitude] = input.coordinates;\n    return new GeographyPoint({ longitude, latitude });\n  }\n  return input;\n}\n\ninterface GeoJSONPoint {\n  type: \"Point\";\n  coordinates: [number, number];\n  crs: {\n    type: \"name\";\n    properties: {\n      name: \"EPSG:4326\";\n    };\n  };\n}\n\nfunction isGeoJSONPoint(obj: any): obj is GeoJSONPoint {\n  const requiredKeys = [\"type\", \"coordinates\"];\n  return isValidObject(obj, {\n    requiredKeys,\n    propertyValidator: (key) => {\n      switch (key) {\n        case \"type\":\n          return obj.type === GeoJSONPointTypeName;\n          break;\n        case \"coordinates\":\n          return isCoordinateArray(obj.coordinates);\n          break;\n        case \"crs\":\n          return isCrs(obj.crs);\n          break;\n        default:\n          return false;\n      }\n    },\n  });\n}\n\nfunction isCoordinateArray(maybeCoordinates: any): boolean {\n  if (!Array.isArray(maybeCoordinates)) {\n    return false;\n  }\n  if (maybeCoordinates.length !== 2) {\n    return false;\n  }\n  if (typeof maybeCoordinates[0] !== \"number\" || typeof maybeCoordinates[1] !== \"number\") {\n    return false;\n  }\n  return true;\n}\n\nfunction isCrs(maybeCrs: any): boolean {\n  return isValidObject(maybeCrs, {\n    requiredKeys: [\"type\", \"properties\"],\n    propertyValidator: (key) => {\n      switch (key) {\n        case \"type\":\n          return maybeCrs.type === \"name\";\n          break;\n        case \"properties\":\n          return isCrsProperties(maybeCrs.properties);\n          break;\n        default:\n          return false;\n      }\n    },\n  });\n}\n\nfunction isCrsProperties(maybeProperties: any): boolean {\n  return isValidObject(maybeProperties, {\n    requiredKeys: [\"name\"],\n    propertyValidator: (key) => {\n      if (key === \"name\") {\n        return maybeProperties.name === WorldGeodeticSystem1984;\n      } else {\n        return false;\n      }\n    },\n  });\n}\n\nfunction isValidObject(\n  obj: any,\n  options: {\n    requiredKeys?: string[];\n    propertyValidator?: (keyName: string) => boolean;\n  } = {},\n): boolean {\n  if (typeof obj !== \"object\" || obj === null) {\n    return false;\n  }\n\n  const keys = Object.keys(obj);\n\n  if (options.requiredKeys) {\n    for (const requiredKey of options.requiredKeys) {\n      if (!keys.includes(requiredKey)) {\n        return false;\n      }\n    }\n  }\n\n  if (options.propertyValidator) {\n    for (const key of keys) {\n      if (!options.propertyValidator(key)) {\n        return false;\n      }\n    }\n  }\n\n  return true;\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;;AAElC,OAAO,cAAc,MAAM,kBAAkB,CAAC;AAC9C,OAAO,EAAE,IAAI,EAAE,MAAM,QAAQ,CAAC;;;AAE9B,MAAM,gBAAgB,GAAG,qDAAqD,CAAC;AAC/E,MAAM,oBAAoB,GAAG,OAAO,CAAC;AACrC,MAAM,uBAAuB,GAAG,WAAW,CAAC,CAAC,2BAA2B;AAExE,MAAM,CAAC,cAAc,EAAE,gBAAgB,CAAC,GAAG;IACzC;QAAC,uBAAuB;QAAE,cAAc;QAAE,iBAAiB;KAAC;IAC5D;QAAC,yBAAyB;QAAE,gBAAgB;QAAE,mBAAmB;KAAC;CACnE,CAAC,GAAG,CACH,CAAC,GAAG,EAAE,CACJ,CADM,AACL,KAAc,EAAW,CACxB,CAD0B,EACvB,CAAC,WAAW,CAAC,CAAC,GAAG,EAAE,EAAE,EAAE,CAAG,CAAD,CAAG,CAAC,GAAG,CAAC,EAAE,KAAK,CAAC,CACjD,CAAC;AAEI,SAAU,SAAS,CAAU,GAAY;IAC7C,0LAAO,OAAA,AAAI,EAAC,GAAG,EAAE,cAAc,CAAY,CAAC;AAC9C,CAAC;AAEK,SAAU,WAAW,CAAU,GAAY;IAC/C,0LAAO,OAAA,AAAI,EAAC,GAAG,EAAE,gBAAgB,CAAY,CAAC;AAChD,CAAC;AAED,SAAS,uBAAuB,CAAC,KAAc;IAC7C,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI,KAAK,CAAC,KAAK,CAAC,EAAE,CAAC;QAC9C,OAAO,KAAK,CAAC;IACf,CAAC,MAAM,IAAI,KAAK,KAAK,QAAQ,EAAE,CAAC;QAC9B,OAAO,KAAK,CAAC;IACf,CAAC,MAAM,IAAI,KAAK,KAAK,CAAC,QAAQ,EAAE,CAAC;QAC/B,OAAO,MAAM,CAAC;IAChB,CAAC,MAAM,CAAC;QACN,OAAO,KAAK,CAAC;IACf,CAAC;AACH,CAAC;AAED,SAAS,cAAc,CAAC,KAAc;IACpC,OAAO,KAAK,YAAY,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC;AAC7D,CAAC;AAED,SAAS,iBAAiB,CAAC,KAAc;IACvC,OAAO,KAAK,qMAAY,UAAc,CAAC,CAAC,CAAC,KAAK,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC;AAClE,CAAC;AAED,SAAS,yBAAyB,CAAC,KAAc;IAC/C,OAAQ,KAAK,EAAE,CAAC;QACd,KAAK,KAAK;YACR,OAAO,GAAG,CAAC;QACb,KAAK,MAAM;YACT,OAAO,CAAC,QAAQ,CAAC;QACnB,KAAK,KAAK;YACR,OAAO,QAAQ,CAAC;QAClB;YACE,OAAO,KAAK,CAAC;IACjB,CAAC;AACH,CAAC;AAED,SAAS,gBAAgB,CAAC,KAAc;IACtC,OAAO,OAAO,KAAK,KAAK,QAAQ,IAAI,gBAAgB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,IAAI,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;AAC7F,CAAC;AAED,SAAS,mBAAmB,CAAC,KAAc;IACzC,IAAI,cAAc,CAAC,KAAK,CAAC,EAAE,CAAC;QAC1B,MAAM,CAAC,SAAS,EAAE,QAAQ,CAAC,GAAG,KAAK,CAAC,WAAW,CAAC;QAChD,OAAO,4LAAI,WAAc,CAAC;YAAE,SAAS;YAAE,QAAQ;QAAA,CAAE,CAAC,CAAC;IACrD,CAAC;IACD,OAAO,KAAK,CAAC;AACf,CAAC;AAaD,SAAS,cAAc,CAAC,GAAQ;IAC9B,MAAM,YAAY,GAAG;QAAC,MAAM;QAAE,aAAa;KAAC,CAAC;IAC7C,OAAO,aAAa,CAAC,GAAG,EAAE;QACxB,YAAY;QACZ,iBAAiB,EAAE,CAAC,GAAG,EAAE,EAAE;YACzB,OAAQ,GAAG,EAAE,CAAC;gBACZ,KAAK,MAAM;oBACT,OAAO,GAAG,CAAC,IAAI,KAAK,oBAAoB,CAAC;;gBAE3C,KAAK,aAAa;oBAChB,OAAO,iBAAiB,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC;;gBAE5C,KAAK,KAAK;oBACR,OAAO,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;;gBAExB;oBACE,OAAO,KAAK,CAAC;YACjB,CAAC;QACH,CAAC;KACF,CAAC,CAAC;AACL,CAAC;AAED,SAAS,iBAAiB,CAAC,gBAAqB;IAC9C,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,gBAAgB,CAAC,EAAE,CAAC;QACrC,OAAO,KAAK,CAAC;IACf,CAAC;IACD,IAAI,gBAAgB,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;QAClC,OAAO,KAAK,CAAC;IACf,CAAC;IACD,IAAI,OAAO,gBAAgB,CAAC,CAAC,CAAC,KAAK,QAAQ,IAAI,OAAO,gBAAgB,CAAC,CAAC,CAAC,KAAK,QAAQ,EAAE,CAAC;QACvF,OAAO,KAAK,CAAC;IACf,CAAC;IACD,OAAO,IAAI,CAAC;AACd,CAAC;AAED,SAAS,KAAK,CAAC,QAAa;IAC1B,OAAO,aAAa,CAAC,QAAQ,EAAE;QAC7B,YAAY,EAAE;YAAC,MAAM;YAAE,YAAY;SAAC;QACpC,iBAAiB,EAAE,CAAC,GAAG,EAAE,EAAE;YACzB,OAAQ,GAAG,EAAE,CAAC;gBACZ,KAAK,MAAM;oBACT,OAAO,QAAQ,CAAC,IAAI,KAAK,MAAM,CAAC;;gBAElC,KAAK,YAAY;oBACf,OAAO,eAAe,CAAC,QAAQ,CAAC,UAAU,CAAC,CAAC;;gBAE9C;oBACE,OAAO,KAAK,CAAC;YACjB,CAAC;QACH,CAAC;KACF,CAAC,CAAC;AACL,CAAC;AAED,SAAS,eAAe,CAAC,eAAoB;IAC3C,OAAO,aAAa,CAAC,eAAe,EAAE;QACpC,YAAY,EAAE;YAAC,MAAM;SAAC;QACtB,iBAAiB,EAAE,CAAC,GAAG,EAAE,EAAE;YACzB,IAAI,GAAG,KAAK,MAAM,EAAE,CAAC;gBACnB,OAAO,eAAe,CAAC,IAAI,KAAK,uBAAuB,CAAC;YAC1D,CAAC,MAAM,CAAC;gBACN,OAAO,KAAK,CAAC;YACf,CAAC;QACH,CAAC;KACF,CAAC,CAAC;AACL,CAAC;AAED,SAAS,aAAa,CACpB,GAAQ,EACR,UAGI,CAAA,CAAE;IAEN,IAAI,OAAO,GAAG,KAAK,QAAQ,IAAI,GAAG,KAAK,IAAI,EAAE,CAAC;QAC5C,OAAO,KAAK,CAAC;IACf,CAAC;IAED,MAAM,IAAI,GAAG,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;IAE9B,IAAI,OAAO,CAAC,YAAY,EAAE,CAAC;QACzB,KAAK,MAAM,WAAW,IAAI,OAAO,CAAC,YAAY,CAAE,CAAC;YAC/C,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,EAAE,CAAC;gBAChC,OAAO,KAAK,CAAC;YACf,CAAC;QACH,CAAC;IACH,CAAC;IAED,IAAI,OAAO,CAAC,iBAAiB,EAAE,CAAC;QAC9B,KAAK,MAAM,GAAG,IAAI,IAAI,CAAE,CAAC;YACvB,IAAI,CAAC,OAAO,CAAC,iBAAiB,CAAC,GAAG,CAAC,EAAE,CAAC;gBACpC,OAAO,KAAK,CAAC;YACf,CAAC;QACH,CAAC;IACH,CAAC;IAED,OAAO,IAAI,CAAC;AACd,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2874, "column": 0}, "map": {"version":3,"file":"serviceModels.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/serviceModels.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport { OperationOptions } from \"@azure/core-client\";\nimport { PagedAsyncIterableIterator } from \"@azure/core-paging\";\nimport {\n  AsciiFoldingTokenFilter,\n  AzureOpenAIModelName,\n  BinaryQuantizationCompression,\n  BM25Similarity,\n  CharFilterName,\n  CjkBigramTokenFilter,\n  ClassicSimilarity,\n  ClassicTokenizer,\n  CognitiveServicesAccountKey,\n  CommonGramTokenFilter,\n  ConditionalSkill,\n  CorsOptions,\n  CustomEntity,\n  DefaultCognitiveServicesAccount,\n  DictionaryDecompounderTokenFilter,\n  DistanceScoringFunction,\n  DocumentExtractionSkill,\n  EdgeNGramTokenFilterSide,\n  EdgeNGramTokenizer,\n  ElisionTokenFilter,\n  EntityLinkingSkill,\n  EntityRecognitionSkillV3,\n  FieldMapping,\n  FreshnessScoringFunction,\n  HighWaterMarkChangeDetectionPolicy,\n  IndexingSchedule,\n  IndexProjectionMode,\n  KeepTokenFilter,\n  KeywordMarkerTokenFilter,\n  KnownBlobIndexerDataToExtract,\n  KnownBlobIndexerImageAction,\n  KnownBlobIndexerParsingMode,\n  KnownBlobIndexerPDFTextRotationAlgorithm,\n  KnownCharFilterName,\n  KnownCustomEntityLookupSkillLanguage,\n  KnownEntityCategory,\n  KnownEntityRecognitionSkillLanguage,\n  KnownImageAnalysisSkillLanguage,\n  KnownImageDetail,\n  KnownIndexerExecutionEnvironment,\n  KnownKeyPhraseExtractionSkillLanguage,\n  KnownLexicalAnalyzerName,\n  KnownLexicalTokenizerName,\n  KnownOcrSkillLanguage,\n  KnownPIIDetectionSkillMaskingMode,\n  KnownRegexFlags,\n  KnownSearchFieldDataType,\n  KnownSearchIndexerDataSourceType,\n  KnownSentimentSkillLanguage,\n  KnownSplitSkillLanguage,\n  KnownTextSplitMode,\n  KnownTextTranslationSkillLanguage,\n  KnownTokenFilterName,\n  KnownVectorSearchAlgorithmKind,\n  KnownVectorSearchAlgorithmMetric,\n  KnownVisualFeature,\n  LanguageDetectionSkill,\n  LengthTokenFilter,\n  LexicalAnalyzerName,\n  LexicalTokenizerName,\n  LimitTokenFilter,\n  LuceneStandardAnalyzer,\n  MagnitudeScoringFunction,\n  MappingCharFilter,\n  MergeSkill,\n  MicrosoftLanguageStemmingTokenizer,\n  MicrosoftLanguageTokenizer,\n  NGramTokenizer,\n  PathHierarchyTokenizerV2 as PathHierarchyTokenizer,\n  PatternCaptureTokenFilter,\n  PatternReplaceCharFilter,\n  PatternReplaceTokenFilter,\n  PhoneticTokenFilter,\n  ScalarQuantizationCompression,\n  ScoringFunctionAggregation,\n  SearchIndexerDataContainer,\n  SearchIndexerDataNoneIdentity,\n  SearchIndexerDataUserAssignedIdentity,\n  SearchIndexerIndexProjectionSelector,\n  SearchIndexerKnowledgeStoreProjection,\n  SearchIndexerSkill as BaseSearchIndexerSkill,\n  SemanticSearch,\n  SentimentSkillV3,\n  ServiceCounters,\n  ServiceLimits,\n  ShaperSkill,\n  ShingleTokenFilter,\n  SnowballTokenFilter,\n  SoftDeleteColumnDeletionDetectionPolicy,\n  SqlIntegratedChangeTrackingPolicy,\n  StemmerOverrideTokenFilter,\n  StemmerTokenFilter,\n  StopAnalyzer,\n  StopwordsTokenFilter,\n  Suggester as SearchSuggester,\n  SynonymTokenFilter,\n  TagScoringFunction,\n  TextWeights,\n  TokenFilterName,\n  TruncateTokenFilter,\n  UaxUrlEmailTokenizer,\n  UniqueTokenFilter,\n  VectorEncodingFormat,\n  VectorSearchProfile,\n  VectorSearchVectorizerKind,\n  WordDelimiterTokenFilter,\n} from \"./generated/service/models\";\n\n/**\n * Options for a list skillsets operation.\n */\nexport type ListSkillsetsOptions = OperationOptions;\n\n/**\n * Options for a list synonymMaps operation.\n */\nexport type ListSynonymMapsOptions = OperationOptions;\n\n/**\n * Options for a list indexes operation.\n */\nexport type ListIndexesOptions = OperationOptions;\n\n/**\n * Options for a list indexers operation.\n */\nexport type ListIndexersOptions = OperationOptions;\n\n/**\n * Options for a list data sources operation.\n */\nexport type ListDataSourceConnectionsOptions = OperationOptions;\n\n/**\n * Options for get index operation.\n */\nexport type GetIndexOptions = OperationOptions;\n\n/**\n * Options for get skillset operation.\n */\nexport type GetSkillSetOptions = OperationOptions;\n\n/**\n * Options for get synonymmaps operation.\n */\nexport type GetSynonymMapsOptions = OperationOptions;\n\n/**\n * Options for get indexer operation.\n */\nexport type GetIndexerOptions = OperationOptions;\n\n/**\n * Options for get datasource operation.\n */\nexport type GetDataSourceConnectionOptions = OperationOptions;\n\n/**\n * Options for get index statistics operation.\n */\nexport type GetIndexStatisticsOptions = OperationOptions;\n\n/**\n * Statistics for a given index. Statistics are collected periodically and are not guaranteed to\n * always be up-to-date.\n */\nexport interface SearchIndexStatistics {\n  /**\n   * The number of documents in the index.\n   * **NOTE: This property will not be serialized. It can only be populated by the server.**\n   */\n  readonly documentCount: number;\n  /**\n   * The amount of storage in bytes consumed by the index.\n   * **NOTE: This property will not be serialized. It can only be populated by the server.**\n   */\n  readonly storageSize: number;\n  /**\n   * The amount of memory in bytes consumed by vectors in the index.\n   * NOTE: This property will not be serialized. It can only be populated by the server.\n   */\n  readonly vectorIndexSize: number;\n}\n\n/**\n * Response from a get service statistics request. If successful, it includes service level\n * counters and limits.\n */\nexport interface SearchServiceStatistics {\n  /**\n   * Service level resource counters.\n   */\n  counters: ServiceCounters;\n  /**\n   * Service level general limits.\n   */\n  limits: ServiceLimits;\n}\n\n/**\n * Options for get service statistics operation.\n */\nexport type GetServiceStatisticsOptions = OperationOptions;\n\n/**\n * Options for get indexer status operation.\n */\nexport type GetIndexerStatusOptions = OperationOptions;\n\n/**\n * Options for reset indexer operation.\n */\nexport type ResetIndexerOptions = OperationOptions;\n\n/**\n * Options for run indexer operation.\n */\nexport type RunIndexerOptions = OperationOptions;\n\n/**\n * Options for create index operation.\n */\nexport type CreateIndexOptions = OperationOptions;\n\n/**\n * Options for create skillset operation.\n */\nexport type CreateSkillsetOptions = OperationOptions;\n\n/**\n * Options for create alias operation.\n */\nexport type CreateAliasOptions = OperationOptions;\n\n/**\n * Options for create or update alias operation.\n */\nexport interface CreateOrUpdateAliasOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be deleted only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for delete alias operation.\n */\nexport interface DeleteAliasOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be deleted only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for get alias operation.\n */\nexport type GetAliasOptions = OperationOptions;\n\n/**\n * Options for list aliases operation.\n */\nexport type ListAliasesOptions = OperationOptions;\n\n/**\n * Options for create synonymmap operation.\n */\nexport type CreateSynonymMapOptions = OperationOptions;\n\n/**\n * Options for create indexer operation.\n */\nexport type CreateIndexerOptions = OperationOptions;\n\n/**\n * Options for create datasource operation.\n */\nexport type CreateDataSourceConnectionOptions = OperationOptions;\n\n/**\n * Options for create/update index operation.\n */\nexport interface CreateOrUpdateIndexOptions extends OperationOptions {\n  /**\n   * Allows new analyzers, tokenizers, token filters, or char filters to be added to an index by\n   * taking the index offline for at least a few seconds. This temporarily causes indexing and\n   * query requests to fail. Performance and write availability of the index can be impaired for\n   * several minutes after the index is updated, or longer for very large indexes.\n   */\n  allowIndexDowntime?: boolean;\n  /**\n   * If set to true, Resource will be deleted only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for reset docs operation.\n */\nexport interface ResetDocumentsOptions extends OperationOptions {\n  /** document keys to be reset */\n  documentKeys?: string[];\n  /** datasource document identifiers to be reset */\n  datasourceDocumentIds?: string[];\n  /** If false, keys or ids will be appended to existing ones. If true, only the keys or ids in this payload will be queued to be re-ingested. */\n  overwrite?: boolean;\n}\n\n/**\n * Options for reset skills operation.\n */\nexport interface ResetSkillsOptions extends OperationOptions {\n  /** the names of skills to be reset. */\n  skillNames?: string[];\n}\n\n/**\n * Options for create/update skillset operation.\n */\nexport interface CreateOrUpdateSkillsetOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be updated only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for create/update synonymmap operation.\n */\nexport interface CreateOrUpdateSynonymMapOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be updated only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for create/update indexer operation.\n */\nexport interface CreateorUpdateIndexerOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be updated only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for create/update datasource operation.\n */\nexport interface CreateorUpdateDataSourceConnectionOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be updated only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for delete index operation.\n */\nexport interface DeleteIndexOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be deleted only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for delete skillset operaion.\n */\nexport interface DeleteSkillsetOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be deleted only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for delete synonymmap operation.\n */\nexport interface DeleteSynonymMapOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be deleted only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for delete indexer operation.\n */\nexport interface DeleteIndexerOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be deleted only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Options for delete datasource operation.\n */\nexport interface DeleteDataSourceConnectionOptions extends OperationOptions {\n  /**\n   * If set to true, Resource will be deleted only if the etag matches.\n   */\n  onlyIfUnchanged?: boolean;\n}\n\n/**\n * Specifies some text and analysis components used to break that text into tokens.\n */\nexport interface AnalyzeRequest {\n  /**\n   * The text to break into tokens.\n   */\n  text: string;\n  /**\n   * The name of the analyzer to use to break the given text. If this parameter is not specified,\n   * you must specify a tokenizer instead. The tokenizer and analyzer parameters are mutually\n   * exclusive. {@link KnownAnalyzerNames} is an enum containing built-in analyzer names.\n   * NOTE: Either analyzerName or tokenizerName is required in an AnalyzeRequest.\n   */\n  analyzerName?: LexicalAnalyzerName;\n  /**\n   * The name of the tokenizer to use to break the given text. If this parameter is not specified,\n   * you must specify an analyzer instead. The tokenizer and analyzer parameters are mutually\n   * exclusive. {@link KnownTokenizerNames} is an enum containing built-in tokenizer names.\n   * NOTE: Either analyzerName or tokenizerName is required in an AnalyzeRequest.\n   */\n  tokenizerName?: LexicalTokenizerName;\n  /**\n   * An optional list of token filters to use when breaking the given text. This parameter can only\n   * be set when using the tokenizer parameter.\n   */\n  tokenFilters?: TokenFilterName[];\n  /**\n   * An optional list of character filters to use when breaking the given text. This parameter can\n   * only be set when using the tokenizer parameter.\n   */\n  charFilters?: CharFilterName[];\n}\n\n/**\n * Options for analyze text operation.\n */\nexport type AnalyzeTextOptions = OperationOptions & AnalyzeRequest;\n\n// BEGIN manually modified generated interfaces\n//\n// This section is for places where we have to manually fix issues\n// with interfaces from the generated code.\n// One issue is that unions of discriminated types generated with\n// their abstract base class as a member.\n\n/**\n * Flexibly separates text into terms via a regular expression pattern. This analyzer is\n * implemented using Apache Lucene.\n */\nexport interface PatternAnalyzer {\n  /**\n   * Polymorphic Discriminator\n   */\n  odatatype: \"#Microsoft.Azure.Search.PatternAnalyzer\";\n  /**\n   * The name of the analyzer. It must only contain letters, digits, spaces, dashes or underscores,\n   * can only start and end with alphanumeric characters, and is limited to 128 characters.\n   */\n  name: string;\n  /**\n   * A value indicating whether terms should be lower-cased. Default is true. Default value: true.\n   */\n  lowerCaseTerms?: boolean;\n  /**\n   * A regular expression pattern to match token separators. Default is an expression that matches\n   * one or more whitespace characters. Default value: `\\W+`.\n   */\n  pattern?: string;\n  /**\n   * Regular expression flags. Possible values include: 'CANON_EQ', 'CASE_INSENSITIVE', 'COMMENTS',\n   * 'DOTALL', 'LITERAL', 'MULTILINE', 'UNICODE_CASE', 'UNIX_LINES'\n   */\n  flags?: RegexFlags[];\n  /**\n   * A list of stopwords.\n   */\n  stopwords?: string[];\n}\n\n/**\n * Allows you to take control over the process of converting text into indexable/searchable tokens.\n * It's a user-defined configuration consisting of a single predefined tokenizer and one or more\n * filters. The tokenizer is responsible for breaking text into tokens, and the filters for\n * modifying tokens emitted by the tokenizer.\n */\nexport interface CustomAnalyzer {\n  /**\n   * Polymorphic Discriminator\n   */\n  odatatype: \"#Microsoft.Azure.Search.CustomAnalyzer\";\n  /**\n   * The name of the analyzer. It must only contain letters, digits, spaces, dashes or underscores,\n   * can only start and end with alphanumeric characters, and is limited to 128 characters.\n   */\n  name: string;\n  /**\n   * The name of the tokenizer to use to divide continuous text into a sequence of tokens, such as\n   * breaking a sentence into words. {@link KnownTokenizerNames} is an enum containing built-in tokenizer names.\n   */\n  tokenizerName: LexicalTokenizerName;\n  /**\n   * A list of token filters used to filter out or modify the tokens generated by a tokenizer. For\n   * example, you can specify a lowercase filter that converts all characters to lowercase. The\n   * filters are run in the order in which they are listed.\n   */\n  tokenFilters?: TokenFilterName[];\n  /**\n   * A list of character filters used to prepare input text before it is processed by the\n   * tokenizer. For instance, they can replace certain characters or symbols. The filters are run\n   * in the order in which they are listed.\n   */\n  charFilters?: CharFilterName[];\n}\n\n/**\n * Contains the possible cases for Analyzer.\n */\nexport type LexicalAnalyzer =\n  | CustomAnalyzer\n  | PatternAnalyzer\n  | LuceneStandardAnalyzer\n  | StopAnalyzer;\n\n/**\n * A skill that can call a Web API endpoint, allowing you to extend a skillset by having it call\n * your custom code.\n */\nexport interface WebApiSkill extends BaseSearchIndexerSkill {\n  /**\n   * Polymorphic discriminator, which specifies the different types this object can be\n   */\n  odatatype: \"#Microsoft.Skills.Custom.WebApiSkill\";\n  /**\n   * The url for the Web API.\n   */\n  uri: string;\n  /**\n   * The headers required to make the http request.\n   */\n  httpHeaders?: { [propertyName: string]: string };\n  /**\n   * The method for the http request.\n   */\n  httpMethod?: string;\n  /**\n   * The desired timeout for the request. Default is 30 seconds.\n   */\n  timeout?: string;\n  /**\n   * The desired batch size which indicates number of documents.\n   */\n  batchSize?: number;\n  /**\n   * If set, the number of parallel calls that can be made to the Web API.\n   */\n  degreeOfParallelism?: number;\n  /**\n   * Applies to custom skills that connect to external code in an Azure function or some other\n   * application that provides the transformations. This value should be the application ID\n   * created for the function or app when it was registered with Azure Active Directory. When\n   * specified, the custom skill connects to the function or app using a managed ID (either system\n   * or user-assigned) of the search service and the access token of the function or app, using\n   * this value as the resource id for creating the scope of the access token.\n   */\n  authResourceId?: string;\n  /**\n   * The user-assigned managed identity used for outbound connections. If an authResourceId is\n   * provided and it's not specified, the system-assigned managed identity is used. On updates to\n   * the indexer, if the identity is unspecified, the value remains unchanged. If undefined, the\n   * value of this property is cleared.\n   */\n  authIdentity?: SearchIndexerDataIdentity;\n}\n\n/**\n * Contains the possible cases for Skill.\n */\nexport type SearchIndexerSkill =\n  | AzureOpenAIEmbeddingSkill\n  | ConditionalSkill\n  | CustomEntityLookupSkill\n  | DocumentExtractionSkill\n  | EntityLinkingSkill\n  | EntityRecognitionSkill\n  | EntityRecognitionSkillV3\n  | ImageAnalysisSkill\n  | KeyPhraseExtractionSkill\n  | LanguageDetectionSkill\n  | MergeSkill\n  | OcrSkill\n  | PIIDetectionSkill\n  | SentimentSkill\n  | SentimentSkillV3\n  | ShaperSkill\n  | SplitSkill\n  | TextTranslationSkill\n  | WebApiSkill;\n\n/**\n * Contains the possible cases for CognitiveServicesAccount.\n */\nexport type CognitiveServicesAccount =\n  | DefaultCognitiveServicesAccount\n  | CognitiveServicesAccountKey;\n/**\n * Tokenizer that uses regex pattern matching to construct distinct tokens. This tokenizer is\n * implemented using Apache Lucene.\n */\nexport interface PatternTokenizer {\n  /**\n   * Polymorphic Discriminator\n   */\n  odatatype: \"#Microsoft.Azure.Search.PatternTokenizer\";\n  /**\n   * The name of the tokenizer. It must only contain letters, digits, spaces, dashes or\n   * underscores, can only start and end with alphanumeric characters, and is limited to 128\n   * characters.\n   */\n  name: string;\n  /**\n   * A regular expression pattern to match token separators. Default is an expression that matches\n   * one or more whitespace characters. Default value: `\\W+`.\n   */\n  pattern?: string;\n  /**\n   * Regular expression flags. Possible values include: 'CANON_EQ', 'CASE_INSENSITIVE', 'COMMENTS',\n   * 'DOTALL', 'LITERAL', 'MULTILINE', 'UNICODE_CASE', 'UNIX_LINES'\n   */\n  flags?: RegexFlags[];\n  /**\n   * The zero-based ordinal of the matching group in the regular expression pattern to extract into\n   * tokens. Use -1 if you want to use the entire pattern to split the input into tokens,\n   * irrespective of matching groups. Default is -1. Default value: -1.\n   */\n  group?: number;\n}\n/**\n * Breaks text following the Unicode Text Segmentation rules. This tokenizer is implemented using\n * Apache Lucene.\n */\nexport interface LuceneStandardTokenizer {\n  /**\n   * Polymorphic Discriminator\n   */\n  odatatype:\n    | \"#Microsoft.Azure.Search.StandardTokenizerV2\"\n    | \"#Microsoft.Azure.Search.StandardTokenizer\";\n  /**\n   * The name of the tokenizer. It must only contain letters, digits, spaces, dashes or\n   * underscores, can only start and end with alphanumeric characters, and is limited to 128\n   * characters.\n   */\n  name: string;\n  /**\n   * The maximum token length. Default is 255. Tokens longer than the maximum length are split. The\n   * maximum token length that can be used is 300 characters. Default value: 255.\n   */\n  maxTokenLength?: number;\n}\n\n/**\n * Generates n-grams of the given size(s) starting from the front or the back of an input token.\n * This token filter is implemented using Apache Lucene.\n */\nexport interface EdgeNGramTokenFilter {\n  /**\n   * Polymorphic Discriminator\n   */\n  odatatype:\n    | \"#Microsoft.Azure.Search.EdgeNGramTokenFilterV2\"\n    | \"#Microsoft.Azure.Search.EdgeNGramTokenFilter\";\n  /**\n   * The name of the token filter. It must only contain letters, digits, spaces, dashes or\n   * underscores, can only start and end with alphanumeric characters, and is limited to 128\n   * characters.\n   */\n  name: string;\n  /**\n   * The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of\n   * maxGram. Default value: 1.\n   */\n  minGram?: number;\n  /**\n   * The maximum n-gram length. Default is 2. Maximum is 300. Default value: 2.\n   */\n  maxGram?: number;\n  /**\n   * Specifies which side of the input the n-gram should be generated from. Default is \"front\".\n   * Possible values include: 'Front', 'Back'\n   */\n  side?: EdgeNGramTokenFilterSide;\n}\n\n/**\n * Emits the entire input as a single token. This tokenizer is implemented using Apache Lucene.\n */\nexport interface KeywordTokenizer {\n  /**\n   * Polymorphic Discriminator\n   */\n  odatatype:\n    | \"#Microsoft.Azure.Search.KeywordTokenizerV2\"\n    | \"#Microsoft.Azure.Search.KeywordTokenizer\";\n  /**\n   * The name of the tokenizer. It must only contain letters, digits, spaces, dashes or\n   * underscores, can only start and end with alphanumeric characters, and is limited to 128\n   * characters.\n   */\n  name: string;\n  /**\n   * The maximum token length. Default is 256. Tokens longer than the maximum length are split. The\n   * maximum token length that can be used is 300 characters. Default value: 256.\n   */\n  maxTokenLength?: number;\n}\n\n/**\n * Contains the possible cases for Tokenizer.\n */\nexport type LexicalTokenizer =\n  | ClassicTokenizer\n  | EdgeNGramTokenizer\n  | KeywordTokenizer\n  | MicrosoftLanguageTokenizer\n  | MicrosoftLanguageStemmingTokenizer\n  | NGramTokenizer\n  | PathHierarchyTokenizer\n  | PatternTokenizer\n  | LuceneStandardTokenizer\n  | UaxUrlEmailTokenizer;\n\n/**\n *  Definition of additional projections to azure blob, table, or files, of enriched data.\n */\nexport interface SearchIndexerKnowledgeStore {\n  /**\n   * The connection string to the storage account projections will be stored in.\n   */\n  storageConnectionString: string;\n  /**\n   * A list of additional projections to perform during indexing.\n   */\n  projections: SearchIndexerKnowledgeStoreProjection[];\n  /**\n   * The user-assigned managed identity used for connections to Azure Storage when writing\n   * knowledge store projections. If the connection string indicates an identity (ResourceId) and\n   * it's not specified, the system-assigned managed identity is used. On updates to the indexer,\n   * if the identity is unspecified, the value remains unchanged. If set to \"none\", the value of\n   * this property is cleared.\n   */\n  identity?: SearchIndexerDataIdentity;\n}\n\n/**\n * Contains the possible cases for Similarity.\n */\nexport type SimilarityAlgorithm = ClassicSimilarity | BM25Similarity;\n\n/**\n * Generates n-grams of the given size(s). This token filter is implemented using Apache Lucene.\n */\nexport interface NGramTokenFilter {\n  /**\n   * Polymorphic Discriminator\n   */\n  odatatype:\n    | \"#Microsoft.Azure.Search.NGramTokenFilterV2\"\n    | \"#Microsoft.Azure.Search.NGramTokenFilter\";\n  /**\n   * The name of the token filter. It must only contain letters, digits, spaces, dashes or\n   * underscores, can only start and end with alphanumeric characters, and is limited to 128\n   * characters.\n   */\n  name: string;\n  /**\n   * The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of\n   * maxGram. Default value: 1.\n   */\n  minGram?: number;\n  /**\n   * The maximum n-gram length. Default is 2. Maximum is 300. Default value: 2.\n   */\n  maxGram?: number;\n}\n\n/**\n * Contains the possible cases for TokenFilter.\n */\nexport type TokenFilter =\n  | AsciiFoldingTokenFilter\n  | CjkBigramTokenFilter\n  | CommonGramTokenFilter\n  | DictionaryDecompounderTokenFilter\n  | EdgeNGramTokenFilter\n  | ElisionTokenFilter\n  | KeepTokenFilter\n  | KeywordMarkerTokenFilter\n  | LengthTokenFilter\n  | LimitTokenFilter\n  | NGramTokenFilter\n  | PatternCaptureTokenFilter\n  | PatternReplaceTokenFilter\n  | PhoneticTokenFilter\n  | ShingleTokenFilter\n  | SnowballTokenFilter\n  | StemmerTokenFilter\n  | StemmerOverrideTokenFilter\n  | StopwordsTokenFilter\n  | SynonymTokenFilter\n  | TruncateTokenFilter\n  | UniqueTokenFilter\n  | WordDelimiterTokenFilter;\n\n/**\n * Contains the possible cases for CharFilter.\n */\nexport type CharFilter = MappingCharFilter | PatternReplaceCharFilter;\n\n/**\n * Contains the possible cases for ScoringFunction.\n */\nexport type ScoringFunction =\n  | DistanceScoringFunction\n  | FreshnessScoringFunction\n  | MagnitudeScoringFunction\n  | TagScoringFunction;\n\n/**\n * Defines values for ComplexDataType.\n * Possible values include: 'Edm.ComplexType', 'Collection(Edm.ComplexType)'\n * @readonly\n */\nexport type ComplexDataType = \"Edm.ComplexType\" | \"Collection(Edm.ComplexType)\";\n\n/**\n * Represents a field in an index definition, which describes the name, data type, and search\n * behavior of a field.\n */\nexport type SearchField = SimpleField | ComplexField;\n\n/**\n * Represents a field in an index definition, which describes the name, data type, and search\n * behavior of a field.\n */\nexport interface SimpleField {\n  /**\n   * The name of the field, which must be unique within the fields collection of the index or\n   * parent field.\n   */\n  name: string;\n  /**\n   * The data type of the field.\n   */\n  type: SearchFieldDataType;\n  /**\n   * A value indicating whether the field uniquely identifies documents in the index. Exactly one\n   * top-level field in each index must be chosen as the key field and it must be of type\n   * Edm.String. Key fields can be used to look up documents directly and update or delete specific\n   * documents. Default is false.\n   */\n  key?: boolean;\n  /**\n   * A value indicating whether the field can be returned in a search result. You can disable this\n   * option if you want to use a field (for example, margin) as a filter, sorting, or scoring\n   * mechanism but do not want the field to be visible to the end user. This property must be false\n   * for key fields. This property can be changed on existing fields. Enabling this property does\n   * not cause any increase in index storage requirements. Default is true for vector fields, false\n   * otherwise.\n   */\n  hidden?: boolean;\n  /**\n   * An immutable value indicating whether the field will be persisted separately on disk to be\n   * returned in a search result. You can disable this option if you don't plan to return the field\n   * contents in a search response to save on storage overhead. This can only be set during index\n   * creation and only for vector fields. This property cannot be changed for existing fields or set\n   * as false for new fields. If this property is set as false, the property 'hidden' must be set to\n   * 'true'. This property must be false or unset for key fields, for new fields, and for non-vector\n   * fields. Disabling this property will reduce index storage requirements.\n   */\n  stored?: boolean;\n  /**\n   * A value indicating whether the field is full-text searchable. This means it will undergo\n   * analysis such as word-breaking during indexing. If you set a searchable field to a value like\n   * \"sunny day\", internally it will be split into the individual tokens \"sunny\" and \"day\". This\n   * enables full-text searches for these terms. Fields of type Edm.String or Collection(Edm.String)\n   * are searchable by default. This property must be false for simple fields of other non-string\n   * data types. Note: searchable fields consume extra space\n   * in your index to accommodate additional tokenized versions of the field value for full-text\n   * searches. If you want to save space in your index and you don't need a field to be included in\n   * searches, set searchable to false. Default is false.\n   */\n  searchable?: boolean;\n  /**\n   * A value indicating whether to enable the field to be referenced in $filter queries. filterable\n   * differs from searchable in how strings are handled. Fields of type Edm.String or\n   * Collection(Edm.String) that are filterable do not undergo word-breaking, so comparisons are for\n   * exact matches only. For example, if you set such a field f to \"sunny day\", $filter=f eq 'sunny'\n   * will find no matches, but $filter=f eq 'sunny day' will. Default is false.\n   */\n  filterable?: boolean;\n  /**\n   * A value indicating whether to enable the field to be referenced in $orderby expressions. By\n   * default, the search engine sorts results by score, but in many experiences users will want to\n   * sort by fields in the documents. A simple field can be sortable only if it is single-valued (it\n   * has a single value in the scope of the parent document). Simple collection fields cannot be\n   * sortable, since they are multi-valued. Simple sub-fields of complex collections are also\n   * multi-valued, and therefore cannot be sortable. This is true whether it's an immediate parent\n   * field, or an ancestor field, that's the complex collection. The default is false.\n   *\n   */\n  sortable?: boolean;\n  /**\n   * A value indicating whether to enable the field to be referenced in facet queries. Typically\n   * used in a presentation of search results that includes hit count by category (for example,\n   * search for digital cameras and see hits by brand, by megapixels, by price, and so on). Fields\n   * of type Edm.GeographyPoint or Collection(Edm.GeographyPoint) cannot be facetable. Default is\n   * false.\n   */\n  facetable?: boolean;\n  /**\n   * The name of the analyzer to use for the field. This option can be used only with searchable\n   * fields and it can't be set together with either searchAnalyzer or indexAnalyzer. Once the\n   * analyzer is chosen, it cannot be changed for the field.\n   */\n  analyzerName?: LexicalAnalyzerName;\n  /**\n   * The name of the analyzer used at search time for the field. This option can be used only with\n   * searchable fields. It must be set together with `indexAnalyzerName` and it cannot be set\n   * together with the `analyzerName` option. This property cannot be set to the name of a language\n   * analyzer; use the `analyzerName` property instead if you need a language analyzer. This\n   * analyzer can be updated on an existing field.\n   */\n  searchAnalyzerName?: LexicalAnalyzerName;\n  /**\n   * The name of the analyzer used at indexing time for the field. This option can be used only\n   * with searchable fields. It must be set together with searchAnalyzer and it cannot be set\n   * together with the analyzer option.  This property cannot be set to the name of a language\n   * analyzer; use the analyzer property instead if you need a language analyzer. Once the analyzer\n   * is chosen, it cannot be changed for the field.\n   */\n  indexAnalyzerName?: LexicalAnalyzerName;\n  /**\n   * A list of the names of synonym maps to associate with this field. This option can be used only\n   * with searchable fields. Currently only one synonym map per field is supported. Assigning a\n   * synonym map to a field ensures that query terms targeting that field are expanded at query-time\n   * using the rules in the synonym map. This attribute can be changed on existing fields.\n   */\n  synonymMapNames?: string[];\n  /**\n   * The dimensionality of the vector field.\n   */\n  vectorSearchDimensions?: number;\n  /**\n   * The name of the vector search profile that specifies the algorithm and vectorizer to use when\n   * searching the vector field.\n   */\n  vectorSearchProfileName?: string;\n  /**\n   * The encoding format to interpret the field contents.\n   */\n  vectorEncodingFormat?: VectorEncodingFormat;\n}\n\nexport function isComplexField(field: SearchField): field is ComplexField {\n  return field.type === \"Edm.ComplexType\" || field.type === \"Collection(Edm.ComplexType)\";\n}\n\n/**\n * Represents a field in an index definition, which describes the name, data type, and search\n * behavior of a field.\n */\nexport interface ComplexField {\n  /**\n   * The name of the field, which must be unique within the fields collection of the index or\n   * parent field.\n   */\n  name: string;\n  /**\n   * The data type of the field.\n   * Possible values include: 'Edm.ComplexType','Collection(Edm.ComplexType)'\n   */\n  type: ComplexDataType;\n  /**\n   * A list of sub-fields.\n   */\n  fields?: SearchField[];\n}\n\n/**\n * Represents a synonym map definition.\n */\nexport interface SynonymMap {\n  /**\n   * The name of the synonym map.\n   */\n  name: string;\n  /**\n   * An array of synonym rules in the specified synonym map format.\n   */\n  synonyms: string[];\n  /**\n   * A description of an encryption key that you create in Azure Key Vault. This key is used to\n   * provide an additional level of encryption-at-rest for your data when you want full assurance\n   * that no one, not even Microsoft, can decrypt your data in Azure Cognitive Search. Once you\n   * have encrypted your data, it will always remain encrypted. Azure Cognitive Search will ignore\n   * attempts to set this property to null. You can change this property as needed if you want to\n   * rotate your encryption key; Your data will be unaffected. Encryption with customer-managed\n   * keys is not available for free search services, and is only available for paid services\n   * created on or after January 1, 2019.\n   */\n  encryptionKey?: SearchResourceEncryptionKey;\n  /**\n   * The ETag of the synonym map.\n   */\n  etag?: string;\n}\n\n/**\n * An iterator for listing the indexes that exist in the Search service. Will make requests\n * as needed during iteration. Use .byPage() to make one request to the server\n * per iteration.\n */\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport type IndexIterator = PagedAsyncIterableIterator<SearchIndex, SearchIndex[], {}>;\n\n/**\n * An iterator for listing the indexes that exist in the Search service. Will make requests\n * as needed during iteration. Use .byPage() to make one request to the server\n * per iteration.\n */\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport type IndexNameIterator = PagedAsyncIterableIterator<string, string[], {}>;\n\n/**\n * Represents a search index definition, which describes the fields and search behavior of an\n * index.\n */\nexport interface SearchIndex {\n  /**\n   * The name of the index.\n   */\n  name: string;\n  /**\n   * The fields of the index.\n   */\n  fields: SearchField[];\n  /**\n   * The scoring profiles for the index.\n   */\n  scoringProfiles?: ScoringProfile[];\n  /**\n   * The name of the scoring profile to use if none is specified in the query. If this property is\n   * not set and no scoring profile is specified in the query, then default scoring (tf-idf) will\n   * be used.\n   */\n  defaultScoringProfile?: string;\n  /**\n   * Options to control Cross-Origin Resource Sharing (CORS) for the index.\n   */\n  corsOptions?: CorsOptions;\n  /**\n   * The suggesters for the index.\n   */\n  suggesters?: SearchSuggester[];\n  /**\n   * The analyzers for the index.\n   */\n  analyzers?: LexicalAnalyzer[];\n  /**\n   * The tokenizers for the index.\n   */\n  tokenizers?: LexicalTokenizer[];\n  /**\n   * The token filters for the index.\n   */\n  tokenFilters?: TokenFilter[];\n  /**\n   * The character filters for the index.\n   */\n  charFilters?: CharFilter[];\n  /**\n   * A description of an encryption key that you create in Azure Key Vault. This key is used to\n   * provide an additional level of encryption-at-rest for your data when you want full assurance\n   * that no one, not even Microsoft, can decrypt your data in Azure Cognitive Search. Once you\n   * have encrypted your data, it will always remain encrypted. Azure Cognitive Search will ignore\n   * attempts to set this property to null. You can change this property as needed if you want to\n   * rotate your encryption key; Your data will be unaffected. Encryption with customer-managed\n   * keys is not available for free search services, and is only available for paid services\n   * created on or after January 1, 2019.\n   */\n  encryptionKey?: SearchResourceEncryptionKey;\n  /**\n   * The type of similarity algorithm to be used when scoring and ranking the documents matching a\n   * search query. The similarity algorithm can only be defined at index creation time and cannot\n   * be modified on existing indexes. If null, the ClassicSimilarity algorithm is used.\n   */\n  similarity?: SimilarityAlgorithm;\n  /**\n   * Defines parameters for a search index that influence semantic capabilities.\n   */\n  semanticSearch?: SemanticSearch;\n  /**\n   * Contains configuration options related to vector search.\n   */\n  vectorSearch?: VectorSearch;\n  /**\n   * The ETag of the index.\n   */\n  etag?: string;\n}\n\nexport interface SearchIndexerCache {\n  /**\n   * The connection string to the storage account where the cache data will be persisted.\n   */\n  storageConnectionString?: string;\n  /**\n   * Specifies whether incremental reprocessing is enabled.\n   */\n  enableReprocessing?: boolean;\n  /** The user-assigned managed identity used for connections to the enrichment cache.  If the\n   * connection string indicates an identity (ResourceId) and it's not specified, the\n   * system-assigned managed identity is used. On updates to the indexer, if the identity is\n   * unspecified, the value remains unchanged. If set to \"none\", the value of this property is\n   * cleared.\n   */\n  identity?: SearchIndexerDataIdentity;\n}\n\n/**\n * Represents an indexer.\n */\nexport interface SearchIndexer {\n  /**\n   * The name of the indexer.\n   */\n  name: string;\n  /**\n   * The description of the indexer.\n   */\n  description?: string;\n  /**\n   * The name of the datasource from which this indexer reads data.\n   */\n  dataSourceName: string;\n  /**\n   * The name of the skillset executing with this indexer.\n   */\n  skillsetName?: string;\n  /**\n   * The name of the index to which this indexer writes data.\n   */\n  targetIndexName: string;\n  /**\n   * The schedule for this indexer.\n   */\n  schedule?: IndexingSchedule;\n  /**\n   * Parameters for indexer execution.\n   */\n  parameters?: IndexingParameters;\n  /**\n   * Defines mappings between fields in the data source and corresponding target fields in the\n   * index.\n   */\n  fieldMappings?: FieldMapping[];\n  /**\n   * Output field mappings are applied after enrichment and immediately before indexing.\n   */\n  outputFieldMappings?: FieldMapping[];\n  /**\n   * A value indicating whether the indexer is disabled. Default is false. Default value: false.\n   */\n  isDisabled?: boolean;\n  /**\n   * The ETag of the indexer.\n   */\n  etag?: string;\n  /**\n   * A description of an encryption key that you create in Azure Key Vault. This key is used to\n   * provide an additional level of encryption-at-rest for your indexer definition (as well as\n   * indexer execution status) when you want full assurance that no one, not even Microsoft, can\n   * decrypt them in Azure Cognitive Search. Once you have encrypted your indexer definition, it\n   * will always remain encrypted. Azure Cognitive Search will ignore attempts to set this property\n   * to null. You can change this property as needed if you want to rotate your encryption key;\n   * Your indexer definition (and indexer execution status) will be unaffected. Encryption with\n   * customer-managed keys is not available for free search services, and is only available for\n   * paid services created on or after January 1, 2019.\n   */\n  encryptionKey?: SearchResourceEncryptionKey;\n}\n\n/**\n * A customer-managed encryption key in Azure Key Vault. Keys that you create and manage can be\n * used to encrypt or decrypt data-at-rest in Azure Cognitive Search, such as indexes and synonym\n * maps.\n */\nexport interface SearchResourceEncryptionKey {\n  /**\n   * The name of your Azure Key Vault key to be used to encrypt your data at rest.\n   */\n  keyName: string;\n  /**\n   * The version of your Azure Key Vault key to be used to encrypt your data at rest.\n   */\n  keyVersion: string;\n  /**\n   * The URI of your Azure Key Vault, also referred to as DNS name, that contains the key to be\n   * used to encrypt your data at rest. An example URI might be\n   * https://my-keyvault-name.vault.azure.net.\n   */\n  vaultUrl: string;\n  /**\n   * An AAD Application ID that was granted the required access permissions to the Azure Key Vault\n   * that is to be used when encrypting your data at rest. The Application ID should not be\n   * confused with the Object ID for your AAD Application.\n   */\n  applicationId?: string;\n  /**\n   * The authentication key of the specified AAD application.\n   */\n  applicationSecret?: string;\n  /**\n   * An explicit managed identity to use for this encryption key. If not specified and the access\n   * credentials property is null, the system-assigned managed identity is used. On update to the\n   * resource, if the explicit identity is unspecified, it remains unchanged. If \"none\" is specified,\n   * the value of this property is cleared.\n   */\n  identity?: SearchIndexerDataIdentity;\n}\n\n/**\n * A list of skills.\n */\nexport interface SearchIndexerSkillset {\n  /**\n   * The name of the skillset.\n   */\n  name: string;\n  /**\n   * The description of the skillset.\n   */\n  description?: string;\n  /**\n   * A list of skills in the skillset.\n   */\n  skills: SearchIndexerSkill[];\n  /**\n   * Details about cognitive services to be used when running skills.\n   */\n  cognitiveServicesAccount?: CognitiveServicesAccount;\n  /**\n   * Definition of additional projections to azure blob, table, or files, of enriched data.\n   */\n  knowledgeStore?: SearchIndexerKnowledgeStore;\n  /**\n   *  Definition of additional projections to secondary search index(es).\n   */\n  indexProjection?: SearchIndexerIndexProjection;\n  /**\n   * The ETag of the skillset.\n   */\n  etag?: string;\n  /**\n   * A description of an encryption key that you create in Azure Key Vault. This key is used to\n   * provide an additional level of encryption-at-rest for your skillset definition when you want\n   * full assurance that no one, not even Microsoft, can decrypt your skillset definition in Azure\n   * Cognitive Search. Once you have encrypted your skillset definition, it will always remain\n   * encrypted. Azure Cognitive Search will ignore attempts to set this property to null. You can\n   * change this property as needed if you want to rotate your encryption key; Your skillset\n   * definition will be unaffected. Encryption with customer-managed keys is not available for free\n   * search services, and is only available for paid services created on or after January 1, 2019.\n   */\n  encryptionKey?: SearchResourceEncryptionKey;\n}\n\n/**\n * Defines parameters for a search index that influence scoring in search queries.\n */\nexport interface ScoringProfile {\n  /**\n   * The name of the scoring profile.\n   */\n  name: string;\n  /**\n   * Parameters that boost scoring based on text matches in certain index fields.\n   */\n  textWeights?: TextWeights;\n  /**\n   * The collection of functions that influence the scoring of documents.\n   */\n  functions?: ScoringFunction[];\n  /**\n   * A value indicating how the results of individual scoring functions should be combined.\n   * Defaults to \"Sum\". Ignored if there are no scoring functions. Possible values include: 'sum',\n   * 'average', 'minimum', 'maximum', 'firstMatching'\n   */\n  functionAggregation?: ScoringFunctionAggregation;\n}\n\n/**\n * Defines values for TokenizerName.\n * @readonly\n */\nexport enum KnownTokenizerNames {\n  /**\n   * Grammar-based tokenizer that is suitable for processing most European-language documents. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/standard/ClassicTokenizer.html\n   */\n  Classic = \"classic\",\n  /**\n   * Tokenizes the input from an edge into n-grams of the given size(s). See\n   * https://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.html\n   */\n  EdgeNGram = \"edgeNGram\",\n  /**\n   * Emits the entire input as a single token. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/KeywordTokenizer.html\n   */\n  Keyword = \"keyword_v2\",\n  /**\n   * Divides text at non-letters. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/LetterTokenizer.html\n   */\n  Letter = \"letter\",\n  /**\n   * Divides text at non-letters and converts them to lower case. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/LowerCaseTokenizer.html\n   */\n  Lowercase = \"lowercase\",\n  /**\n   * Divides text using language-specific rules.\n   */\n  // eslint-disable-next-line @typescript-eslint/no-shadow\n  MicrosoftLanguageTokenizer = \"microsoft_language_tokenizer\",\n  /**\n   * Divides text using language-specific rules and reduces words to their base forms.\n   */\n  // eslint-disable-next-line @typescript-eslint/no-shadow\n  MicrosoftLanguageStemmingTokenizer = \"microsoft_language_stemming_tokenizer\",\n  /**\n   * Tokenizes the input into n-grams of the given size(s). See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ngram/NGramTokenizer.html\n   */\n  NGram = \"nGram\",\n  /**\n   * Tokenizer for path-like hierarchies. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/path/PathHierarchyTokenizer.html\n   */\n  PathHierarchy = \"path_hierarchy_v2\",\n  /**\n   * Tokenizer that uses regex pattern matching to construct distinct tokens. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/pattern/PatternTokenizer.html\n   */\n  Pattern = \"pattern\",\n  /**\n   * Standard Lucene analyzer; Composed of the standard tokenizer, lowercase filter and stop\n   * filter. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/standard/StandardTokenizer.html\n   */\n  Standard = \"standard_v2\",\n  /**\n   * Tokenizes urls and emails as one token. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer.html\n   */\n  UaxUrlEmail = \"uax_url_email\",\n  /**\n   * Divides text at whitespace. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/WhitespaceTokenizer.html\n   */\n  Whitespace = \"whitespace\",\n}\n\n/**\n * Defines values for TokenFilterName.\n * @readonly\n */\nexport enum KnownTokenFilterNames {\n  /**\n   * A token filter that applies the Arabic normalizer to normalize the orthography. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ar/ArabicNormalizationFilter.html\n   */\n  ArabicNormalization = \"arabic_normalization\",\n  /**\n   * Strips all characters after an apostrophe (including the apostrophe itself). See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/tr/ApostropheFilter.html\n   */\n  Apostrophe = \"apostrophe\",\n  /**\n   * Converts alphabetic, numeric, and symbolic Unicode characters which are not in the first 127\n   * ASCII characters (the \"Basic Latin\" Unicode block) into their ASCII equivalents, if such\n   * equivalents exist. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.html\n   */\n  AsciiFolding = \"asciifolding\",\n  /**\n   * Forms bigrams of CJK terms that are generated from StandardTokenizer. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/cjk/CJKBigramFilter.html\n   */\n  CjkBigram = \"cjk_bigram\",\n  /**\n   * Normalizes CJK width differences. Folds fullwidth ASCII variants into the equivalent basic\n   * Latin, and half-width Katakana variants into the equivalent Kana. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/cjk/CJKWidthFilter.html\n   */\n  CjkWidth = \"cjk_width\",\n  /**\n   * Removes English possessives, and dots from acronyms. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/standard/ClassicFilter.html\n   */\n  Classic = \"classic\",\n  /**\n   * Construct bigrams for frequently occurring terms while indexing. Single terms are still\n   * indexed too, with bigrams overlaid. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/commongrams/CommonGramsFilter.html\n   */\n  CommonGram = \"common_grams\",\n  /**\n   * Generates n-grams of the given size(s) starting from the front or the back of an input token.\n   * See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.html\n   */\n  EdgeNGram = \"edgeNGram_v2\",\n  /**\n   * Removes elisions. For example, \"l'avion\" (the plane) will be converted to \"avion\" (plane). See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/util/ElisionFilter.html\n   */\n  Elision = \"elision\",\n  /**\n   * Normalizes German characters according to the heuristics of the German2 snowball algorithm.\n   * See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/de/GermanNormalizationFilter.html\n   */\n  GermanNormalization = \"german_normalization\",\n  /**\n   * Normalizes text in Hindi to remove some differences in spelling variations. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/hi/HindiNormalizationFilter.html\n   */\n  HindiNormalization = \"hindi_normalization\",\n  /**\n   * Normalizes the Unicode representation of text in Indian languages. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/in/IndicNormalizationFilter.html\n   */\n  IndicNormalization = \"indic_normalization\",\n  /**\n   * Emits each incoming token twice, once as keyword and once as non-keyword. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/KeywordRepeatFilter.html\n   */\n  KeywordRepeat = \"keyword_repeat\",\n  /**\n   * A high-performance kstem filter for English. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/en/KStemFilter.html\n   */\n  KStem = \"kstem\",\n  /**\n   * Removes words that are too long or too short. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/LengthFilter.html\n   */\n  Length = \"length\",\n  /**\n   * Limits the number of tokens while indexing. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilter.html\n   */\n  Limit = \"limit\",\n  /**\n   * Normalizes token text to lower case. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/LowerCaseFilter.htm\n   */\n  Lowercase = \"lowercase\",\n  /**\n   * Generates n-grams of the given size(s). See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ngram/NGramTokenFilter.html\n   */\n  NGram = \"nGram_v2\",\n  /**\n   * Applies normalization for Persian. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/fa/PersianNormalizationFilter.html\n   */\n  PersianNormalization = \"persian_normalization\",\n  /**\n   * Create tokens for phonetic matches. See\n   * https://lucene.apache.org/core/4_10_3/analyzers-phonetic/org/apache/lucene/analysis/phonetic/package-tree.html\n   */\n  Phonetic = \"phonetic\",\n  /**\n   * Uses the Porter stemming algorithm to transform the token stream. See\n   * http://tartarus.org/~martin/PorterStemmer\n   */\n  PorterStem = \"porter_stem\",\n  /**\n   * Reverses the token string. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/reverse/ReverseStringFilter.html\n   */\n  Reverse = \"reverse\",\n  /**\n   * Normalizes use of the interchangeable Scandinavian characters. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/ScandinavianNormalizationFilter.html\n   */\n  ScandinavianNormalization = \"scandinavian_normalization\",\n  /**\n   * Folds Scandinavian characters -&gt;a and -&gt;o. It also discriminates against use\n   * of double vowels aa, ae, ao, oe and oo, leaving just the first one. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/ScandinavianFoldingFilter.html\n   */\n  ScandinavianFoldingNormalization = \"scandinavian_folding\",\n  /**\n   * Creates combinations of tokens as a single token. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/shingle/ShingleFilter.html\n   */\n  Shingle = \"shingle\",\n  /**\n   * A filter that stems words using a Snowball-generated stemmer. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/snowball/SnowballFilter.html\n   */\n  Snowball = \"snowball\",\n  /**\n   * Normalizes the Unicode representation of Sorani text. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ckb/SoraniNormalizationFilter.html\n   */\n  SoraniNormalization = \"sorani_normalization\",\n  /**\n   * Language specific stemming filter. See\n   * https://docs.microsoft.com/rest/api/searchservice/Custom-analyzers-in-Azure-Search#TokenFilters\n   */\n  Stemmer = \"stemmer\",\n  /**\n   * Removes stop words from a token stream. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/StopFilter.html\n   */\n  Stopwords = \"stopwords\",\n  /**\n   * Trims leading and trailing whitespace from tokens. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/TrimFilter.html\n   */\n  Trim = \"trim\",\n  /**\n   * Truncates the terms to a specific length. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/TruncateTokenFilter.html\n   */\n  Truncate = \"truncate\",\n  /**\n   * Filters out tokens with same text as the previous token. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.html\n   */\n  Unique = \"unique\",\n  /**\n   * Normalizes token text to upper case. See\n   * http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/UpperCaseFilter.html\n   */\n  Uppercase = \"uppercase\",\n  /**\n   * Splits words into subwords and performs optional transformations on subword groups.\n   */\n  WordDelimiter = \"word_delimiter\",\n}\n\n/**\n * Defines values for CharFilterName.\n * @readonly\n */\nexport enum KnownCharFilterNames {\n  /**\n   * A character filter that attempts to strip out HTML constructs. See\n   * https://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.html\n   */\n  HtmlStrip = \"html_strip\",\n}\n\n/**\n * Defines values for AnalyzerName.\n * See https://docs.microsoft.com/rest/api/searchservice/Language-support\n * @readonly\n */\nexport enum KnownAnalyzerNames {\n  /**\n   * Arabic\n   */\n  ArMicrosoft = \"ar.microsoft\",\n  /**\n   * Arabic\n   */\n  ArLucene = \"ar.lucene\",\n  /**\n   * Armenian\n   */\n  HyLucene = \"hy.lucene\",\n  /**\n   * Bangla\n   */\n  BnMicrosoft = \"bn.microsoft\",\n  /**\n   * Basque\n   */\n  EuLucene = \"eu.lucene\",\n  /**\n   * Bulgarian\n   */\n  BgMicrosoft = \"bg.microsoft\",\n  /**\n   * Bulgarian\n   */\n  BgLucene = \"bg.lucene\",\n  /**\n   * Catalan\n   */\n  CaMicrosoft = \"ca.microsoft\",\n  /**\n   * Catalan\n   */\n  CaLucene = \"ca.lucene\",\n  /**\n   * Chinese Simplified\n   */\n  ZhHansMicrosoft = \"zh-Hans.microsoft\",\n  /**\n   * Chinese Simplified\n   */\n  ZhHansLucene = \"zh-Hans.lucene\",\n  /**\n   * Chinese Traditional\n   */\n  ZhHantMicrosoft = \"zh-Hant.microsoft\",\n  /**\n   * Chinese Traditional\n   */\n  ZhHantLucene = \"zh-Hant.lucene\",\n  /**\n   * Croatian\n   */\n  HrMicrosoft = \"hr.microsoft\",\n  /**\n   * Czech\n   */\n  CsMicrosoft = \"cs.microsoft\",\n  /**\n   * Czech\n   */\n  CsLucene = \"cs.lucene\",\n  /**\n   * Danish\n   */\n  DaMicrosoft = \"da.microsoft\",\n  /**\n   * Danish\n   */\n  DaLucene = \"da.lucene\",\n  /**\n   * Dutch\n   */\n  NlMicrosoft = \"nl.microsoft\",\n  /**\n   * Dutch\n   */\n  NlLucene = \"nl.lucene\",\n  /**\n   * English\n   */\n  EnMicrosoft = \"en.microsoft\",\n  /**\n   * English\n   */\n  EnLucene = \"en.lucene\",\n  /**\n   * Estonian\n   */\n  EtMicrosoft = \"et.microsoft\",\n  /**\n   * Finnish\n   */\n  FiMicrosoft = \"fi.microsoft\",\n  /**\n   * Finnish\n   */\n  FiLucene = \"fi.lucene\",\n  /**\n   * French\n   */\n  FrMicrosoft = \"fr.microsoft\",\n  /**\n   * French\n   */\n  FrLucene = \"fr.lucene\",\n  /**\n   * Galician\n   */\n  GlLucene = \"gl.lucene\",\n  /**\n   * German\n   */\n  DeMicrosoft = \"de.microsoft\",\n  /**\n   * German\n   */\n  DeLucene = \"de.lucene\",\n  /**\n   * Greek\n   */\n  ElMicrosoft = \"el.microsoft\",\n  /**\n   * Greek\n   */\n  ElLucene = \"el.lucene\",\n  /**\n   * Gujarati\n   */\n  GuMicrosoft = \"gu.microsoft\",\n  /**\n   * Hebrew\n   */\n  HeMicrosoft = \"he.microsoft\",\n  /**\n   * Hindi\n   */\n  HiMicrosoft = \"hi.microsoft\",\n  /**\n   * Hindi\n   */\n  HiLucene = \"hi.lucene\",\n  /**\n   * Hungarian\n   */\n  HuMicrosoft = \"hu.microsoft\",\n  /**\n   * Hungarian\n   */\n  HuLucene = \"hu.lucene\",\n  /**\n   * Icelandic\n   */\n  IsMicrosoft = \"is.microsoft\",\n  /**\n   * Indonesian (Bahasa)\n   */\n  IdMicrosoft = \"id.microsoft\",\n  /**\n   * Indonesian (Bahasa)\n   */\n  IdLucene = \"id.lucene\",\n  /**\n   * Irish\n   */\n  GaLucene = \"ga.lucene\",\n  /**\n   * Italian\n   */\n  ItMicrosoft = \"it.microsoft\",\n  /**\n   * Italian\n   */\n  ItLucene = \"it.lucene\",\n  /**\n   * Japanese\n   */\n  JaMicrosoft = \"ja.microsoft\",\n  /**\n   * Japanese\n   */\n  JaLucene = \"ja.lucene\",\n  /**\n   * Kannada\n   */\n  KnMicrosoft = \"kn.microsoft\",\n  /**\n   * Korean\n   */\n  KoMicrosoft = \"ko.microsoft\",\n  /**\n   * Korean\n   */\n  KoLucene = \"ko.lucene\",\n  /**\n   * Latvian\n   */\n  LvMicrosoft = \"lv.microsoft\",\n  /**\n   * Latvian\n   */\n  LvLucene = \"lv.lucene\",\n  /**\n   * Lithuanian\n   */\n  LtMicrosoft = \"lt.microsoft\",\n  /**\n   * Malayalam\n   */\n  MlMicrosoft = \"ml.microsoft\",\n  /**\n   * Malay (Latin)\n   */\n  MsMicrosoft = \"ms.microsoft\",\n  /**\n   * Marathi\n   */\n  MrMicrosoft = \"mr.microsoft\",\n  /**\n   * Norwegian\n   */\n  NbMicrosoft = \"nb.microsoft\",\n  /**\n   * Norwegian\n   */\n  NoLucene = \"no.lucene\",\n  /**\n   * Persian\n   */\n  FaLucene = \"fa.lucene\",\n  /**\n   * Polish\n   */\n  PlMicrosoft = \"pl.microsoft\",\n  /**\n   * Polish\n   */\n  PlLucene = \"pl.lucene\",\n  /**\n   * Portuguese (Brazil)\n   */\n  PtBRMicrosoft = \"pt-BR.microsoft\",\n  /**\n   * Portuguese (Brazil)\n   */\n  PtBRLucene = \"pt-BR.lucene\",\n  /**\n   * Portuguese (Portugal)\n   */\n  PtPTMicrosoft = \"pt-PT.microsoft\",\n  /**\n   * Portuguese (Portugal)\n   */\n  PtPTLucene = \"pt-PT.lucene\",\n  /**\n   * Punjabi\n   */ PaMicrosoft = \"pa.microsoft\",\n  /**\n   * Romanian\n   */\n  RoMicrosoft = \"ro.microsoft\",\n  /**\n   * Romanian\n   */\n  RoLucene = \"ro.lucene\",\n  /**\n   * Russian\n   */\n  RuMicrosoft = \"ru.microsoft\",\n  /**\n   * Russian\n   */\n  RuLucene = \"ru.lucene\",\n  /**\n   * Serbian (Cyrillic)\n   */\n  SrCyrillicMicrosoft = \"sr-cyrillic.microsoft\",\n  /**\n   * Serbian (Latin)\n   */\n  SrLatinMicrosoft = \"sr-latin.microsoft\",\n  /**\n   * Slovak\n   */\n  SkMicrosoft = \"sk.microsoft\",\n  /**\n   * Slovenian\n   */\n  SlMicrosoft = \"sl.microsoft\",\n  /**\n   * Spanish\n   */\n  EsMicrosoft = \"es.microsoft\",\n  /**\n   * Spanish\n   */\n  EsLucene = \"es.lucene\",\n  /**\n   * Swedish\n   */\n  SvMicrosoft = \"sv.microsoft\",\n  /**\n   * Swedish\n   */\n  SvLucene = \"sv.lucene\",\n  /**\n   * Tamil\n   */\n  TaMicrosoft = \"ta.microsoft\",\n  /**\n   * Telugu\n   */\n  TeMicrosoft = \"te.microsoft\",\n  /**\n   * Thai\n   */\n  ThMicrosoft = \"th.microsoft\",\n  /**\n   * Thai\n   */\n  ThLucene = \"th.lucene\",\n  /**\n   * Turkish\n   */\n  TrMicrosoft = \"tr.microsoft\",\n  /**\n   * Turkish\n   */\n  TrLucene = \"tr.lucene\",\n  /**\n   * Ukrainian\n   */\n  UkMicrosoft = \"uk.microsoft\",\n  /**\n   * Urdu\n   */\n  UrMicrosoft = \"ur.microsoft\",\n  /**\n   * Vietnamese\n   */\n  ViMicrosoft = \"vi.microsoft\",\n  /**\n   * See: https://lucene.apache.org/core/6_6_1/core/org/apache/lucene/analysis/standard/StandardAnalyzer.html\n   */\n  StandardLucene = \"standard.lucene\",\n  /**\n   * See https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.html\n   */\n  StandardAsciiFoldingLucene = \"standardasciifolding.lucene\",\n  /**\n   * Treats the entire content of a field as a single token. This is useful for data like zip codes, ids, and some product names.\n   */\n  Keyword = \"keyword\",\n  /**\n   * Flexibly separates text into terms via a regular expression pattern.\n   */\n  Pattern = \"pattern\",\n  /**\n   * Divides text at non-letters and converts them to lower case.\n   */\n  Simple = \"simple\",\n  /**\n   * Divides text at non-letters; Applies the lowercase and stopword token filters.\n   */\n  Stop = \"stop\",\n  /**\n   * An analyzer that uses the whitespace tokenizer.\n   */\n  Whitespace = \"whitespace\",\n}\n\n/**\n * Contains the possible cases for DataChangeDetectionPolicy.\n */\nexport type DataChangeDetectionPolicy =\n  | HighWaterMarkChangeDetectionPolicy\n  | SqlIntegratedChangeTrackingPolicy;\n\n/**\n * Contains the possible cases for SearchIndexerDataIdentity.\n */\nexport type SearchIndexerDataIdentity =\n  | SearchIndexerDataNoneIdentity\n  | SearchIndexerDataUserAssignedIdentity;\n\n/**\n * Contains the possible cases for DataDeletionDetectionPolicy.\n */\nexport type DataDeletionDetectionPolicy = SoftDeleteColumnDeletionDetectionPolicy;\n\n/**\n * Represents a datasource definition, which can be used to configure an indexer.\n */\nexport interface SearchIndexerDataSourceConnection {\n  /**\n   * The name of the datasource.\n   */\n  name: string;\n  /**\n   * The description of the datasource.\n   */\n  description?: string;\n  /**\n   * The type of the datasource. Possible values include: 'AzureSql', 'CosmosDb', 'AzureBlob',\n   * 'AzureTable', 'MySql', 'AdlsGen2'\n   */\n  type: SearchIndexerDataSourceType;\n  /**\n   * The connection string for the datasource.\n   */\n  connectionString?: string;\n  /**\n   * The data container for the datasource.\n   */\n  container: SearchIndexerDataContainer;\n  /**\n   * An explicit managed identity to use for this datasource. If not specified and the connection\n   * string is a managed identity, the system-assigned managed identity is used. If not specified,\n   * the value remains unchanged. If \"none\" is specified, the value of this property is cleared.\n   */\n  identity?: SearchIndexerDataIdentity;\n  /**\n   * The data change detection policy for the datasource.\n   */\n  dataChangeDetectionPolicy?: DataChangeDetectionPolicy;\n  /**\n   * The data deletion detection policy for the datasource.\n   */\n  dataDeletionDetectionPolicy?: DataDeletionDetectionPolicy;\n  /**\n   * The ETag of the DataSource.\n   */\n  etag?: string;\n  /**\n   * A description of an encryption key that you create in Azure Key Vault. This key is used to\n   * provide an additional level of encryption-at-rest for your datasource definition when you want\n   * full assurance that no one, not even Microsoft, can decrypt your data source definition in\n   * Azure Cognitive Search. Once you have encrypted your data source definition, it will always\n   * remain encrypted. Azure Cognitive Search will ignore attempts to set this property to null.\n   * You can change this property as needed if you want to rotate your encryption key; Your\n   * datasource definition will be unaffected. Encryption with customer-managed keys is not\n   * available for free search services, and is only available for paid services created on or\n   * after January 1, 2019.\n   */\n  encryptionKey?: SearchResourceEncryptionKey;\n}\n\n/** Contains configuration options related to vector search. */\nexport interface VectorSearch {\n  /** Defines combinations of configurations to use with vector search. */\n  profiles?: VectorSearchProfile[];\n  /** Contains configuration options specific to the algorithm used during indexing or querying. */\n  algorithms?: VectorSearchAlgorithmConfiguration[];\n  /** Contains configuration options on how to vectorize text vector queries. */\n  vectorizers?: VectorSearchVectorizer[];\n  /** Contains configuration options specific to the compression method used during indexing or querying. */\n  compressions?: VectorSearchCompression[];\n}\n\n/** Contains configuration options specific to the algorithm used during indexing and/or querying. */\nexport type VectorSearchAlgorithmConfiguration =\n  | HnswAlgorithmConfiguration\n  | ExhaustiveKnnAlgorithmConfiguration;\n\n/** Contains configuration options specific to the algorithm used during indexing and/or querying. */\nexport interface BaseVectorSearchAlgorithmConfiguration {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  kind: VectorSearchAlgorithmKind;\n  /** The name to associate with this particular configuration. */\n  name: string;\n}\n\n/**\n * Contains configuration options specific to the hnsw approximate nearest neighbors algorithm\n * used during indexing time.\n */\nexport type HnswAlgorithmConfiguration = BaseVectorSearchAlgorithmConfiguration & {\n  /**\n   * Polymorphic discriminator, which specifies the different types this object can be\n   */\n  kind: \"hnsw\";\n  /**\n   * Contains the parameters specific to hnsw algorithm.\n   *\n   */\n  parameters?: HnswParameters;\n};\n\n/**\n * Contains the parameters specific to hnsw algorithm.\n */\nexport interface HnswParameters {\n  /**\n   * The number of bi-directional links created for every new element during construction.\n   * Increasing this parameter value may improve recall and reduce retrieval times for datasets\n   * with high intrinsic dimensionality at the expense of increased memory consumption and longer\n   * indexing time.\n   */\n  m?: number;\n  /**\n   * The size of the dynamic list containing the nearest neighbors, which is used during index\n   * time. Increasing this parameter may improve index quality, at the expense of increased\n   * indexing time. At a certain point, increasing this parameter leads to diminishing returns.\n   */\n  efConstruction?: number;\n  /**\n   * The size of the dynamic list containing the nearest neighbors, which is used during search\n   * time. Increasing this parameter may improve search results, at the expense of slower search.\n   * Increasing this parameter leads to diminishing returns.\n   */\n  efSearch?: number;\n  /**\n   * The similarity metric to use for vector comparisons.\n   */\n  metric?: VectorSearchAlgorithmMetric;\n}\n\n/** Contains configuration options specific to the exhaustive KNN algorithm used during querying, which will perform brute-force search across the entire vector index. */\nexport type ExhaustiveKnnAlgorithmConfiguration = BaseVectorSearchAlgorithmConfiguration & {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  kind: \"exhaustiveKnn\";\n  /** Contains the parameters specific to exhaustive KNN algorithm. */\n  parameters?: ExhaustiveKnnParameters;\n};\n\n/** Contains the parameters specific to exhaustive KNN algorithm. */\nexport interface ExhaustiveKnnParameters {\n  /** The similarity metric to use for vector comparisons. */\n  metric?: VectorSearchAlgorithmMetric;\n}\n\n/** A dictionary of index projection-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type. */\nexport interface SearchIndexerIndexProjectionParameters {\n  /** Describes unknown properties.*/\n  [property: string]: unknown;\n  /** Defines behavior of the index projections in relation to the rest of the indexer. */\n  projectionMode?: IndexProjectionMode;\n}\n\n/** Definition of additional projections to secondary search indexes. */\nexport interface SearchIndexerIndexProjection {\n  /** A list of projections to be performed to secondary search indexes. */\n  selectors: SearchIndexerIndexProjectionSelector[];\n  /** A dictionary of index projection-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type. */\n  parameters?: SearchIndexerIndexProjectionParameters;\n}\n\n/** Contains specific details for a vectorization method to be used during query time. */\nexport interface BaseVectorSearchVectorizer {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  kind: VectorSearchVectorizerKind;\n  /** The name to associate with this particular vectorization method. */\n  vectorizerName: string;\n}\n\n/** Contains the parameters specific to using an Azure Open AI service for vectorization at query time. */\nexport interface AzureOpenAIVectorizer extends BaseVectorSearchVectorizer {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  kind: \"azureOpenAI\";\n  /** Contains the parameters specific to Azure Open AI embedding vectorization. */\n  parameters?: AzureOpenAIParameters;\n}\n\n/** Specifies a user-defined vectorizer for generating the vector embedding of a query string. Integration of an external vectorizer is achieved using the custom Web API interface of a skillset. */\nexport interface WebApiVectorizer extends BaseVectorSearchVectorizer {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  kind: \"customWebApi\";\n  /** Specifies the properties of the user-defined vectorizer. */\n  parameters?: WebApiParameters;\n}\n\n/** Specifies the properties for connecting to a user-defined vectorizer. */\nexport interface WebApiParameters {\n  /** The URI of the Web API providing the vectorizer. */\n  uri?: string;\n  /** The headers required to make the HTTP request. */\n  httpHeaders?: { [propertyName: string]: string };\n  /** The method for the HTTP request. */\n  httpMethod?: string;\n  /** The desired timeout for the request. Default is 30 seconds. */\n  timeout?: string;\n  /** Applies to custom endpoints that connect to external code in an Azure function or some other application that provides the transformations. This value should be the application ID created for the function or app when it was registered with Azure Active Directory. When specified, the vectorization connects to the function or app using a managed ID (either system or user-assigned) of the search service and the access token of the function or app, using this value as the resource id for creating the scope of the access token. */\n  authResourceId?: string;\n  /** The user-assigned managed identity used for outbound connections. If an authResourceId is provided and it's not specified, the system-assigned managed identity is used. On updates to the indexer, if the identity is unspecified, the value remains unchanged. If set to \"none\", the value of this property is cleared. */\n  authIdentity?: SearchIndexerDataIdentity;\n}\n\n/** Contains configuration options on how to vectorize text vector queries. */\nexport type VectorSearchVectorizer = AzureOpenAIVectorizer | WebApiVectorizer;\n\n/** Contains the parameters specific to using an Azure Open AI service for vectorization at query time. */\nexport interface AzureOpenAIParameters {\n  /** The resource uri for your Azure Open AI resource. */\n  resourceUrl?: string;\n  /** ID of your Azure Open AI model deployment on the designated resource. */\n  deploymentId?: string;\n  /** API key for the designated Azure Open AI resource. */\n  apiKey?: string;\n  /** The user-assigned managed identity used for outbound connections. */\n  authIdentity?: SearchIndexerDataIdentity;\n  /** The name of the embedding model that is deployed at the provided deploymentId path. */\n  modelName?: AzureOpenAIModelName;\n}\n\n/** Allows you to generate a vector embedding for a given text input using the Azure OpenAI resource. */\nexport interface AzureOpenAIEmbeddingSkill extends BaseSearchIndexerSkill, AzureOpenAIParameters {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill\";\n  /** The number of dimensions the resulting output embeddings should have. Only supported in text-embedding-3 and later models. */\n  dimensions?: number;\n}\n\n/** A dictionary of knowledge store-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type. */\nexport interface SearchIndexerKnowledgeStoreParameters {\n  /** Describes unknown properties. The value of an unknown property can be of \"any\" type. */\n  [property: string]: unknown;\n  /** Whether or not projections should synthesize a generated key name if one isn't already present. */\n  synthesizeGeneratedKeyName?: boolean;\n}\n\n/** A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type. */\nexport interface IndexingParametersConfiguration {\n  /** Describes unknown properties. The value of an unknown property can be of \"any\" type. */\n  [property: string]: any;\n  /** Represents the parsing mode for indexing from an Azure blob data source. */\n  parsingMode?: BlobIndexerParsingMode;\n  /** Comma-delimited list of filename extensions to ignore when processing from Azure blob storage.  For example, you could exclude \".png, .mp4\" to skip over those files during indexing. */\n  excludedFileNameExtensions?: string;\n  /** Comma-delimited list of filename extensions to select when processing from Azure blob storage.  For example, you could focus indexing on specific application files \".docx, .pptx, .msg\" to specifically include those file types. */\n  indexedFileNameExtensions?: string;\n  /** For Azure blobs, set to false if you want to continue indexing when an unsupported content type is encountered, and you don't know all the content types (file extensions) in advance. */\n  failOnUnsupportedContentType?: boolean;\n  /** For Azure blobs, set to false if you want to continue indexing if a document fails indexing. */\n  failOnUnprocessableDocument?: boolean;\n  /** For Azure blobs, set this property to true to still index storage metadata for blob content that is too large to process. Oversized blobs are treated as errors by default. For limits on blob size, see https://docs.microsoft.com/azure/search/search-limits-quotas-capacity. */\n  indexStorageMetadataOnlyForOversizedDocuments?: boolean;\n  /** For CSV blobs, specifies a comma-delimited list of column headers, useful for mapping source fields to destination fields in an index. */\n  delimitedTextHeaders?: string;\n  /** For CSV blobs, specifies the end-of-line single-character delimiter for CSV files where each line starts a new document (for example, \"|\"). */\n  delimitedTextDelimiter?: string;\n  /** For CSV blobs, indicates that the first (non-blank) line of each blob contains headers. */\n  firstLineContainsHeaders?: boolean;\n  /** For JSON arrays, given a structured or semi-structured document, you can specify a path to the array using this property. */\n  documentRoot?: string;\n  /** Specifies the data to extract from Azure blob storage and tells the indexer which data to extract from image content when \"imageAction\" is set to a value other than \"none\".  This applies to embedded image content in a .PDF or other application, or image files such as .jpg and .png, in Azure blobs. */\n  dataToExtract?: BlobIndexerDataToExtract;\n  /** Determines how to process embedded images and image files in Azure blob storage.  Setting the \"imageAction\" configuration to any value other than \"none\" requires that a skillset also be attached to that indexer. */\n  imageAction?: BlobIndexerImageAction;\n  /** If true, will create a path //document//file_data that is an object representing the original file data downloaded from your blob data source.  This allows you to pass the original file data to a custom skill for processing within the enrichment pipeline, or to the Document Extraction skill. */\n  allowSkillsetToReadFileData?: boolean;\n  /** Determines algorithm for text extraction from PDF files in Azure blob storage. */\n  pdfTextRotationAlgorithm?: BlobIndexerPDFTextRotationAlgorithm;\n  /** Specifies the environment in which the indexer should execute. */\n  executionEnvironment?: IndexerExecutionEnvironment;\n  /** Increases the timeout beyond the 5-minute default for Azure SQL database data sources, specified in the format \"hh:mm:ss\". */\n  queryTimeout?: string;\n}\n\n/** Represents parameters for indexer execution. */\nexport interface IndexingParameters {\n  /** The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type. */\n  batchSize?: number;\n  /** The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0. */\n  maxFailedItems?: number;\n  /** The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0. */\n  maxFailedItemsPerBatch?: number;\n  /** A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type. */\n  configuration?: IndexingParametersConfiguration;\n}\n\n/** A skill looks for text from a custom, user-defined list of words and phrases. */\nexport interface CustomEntityLookupSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Text.CustomEntityLookupSkill\";\n  /** A value indicating which language code to use. Default is en. */\n  defaultLanguageCode?: CustomEntityLookupSkillLanguage;\n  /** Path to a JSON or CSV file containing all the target text to match against. This entity definition is read at the beginning of an indexer run. Any updates to this file during an indexer run will not take effect until subsequent runs. This config must be accessible over HTTPS. */\n  entitiesDefinitionUri?: string;\n  /** The inline CustomEntity definition. */\n  inlineEntitiesDefinition?: CustomEntity[];\n  /** A global flag for CaseSensitive. If CaseSensitive is not set in CustomEntity, this value will be the default value. */\n  globalDefaultCaseSensitive?: boolean;\n  /** A global flag for AccentSensitive. If AccentSensitive is not set in CustomEntity, this value will be the default value. */\n  globalDefaultAccentSensitive?: boolean;\n  /** A global flag for FuzzyEditDistance. If FuzzyEditDistance is not set in CustomEntity, this value will be the default value. */\n  globalDefaultFuzzyEditDistance?: number;\n}\n\n/**\n * Text analytics entity recognition.\n *\n * @deprecated This skill has been deprecated.\n */\nexport interface EntityRecognitionSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Text.EntityRecognitionSkill\";\n  /** A list of entity categories that should be extracted. */\n  categories?: EntityCategory[];\n  /** A value indicating which language code to use. Default is en. */\n  defaultLanguageCode?: EntityRecognitionSkillLanguage;\n  /** Determines whether or not to include entities which are well known but don't conform to a pre-defined type. If this configuration is not set (default), set to null or set to false, entities which don't conform to one of the pre-defined types will not be surfaced. */\n  includeTypelessEntities?: boolean;\n  /** A value between 0 and 1 that be used to only include entities whose confidence score is greater than the value specified. If not set (default), or if explicitly set to null, all entities will be included. */\n  minimumPrecision?: number;\n}\n\n/** A skill that analyzes image files. It extracts a rich set of visual features based on the image content. */\nexport interface ImageAnalysisSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Vision.ImageAnalysisSkill\";\n  /** A value indicating which language code to use. Default is en. */\n  defaultLanguageCode?: ImageAnalysisSkillLanguage;\n  /** A list of visual features. */\n  visualFeatures?: VisualFeature[];\n  /** A string indicating which domain-specific details to return. */\n  details?: ImageDetail[];\n}\n\n/** A skill that uses text analytics for key phrase extraction. */\nexport interface KeyPhraseExtractionSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Text.KeyPhraseExtractionSkill\";\n  /** A value indicating which language code to use. Default is en. */\n  defaultLanguageCode?: KeyPhraseExtractionSkillLanguage;\n  /** A number indicating how many key phrases to return. If absent, all identified key phrases will be returned. */\n  maxKeyPhraseCount?: number;\n  /** The version of the model to use when calling the Text Analytics service. It will default to the latest available when not specified. We recommend you do not specify this value unless absolutely necessary. */\n  modelVersion?: string;\n}\n\n/** A skill that extracts text from image files. */\nexport interface OcrSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Vision.OcrSkill\";\n  /** A value indicating which language code to use. Default is en. */\n  defaultLanguageCode?: OcrSkillLanguage;\n  /** A value indicating to turn orientation detection on or not. Default is false. */\n  shouldDetectOrientation?: boolean;\n}\n\n/** Using the Text Analytics API, extracts personal information from an input text and gives you the option of masking it. */\nexport interface PIIDetectionSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Text.PIIDetectionSkill\";\n  /** A value indicating which language code to use. Default is en. */\n  defaultLanguageCode?: string;\n  /** A value between 0 and 1 that be used to only include entities whose confidence score is greater than the value specified. If not set (default), or if explicitly set to null, all entities will be included. */\n  minimumPrecision?: number;\n  /** A parameter that provides various ways to mask the personal information detected in the input text. Default is 'none'. */\n  maskingMode?: PIIDetectionSkillMaskingMode;\n  /** The character used to mask the text if the maskingMode parameter is set to replace. Default is '*'. */\n  maskingCharacter?: string;\n  /** The version of the model to use when calling the Text Analytics service. It will default to the latest available when not specified. We recommend you do not specify this value unless absolutely necessary. */\n  modelVersion?: string;\n  /** A list of PII entity categories that should be extracted and masked. */\n  categories?: string[];\n  /** If specified, will set the PII domain to include only a subset of the entity categories. Possible values include: 'phi', 'none'. Default is 'none'. */\n  domain?: string;\n}\n\n/**\n * Text analytics positive-negative sentiment analysis, scored as a floating point value in a range of zero to 1.\n *\n * @deprecated This skill has been deprecated.\n */\nexport interface SentimentSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Text.SentimentSkill\";\n  /** A value indicating which language code to use. Default is en. */\n  defaultLanguageCode?: SentimentSkillLanguage;\n}\n\n/** A skill to split a string into chunks of text. */\nexport interface SplitSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Text.SplitSkill\";\n  /** A value indicating which language code to use. Default is en. */\n  defaultLanguageCode?: SplitSkillLanguage;\n  /** A value indicating which split mode to perform. */\n  textSplitMode?: TextSplitMode;\n  /** The desired maximum page length. Default is 10000. */\n  maxPageLength?: number;\n}\n\n/** A skill to translate text from one language to another. */\nexport interface TextTranslationSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Text.TranslationSkill\";\n  /** The language code to translate documents into for documents that don't specify the to language explicitly. */\n  defaultToLanguageCode: TextTranslationSkillLanguage;\n  /** The language code to translate documents from for documents that don't specify the from language explicitly. */\n  defaultFromLanguageCode?: TextTranslationSkillLanguage;\n  /** The language code to translate documents from when neither the fromLanguageCode input nor the defaultFromLanguageCode parameter are provided, and the automatic language detection is unsuccessful. Default is en. */\n  suggestedFrom?: TextTranslationSkillLanguage;\n}\n\n/** A skill that analyzes image files. It extracts a rich set of visual features based on the image content. */\nexport interface ImageAnalysisSkill extends BaseSearchIndexerSkill {\n  /** Polymorphic discriminator, which specifies the different types this object can be */\n  odatatype: \"#Microsoft.Skills.Vision.ImageAnalysisSkill\";\n  /** A value indicating which language code to use. Default is en. */\n  defaultLanguageCode?: ImageAnalysisSkillLanguage;\n  /** A list of visual features. */\n  visualFeatures?: VisualFeature[];\n  /** A string indicating which domain-specific details to return. */\n  details?: ImageDetail[];\n}\n\n/** Contains configuration options specific to the compression method used during indexing or querying. */\nexport type VectorSearchCompression = BinaryQuantizationCompression | ScalarQuantizationCompression;\n\nexport type AnalyzerNames = `${KnownLexicalAnalyzerName}`;\nexport type BlobIndexerDataToExtract = `${KnownBlobIndexerDataToExtract}`;\nexport type BlobIndexerImageAction = `${KnownBlobIndexerImageAction}`;\nexport type BlobIndexerParsingMode = `${KnownBlobIndexerParsingMode}`;\nexport type BlobIndexerPDFTextRotationAlgorithm = `${KnownBlobIndexerPDFTextRotationAlgorithm}`;\nexport type CharFilterNames = `${KnownCharFilterName}`;\nexport type CustomEntityLookupSkillLanguage = `${KnownCustomEntityLookupSkillLanguage}`;\nexport type EntityCategory = `${KnownEntityCategory}`;\nexport type EntityRecognitionSkillLanguage = `${KnownEntityRecognitionSkillLanguage}`;\nexport type ImageAnalysisSkillLanguage = `${KnownImageAnalysisSkillLanguage}`;\nexport type ImageDetail = `${KnownImageDetail}`;\nexport type IndexerExecutionEnvironment = `${KnownIndexerExecutionEnvironment}`;\nexport type KeyPhraseExtractionSkillLanguage = `${KnownKeyPhraseExtractionSkillLanguage}`;\nexport type OcrSkillLanguage = `${KnownOcrSkillLanguage}`;\nexport type PIIDetectionSkillMaskingMode = `${KnownPIIDetectionSkillMaskingMode}`;\nexport type RegexFlags = `${KnownRegexFlags}`;\n/**\n * Defines values for SearchFieldDataType.\n *\n * ### Known values supported by the service:\n *\n * **Edm.String**: Indicates that a field contains a string.\n *\n * **Edm.Int32**: Indicates that a field contains a 32-bit signed integer.\n *\n * **Edm.Int64**: Indicates that a field contains a 64-bit signed integer.\n *\n * **Edm.Double**: Indicates that a field contains an IEEE double-precision floating point number.\n *\n * **Edm.Boolean**: Indicates that a field contains a Boolean value (true or false).\n *\n * **Edm.DateTimeOffset**: Indicates that a field contains a date/time value, including timezone\n * information.\n *\n * **Edm.GeographyPoint**: Indicates that a field contains a geo-location in terms of longitude and\n * latitude.\n *\n * **Edm.ComplexType**: Indicates that a field contains one or more complex objects that in turn\n * have sub-fields of other types.\n *\n * **Edm.Single**: Indicates that a field contains a single-precision floating point number. This is\n * only valid when used as part of a collection type, i.e. Collection(Edm.Single).\n *\n * **Edm.Half**: Indicates that a field contains a half-precision floating point number. This is\n * only valid when used as part of a collection type, i.e. Collection(Edm.Half).\n *\n * **Edm.Int16**: Indicates that a field contains a 16-bit signed integer. This is only valid when\n * used as part of a collection type, i.e. Collection(Edm.Int16).\n *\n * **Edm.SByte**: Indicates that a field contains a 8-bit signed integer. This is only valid when\n * used as part of a collection type, i.e. Collection(Edm.SByte).\n *\n * **Edm.Byte**: Indicates that a field contains a 8-bit unsigned integer. This is only valid when\n * used as part of a collection type, i.e. Collection(Edm.Byte).\n */\nexport type SearchFieldDataType = Exclude<\n  `${KnownSearchFieldDataType}` | `Collection(${KnownSearchFieldDataType})`,\n  \"Edm.ComplexType\" | \"Edm.Byte\" | \"Edm.Half\" | \"Edm.Int16\" | \"Edm.SByte\" | \"Edm.Single\"\n>;\nexport type SearchIndexerDataSourceType = `${KnownSearchIndexerDataSourceType}`;\nexport type SentimentSkillLanguage = `${KnownSentimentSkillLanguage}`;\nexport type SplitSkillLanguage = `${KnownSplitSkillLanguage}`;\nexport type TextSplitMode = `${KnownTextSplitMode}`;\nexport type TextTranslationSkillLanguage = `${KnownTextTranslationSkillLanguage}`;\nexport type TokenFilterNames = `${KnownTokenFilterName}`;\nexport type TokenizerNames = `${KnownLexicalTokenizerName}`;\nexport type VectorSearchAlgorithmKind = `${KnownVectorSearchAlgorithmKind}`;\nexport type VectorSearchAlgorithmMetric = `${KnownVectorSearchAlgorithmMetric}`;\nexport type VisualFeature = `${KnownVisualFeature}`;\n\n// END manually modified generated interfaces\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;;;;;AAg9B5B,SAAU,cAAc,CAAC,KAAkB;IAC/C,OAAO,KAAK,CAAC,IAAI,KAAK,iBAAiB,IAAI,KAAK,CAAC,IAAI,KAAK,6BAA6B,CAAC;AAC1F,CAAC;AAmVD,IAAY,mBAmEX;AAnED,CAAA,SAAY,mBAAmB;IAC7B;;;OAGG,CACH,mBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB;;;OAGG,CACH,mBAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB;;;OAGG,CACH,mBAAA,CAAA,UAAA,GAAA,YAAsB,CAAA;IACtB;;;OAGG,CACH,mBAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB;;;OAGG,CACH,mBAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB;;OAEG,CACH,wDAAwD;IACxD,mBAAA,CAAA,6BAAA,GAAA,8BAA2D,CAAA;IAC3D;;OAEG,CACH,wDAAwD;IACxD,mBAAA,CAAA,qCAAA,GAAA,uCAA4E,CAAA;IAC5E;;;OAGG,CACH,mBAAA,CAAA,QAAA,GAAA,OAAe,CAAA;IACf;;;OAGG,CACH,mBAAA,CAAA,gBAAA,GAAA,mBAAmC,CAAA;IACnC;;;OAGG,CACH,mBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB;;;;OAIG,CACH,mBAAA,CAAA,WAAA,GAAA,aAAwB,CAAA;IACxB;;;OAGG,CACH,mBAAA,CAAA,cAAA,GAAA,eAA6B,CAAA;IAC7B;;;OAGG,CACH,mBAAA,CAAA,aAAA,GAAA,YAAyB,CAAA;AAC3B,CAAC,EAnEW,mBAAmB,IAAA,CAAnB,mBAAmB,GAAA,CAAA,CAAA,GAmE9B;AAMD,IAAY,qBAiLX;AAjLD,CAAA,SAAY,qBAAqB;IAC/B;;;OAGG,CACH,qBAAA,CAAA,sBAAA,GAAA,sBAA4C,CAAA;IAC5C;;;OAGG,CACH,qBAAA,CAAA,aAAA,GAAA,YAAyB,CAAA;IACzB;;;;;OAKG,CACH,qBAAA,CAAA,eAAA,GAAA,cAA6B,CAAA;IAC7B;;;OAGG,CACH,qBAAA,CAAA,YAAA,GAAA,YAAwB,CAAA;IACxB;;;;OAIG,CACH,qBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;;OAGG,CACH,qBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB;;;;OAIG,CACH,qBAAA,CAAA,aAAA,GAAA,cAA2B,CAAA;IAC3B;;;;OAIG,CACH,qBAAA,CAAA,YAAA,GAAA,cAA0B,CAAA;IAC1B;;;OAGG,CACH,qBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB;;;;OAIG,CACH,qBAAA,CAAA,sBAAA,GAAA,sBAA4C,CAAA;IAC5C;;;OAGG,CACH,qBAAA,CAAA,qBAAA,GAAA,qBAA0C,CAAA;IAC1C;;;OAGG,CACH,qBAAA,CAAA,qBAAA,GAAA,qBAA0C,CAAA;IAC1C;;;OAGG,CACH,qBAAA,CAAA,gBAAA,GAAA,gBAAgC,CAAA;IAChC;;;OAGG,CACH,qBAAA,CAAA,QAAA,GAAA,OAAe,CAAA;IACf;;;OAGG,CACH,qBAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB;;;OAGG,CACH,qBAAA,CAAA,QAAA,GAAA,OAAe,CAAA;IACf;;;OAGG,CACH,qBAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB;;;OAGG,CACH,qBAAA,CAAA,QAAA,GAAA,UAAkB,CAAA;IAClB;;;OAGG,CACH,qBAAA,CAAA,uBAAA,GAAA,uBAA8C,CAAA;IAC9C;;;OAGG,CACH,qBAAA,CAAA,WAAA,GAAA,UAAqB,CAAA;IACrB;;;OAGG,CACH,qBAAA,CAAA,aAAA,GAAA,aAA0B,CAAA;IAC1B;;;OAGG,CACH,qBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB;;;OAGG,CACH,qBAAA,CAAA,4BAAA,GAAA,4BAAwD,CAAA;IACxD;;;;OAIG,CACH,qBAAA,CAAA,mCAAA,GAAA,sBAAyD,CAAA;IACzD;;;OAGG,CACH,qBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB;;;OAGG,CACH,qBAAA,CAAA,WAAA,GAAA,UAAqB,CAAA;IACrB;;;OAGG,CACH,qBAAA,CAAA,sBAAA,GAAA,sBAA4C,CAAA;IAC5C;;;OAGG,CACH,qBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB;;;OAGG,CACH,qBAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB;;;OAGG,CACH,qBAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb;;;OAGG,CACH,qBAAA,CAAA,WAAA,GAAA,UAAqB,CAAA;IACrB;;;OAGG,CACH,qBAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB;;;OAGG,CACH,qBAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB;;OAEG,CACH,qBAAA,CAAA,gBAAA,GAAA,gBAAgC,CAAA;AAClC,CAAC,EAjLW,qBAAqB,IAAA,CAArB,qBAAqB,GAAA,CAAA,CAAA,GAiLhC;AAMD,IAAY,oBAMX;AAND,CAAA,SAAY,oBAAoB;IAC9B;;;OAGG,CACH,oBAAA,CAAA,YAAA,GAAA,YAAwB,CAAA;AAC1B,CAAC,EANW,oBAAoB,IAAA,CAApB,oBAAoB,GAAA,CAAA,CAAA,GAM/B;AAOD,IAAY,kBAoXX;AApXD,CAAA,SAAY,kBAAkB;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,kBAAA,GAAA,mBAAqC,CAAA;IACrC;;OAEG,CACH,kBAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B;;OAEG,CACH,kBAAA,CAAA,kBAAA,GAAA,mBAAqC,CAAA;IACrC;;OAEG,CACH,kBAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,gBAAA,GAAA,iBAAiC,CAAA;IACjC;;OAEG,CACH,kBAAA,CAAA,aAAA,GAAA,cAA2B,CAAA;IAC3B;;OAEG,CACH,kBAAA,CAAA,gBAAA,GAAA,iBAAiC,CAAA;IACjC;;OAEG,CACH,kBAAA,CAAA,aAAA,GAAA,cAA2B,CAAA;IAC3B;;OAEG,CAAC,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAChC;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,sBAAA,GAAA,uBAA6C,CAAA;IAC7C;;OAEG,CACH,kBAAA,CAAA,mBAAA,GAAA,oBAAuC,CAAA;IACvC;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,WAAA,GAAA,WAAsB,CAAA;IACtB;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,cAAA,GAAA,cAA4B,CAAA;IAC5B;;OAEG,CACH,kBAAA,CAAA,iBAAA,GAAA,iBAAkC,CAAA;IAClC;;OAEG,CACH,kBAAA,CAAA,6BAAA,GAAA,6BAA0D,CAAA;IAC1D;;OAEG,CACH,kBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB;;OAEG,CACH,kBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB;;OAEG,CACH,kBAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB;;OAEG,CACH,kBAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb;;OAEG,CACH,kBAAA,CAAA,aAAA,GAAA,YAAyB,CAAA;AAC3B,CAAC,EApXW,kBAAkB,IAAA,CAAlB,kBAAkB,GAAA,CAAA,CAAA,GAoX7B,CAggBD,6CAA6C","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3383, "column": 0}, "map": {"version":3,"file":"serviceUtils.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/serviceUtils.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport {\n  SearchResult as GeneratedSearchResult,\n  SuggestDocumentsResult as GeneratedSuggestDocumentsResult,\n} from \"./generated/data/models\";\nimport {\n  AzureOpenAIVectorizer as GeneratedAzureOpenAIVectorizer,\n  BM25Similarity,\n  ClassicSimilarity,\n  CognitiveServicesAccountKey,\n  CognitiveServicesAccountUnion,\n  CustomAnalyzer as BaseCustomAnalyzer,\n  DataChangeDetectionPolicyUnion,\n  DataDeletionDetectionPolicyUnion,\n  DefaultCognitiveServicesAccount,\n  ExhaustiveKnnAlgorithmConfiguration as GeneratedExhaustiveKnnAlgorithmConfiguration,\n  HighWaterMarkChangeDetectionPolicy,\n  HnswAlgorithmConfiguration as GeneratedHnswAlgorithmConfiguration,\n  LexicalAnalyzerUnion,\n  LexicalTokenizerUnion,\n  LuceneStandardAnalyzer,\n  PatternAnalyzer as GeneratedPatternAnalyzer,\n  PatternTokenizer,\n  SearchField as GeneratedSearchField,\n  SearchIndex as GeneratedSearchIndex,\n  SearchIndexer as GeneratedSearchIndexer,\n  SearchIndexerDataIdentityUnion,\n  SearchIndexerDataNoneIdentity,\n  SearchIndexerDataSource as GeneratedSearchIndexerDataSourceConnection,\n  SearchIndexerDataUserAssignedIdentity,\n  SearchIndexerSkillset as GeneratedSearchIndexerSkillset,\n  SearchIndexerSkillUnion,\n  SearchResourceEncryptionKey as GeneratedSearchResourceEncryptionKey,\n  SimilarityUnion,\n  SoftDeleteColumnDeletionDetectionPolicy,\n  SqlIntegratedChangeTrackingPolicy,\n  StopAnalyzer,\n  SynonymMap as GeneratedSynonymMap,\n  TokenFilterUnion,\n  VectorSearch as GeneratedVectorSearch,\n  VectorSearchAlgorithmConfigurationUnion as GeneratedVectorSearchAlgorithmConfiguration,\n  VectorSearchVectorizerUnion as GeneratedVectorSearchVectorizer,\n  WebApiVectorizer as GeneratedWebAPIVectorizer,\n} from \"./generated/service/models\";\nimport { SearchResult, SelectFields, SuggestDocumentsResult, SuggestResult } from \"./indexModels\";\nimport { logger } from \"./logger\";\nimport {\n  AzureOpenAIVectorizer,\n  BlobIndexerDataToExtract,\n  BlobIndexerImageAction,\n  BlobIndexerParsingMode,\n  BlobIndexerPDFTextRotationAlgorithm,\n  CharFilter,\n  CognitiveServicesAccount,\n  ComplexField,\n  DataChangeDetectionPolicy,\n  DataDeletionDetectionPolicy,\n  IndexerExecutionEnvironment,\n  IndexingParameters,\n  IndexingParametersConfiguration,\n  isComplexField,\n  LexicalAnalyzer,\n  LexicalTokenizer,\n  PatternAnalyzer,\n  RegexFlags,\n  ScoringProfile,\n  SearchField,\n  SearchFieldDataType,\n  SearchIndex,\n  SearchIndexer,\n  SearchIndexerDataIdentity,\n  SearchIndexerDataSourceConnection,\n  SearchIndexerDataSourceType,\n  SearchIndexerIndexProjection,\n  SearchIndexerSkill,\n  SearchIndexerSkillset,\n  SearchResourceEncryptionKey,\n  SimilarityAlgorithm,\n  SimpleField,\n  SynonymMap,\n  TokenFilter,\n  VectorSearch,\n  VectorSearchAlgorithmConfiguration,\n  VectorSearchAlgorithmMetric,\n  VectorSearchVectorizer,\n  WebApiVectorizer,\n} from \"./serviceModels\";\n\nexport const defaultServiceVersion = \"2024-07-01\";\n\nconst knownSkills: Record<`${SearchIndexerSkillUnion[\"odatatype\"]}`, true> = {\n  \"#Microsoft.Skills.Custom.WebApiSkill\": true,\n  \"#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill\": true,\n  \"#Microsoft.Skills.Text.CustomEntityLookupSkill\": true,\n  \"#Microsoft.Skills.Text.EntityRecognitionSkill\": true,\n  \"#Microsoft.Skills.Text.KeyPhraseExtractionSkill\": true,\n  \"#Microsoft.Skills.Text.LanguageDetectionSkill\": true,\n  \"#Microsoft.Skills.Text.MergeSkill\": true,\n  \"#Microsoft.Skills.Text.PIIDetectionSkill\": true,\n  \"#Microsoft.Skills.Text.SentimentSkill\": true,\n  \"#Microsoft.Skills.Text.SplitSkill\": true,\n  \"#Microsoft.Skills.Text.TranslationSkill\": true,\n  \"#Microsoft.Skills.Text.V3.EntityLinkingSkill\": true,\n  \"#Microsoft.Skills.Text.V3.EntityRecognitionSkill\": true,\n  \"#Microsoft.Skills.Text.V3.SentimentSkill\": true,\n  \"#Microsoft.Skills.Util.ConditionalSkill\": true,\n  \"#Microsoft.Skills.Util.DocumentExtractionSkill\": true,\n  \"#Microsoft.Skills.Util.ShaperSkill\": true,\n  \"#Microsoft.Skills.Vision.ImageAnalysisSkill\": true,\n  \"#Microsoft.Skills.Vision.OcrSkill\": true,\n};\n\nexport function convertSkillsToPublic(skills: SearchIndexerSkillUnion[]): SearchIndexerSkill[] {\n  if (!skills) {\n    return skills;\n  }\n\n  // This validation has already GAed\n  return skills.filter((skill): skill is SearchIndexerSkill => knownSkills[skill.odatatype]);\n}\n\nexport function convertCognitiveServicesAccountToGenerated(\n  cognitiveServicesAccount?: CognitiveServicesAccount,\n): CognitiveServicesAccountUnion | undefined {\n  if (!cognitiveServicesAccount) {\n    return cognitiveServicesAccount;\n  }\n\n  return cognitiveServicesAccount as CognitiveServicesAccountUnion;\n}\n\nexport function convertCognitiveServicesAccountToPublic(\n  cognitiveServicesAccount?: CognitiveServicesAccountUnion,\n): CognitiveServicesAccount | undefined {\n  if (!cognitiveServicesAccount) {\n    return cognitiveServicesAccount;\n  }\n\n  if (cognitiveServicesAccount.odatatype === \"#Microsoft.Azure.Search.DefaultCognitiveServices\") {\n    return cognitiveServicesAccount as DefaultCognitiveServicesAccount;\n  } else {\n    return cognitiveServicesAccount as CognitiveServicesAccountKey;\n  }\n}\n\nexport function convertTokenFiltersToGenerated(\n  tokenFilters?: TokenFilter[],\n): TokenFilterUnion[] | undefined {\n  if (!tokenFilters) {\n    return tokenFilters;\n  }\n\n  const result: TokenFilterUnion[] = [];\n  for (const filter of tokenFilters) {\n    result.push(filter);\n  }\n\n  return result;\n}\n\nfunction convertAnalyzersToGenerated(\n  analyzers?: LexicalAnalyzer[],\n): LexicalAnalyzerUnion[] | undefined {\n  if (!analyzers) {\n    return analyzers;\n  }\n\n  const result: LexicalAnalyzerUnion[] = [];\n  for (const analyzer of analyzers) {\n    switch (analyzer.odatatype) {\n      case \"#Microsoft.Azure.Search.StandardAnalyzer\":\n      case \"#Microsoft.Azure.Search.StopAnalyzer\":\n        result.push(analyzer);\n        break;\n      case \"#Microsoft.Azure.Search.PatternAnalyzer\":\n        result.push({\n          ...analyzer,\n          flags: analyzer.flags ? analyzer.flags.join(\"|\") : undefined,\n        });\n        break;\n      case \"#Microsoft.Azure.Search.CustomAnalyzer\":\n        result.push({\n          ...analyzer,\n          tokenizerName: analyzer.tokenizerName,\n        });\n        break;\n    }\n  }\n  return result;\n}\n\nfunction convertAnalyzersToPublic(\n  analyzers?: LexicalAnalyzerUnion[],\n): LexicalAnalyzer[] | undefined {\n  if (!analyzers) {\n    return analyzers;\n  }\n\n  const result: LexicalAnalyzer[] = [];\n  for (const analyzer of analyzers) {\n    switch (analyzer.odatatype) {\n      case \"#Microsoft.Azure.Search.StandardAnalyzer\":\n        result.push(analyzer as LuceneStandardAnalyzer);\n        break;\n      case \"#Microsoft.Azure.Search.StopAnalyzer\":\n        result.push(analyzer as StopAnalyzer);\n        break;\n      case \"#Microsoft.Azure.Search.PatternAnalyzer\":\n        result.push({\n          ...analyzer,\n          flags: (analyzer as GeneratedPatternAnalyzer).flags\n            ? ((analyzer as GeneratedPatternAnalyzer).flags!.split(\"|\") as RegexFlags[])\n            : undefined,\n        } as PatternAnalyzer);\n        break;\n      case \"#Microsoft.Azure.Search.CustomAnalyzer\":\n        result.push(analyzer as BaseCustomAnalyzer);\n        break;\n    }\n  }\n  return result;\n}\n\nexport function convertFieldsToPublic(fields: GeneratedSearchField[]): SearchField[] {\n  if (!fields) {\n    return fields;\n  }\n\n  return fields.map<SearchField>((field): SearchField => {\n    if (field.type === \"Collection(Edm.ComplexType)\" || field.type === \"Edm.ComplexType\") {\n      const result: ComplexField = {\n        name: field.name,\n        type: field.type,\n        fields: convertFieldsToPublic(field.fields!),\n      };\n      return result;\n    } else {\n      const type: SearchFieldDataType = field.type as SearchFieldDataType;\n      const synonymMapNames: string[] | undefined = field.synonymMaps;\n\n      const { retrievable, analyzer, searchAnalyzer, indexAnalyzer, ...restField } = field;\n      const hidden = typeof retrievable === \"boolean\" ? !retrievable : retrievable;\n\n      const result: SimpleField = {\n        ...restField,\n        type,\n        hidden,\n        analyzerName: analyzer,\n        searchAnalyzerName: searchAnalyzer,\n        indexAnalyzerName: indexAnalyzer,\n        synonymMapNames,\n      };\n      return result;\n    }\n  });\n}\n\nexport function convertFieldsToGenerated(fields: SearchField[]): GeneratedSearchField[] {\n  return fields.map<GeneratedSearchField>((field) => {\n    if (isComplexField(field)) {\n      return {\n        name: field.name,\n        type: field.type,\n        fields: field.fields ? convertFieldsToGenerated(field.fields) : field.fields,\n      };\n    } else {\n      const { hidden, ...restField } = field;\n      const retrievable = typeof hidden === \"boolean\" ? !hidden : hidden;\n      return {\n        ...restField,\n        retrievable,\n        // modify API defaults to use less storage for simple types\n        searchable: field.searchable ?? false,\n        filterable: field.filterable ?? false,\n        facetable: field.facetable ?? false,\n        sortable: field.sortable ?? false,\n        analyzer: field.analyzerName,\n        searchAnalyzer: field.searchAnalyzerName,\n        indexAnalyzer: field.indexAnalyzerName,\n        synonymMaps: field.synonymMapNames,\n      };\n    }\n  });\n}\n\nfunction convertTokenizersToGenerated(\n  tokenizers?: LexicalTokenizer[],\n): LexicalTokenizerUnion[] | undefined {\n  if (!tokenizers) {\n    return tokenizers;\n  }\n\n  const result: LexicalTokenizerUnion[] = [];\n  for (const tokenizer of tokenizers) {\n    if (tokenizer.odatatype === \"#Microsoft.Azure.Search.PatternTokenizer\") {\n      result.push({\n        ...tokenizer,\n        flags: tokenizer.flags ? tokenizer.flags.join(\"|\") : undefined,\n      });\n    } else {\n      result.push(tokenizer);\n    }\n  }\n  return result;\n}\n\nfunction convertTokenizersToPublic(\n  tokenizers?: LexicalTokenizerUnion[],\n): LexicalTokenizer[] | undefined {\n  if (!tokenizers) {\n    return tokenizers;\n  }\n\n  const result: LexicalTokenizer[] = [];\n  for (const tokenizer of tokenizers) {\n    if (tokenizer.odatatype === \"#Microsoft.Azure.Search.PatternTokenizer\") {\n      const patternTokenizer = tokenizer as PatternTokenizer;\n      const flags = patternTokenizer.flags?.split(\"|\") as RegexFlags[] | undefined;\n      result.push({\n        ...tokenizer,\n        flags,\n      });\n    } else {\n      result.push(tokenizer);\n    }\n  }\n  return result;\n}\n\nexport function convertSimilarityToGenerated(\n  similarity?: SimilarityAlgorithm,\n): SimilarityUnion | undefined {\n  if (!similarity) {\n    return similarity;\n  }\n\n  return similarity as SimilarityUnion;\n}\n\nexport function convertSimilarityToPublic(\n  similarity?: SimilarityUnion,\n): SimilarityAlgorithm | undefined {\n  if (!similarity) {\n    return similarity;\n  }\n\n  if (similarity.odatatype === \"#Microsoft.Azure.Search.ClassicSimilarity\") {\n    return similarity as ClassicSimilarity;\n  } else {\n    return similarity as BM25Similarity;\n  }\n}\n\nfunction convertEncryptionKeyToPublic(\n  encryptionKey?: GeneratedSearchResourceEncryptionKey,\n): SearchResourceEncryptionKey | undefined {\n  if (!encryptionKey) {\n    return encryptionKey;\n  }\n\n  const result: SearchResourceEncryptionKey = {\n    keyName: encryptionKey.keyName,\n    keyVersion: encryptionKey.keyVersion,\n    vaultUrl: encryptionKey.vaultUri,\n  };\n\n  if (encryptionKey.accessCredentials) {\n    result.applicationId = encryptionKey.accessCredentials.applicationId;\n    result.applicationSecret = encryptionKey.accessCredentials.applicationSecret;\n  }\n\n  return result;\n}\n\nfunction convertEncryptionKeyToGenerated(\n  encryptionKey?: SearchResourceEncryptionKey,\n): GeneratedSearchResourceEncryptionKey | undefined {\n  if (!encryptionKey) {\n    return encryptionKey;\n  }\n\n  const result: GeneratedSearchResourceEncryptionKey = {\n    keyName: encryptionKey.keyName,\n    keyVersion: encryptionKey.keyVersion,\n    vaultUri: encryptionKey.vaultUrl,\n  };\n\n  if (encryptionKey.applicationId) {\n    result.accessCredentials = {\n      applicationId: encryptionKey.applicationId,\n      applicationSecret: encryptionKey.applicationSecret,\n    };\n  }\n\n  return result;\n}\n\nexport function generatedIndexToPublicIndex(generatedIndex: GeneratedSearchIndex): SearchIndex {\n  return {\n    name: generatedIndex.name,\n    defaultScoringProfile: generatedIndex.defaultScoringProfile,\n    corsOptions: generatedIndex.corsOptions,\n    suggesters: generatedIndex.suggesters,\n    encryptionKey: convertEncryptionKeyToPublic(generatedIndex.encryptionKey),\n    etag: generatedIndex.etag,\n    analyzers: convertAnalyzersToPublic(generatedIndex.analyzers),\n    tokenizers: convertTokenizersToPublic(generatedIndex.tokenizers),\n    tokenFilters: generatedIndex.tokenFilters as TokenFilter[],\n    charFilters: generatedIndex.charFilters as CharFilter[],\n    scoringProfiles: generatedIndex.scoringProfiles as ScoringProfile[],\n    fields: convertFieldsToPublic(generatedIndex.fields),\n    similarity: convertSimilarityToPublic(generatedIndex.similarity),\n    semanticSearch: generatedIndex.semanticSearch,\n    vectorSearch: generatedVectorSearchToPublicVectorSearch(generatedIndex.vectorSearch),\n  };\n}\n\nexport function generatedVectorSearchVectorizerToPublicVectorizer(): undefined;\nexport function generatedVectorSearchVectorizerToPublicVectorizer(\n  generatedVectorizer: GeneratedVectorSearchVectorizer,\n): VectorSearchVectorizer;\nexport function generatedVectorSearchVectorizerToPublicVectorizer(\n  generatedVectorizer?: GeneratedVectorSearchVectorizer,\n): VectorSearchVectorizer | undefined {\n  if (!generatedVectorizer) {\n    return generatedVectorizer;\n  }\n\n  switch (generatedVectorizer.kind) {\n    case \"azureOpenAI\": {\n      const { parameters } = generatedVectorizer as GeneratedAzureOpenAIVectorizer;\n      const authIdentity = convertSearchIndexerDataIdentityToPublic(parameters?.authIdentity);\n      const vectorizer: AzureOpenAIVectorizer = {\n        ...(generatedVectorizer as GeneratedAzureOpenAIVectorizer),\n        parameters: { ...parameters, authIdentity },\n      };\n      return vectorizer;\n    }\n    case \"customWebApi\": {\n      const { parameters } = generatedVectorizer as GeneratedWebAPIVectorizer;\n      const authIdentity = convertSearchIndexerDataIdentityToPublic(parameters?.authIdentity);\n      const vectorizer: WebApiVectorizer = {\n        ...(generatedVectorizer as GeneratedWebAPIVectorizer),\n        parameters: { ...parameters, authIdentity },\n      };\n      return vectorizer;\n    }\n  }\n  logger.warning(`Unsupported vectorizer kind: ${(generatedVectorizer as any).kind}`);\n  return generatedVectorizer as any;\n}\n\nexport function generatedVectorSearchAlgorithmConfigurationToPublicVectorSearchAlgorithmConfiguration(): undefined;\nexport function generatedVectorSearchAlgorithmConfigurationToPublicVectorSearchAlgorithmConfiguration(\n  generatedAlgorithmConfiguration: GeneratedVectorSearchAlgorithmConfiguration,\n): VectorSearchAlgorithmConfiguration;\nexport function generatedVectorSearchAlgorithmConfigurationToPublicVectorSearchAlgorithmConfiguration(\n  generatedAlgorithmConfiguration?: GeneratedVectorSearchAlgorithmConfiguration,\n): VectorSearchAlgorithmConfiguration | undefined {\n  if (!generatedAlgorithmConfiguration) {\n    return generatedAlgorithmConfiguration;\n  }\n\n  if ([\"hnsw\", \"exhaustiveKnn\"].includes(generatedAlgorithmConfiguration.kind)) {\n    const algorithmConfiguration = generatedAlgorithmConfiguration as\n      | GeneratedHnswAlgorithmConfiguration\n      | GeneratedExhaustiveKnnAlgorithmConfiguration;\n    const metric = algorithmConfiguration.parameters?.metric as VectorSearchAlgorithmMetric;\n    return {\n      ...algorithmConfiguration,\n      parameters: { ...algorithmConfiguration.parameters, metric },\n    };\n  }\n\n  throw Error(\"Unsupported algorithm configuration\");\n}\n\nexport function generatedVectorSearchToPublicVectorSearch(\n  vectorSearch?: GeneratedVectorSearch,\n): VectorSearch | undefined {\n  if (!vectorSearch) {\n    return vectorSearch;\n  }\n\n  return {\n    ...vectorSearch,\n    algorithms: vectorSearch.algorithms?.map(\n      generatedVectorSearchAlgorithmConfigurationToPublicVectorSearchAlgorithmConfiguration,\n    ),\n    vectorizers: vectorSearch.vectorizers?.map(generatedVectorSearchVectorizerToPublicVectorizer),\n  };\n}\n\nexport function generatedSearchResultToPublicSearchResult<\n  TModel extends object,\n  TFields extends SelectFields<TModel>,\n>(results: GeneratedSearchResult[]): SearchResult<TModel, TFields>[] {\n  const returnValues: SearchResult<TModel, TFields>[] = results.map<SearchResult<TModel, TFields>>(\n    (result) => {\n      const {\n        _score: score,\n        _highlights: highlights,\n        _rerankerScore: rerankerScore,\n        _captions: captions,\n        ...restProps\n      } = result;\n      const obj = {\n        score,\n        highlights,\n        rerankerScore,\n        captions,\n        document: restProps,\n      };\n      return obj as SearchResult<TModel, TFields>;\n    },\n  );\n  return returnValues;\n}\n\nexport function generatedSuggestDocumentsResultToPublicSuggestDocumentsResult<\n  TModel extends object,\n  TFields extends SelectFields<TModel>,\n>(searchDocumentsResult: GeneratedSuggestDocumentsResult): SuggestDocumentsResult<TModel, TFields> {\n  const results = searchDocumentsResult.results.map<SuggestResult<TModel, TFields>>((element) => {\n    const { _text, ...restProps } = element;\n\n    const obj = {\n      text: _text,\n      document: restProps,\n    };\n\n    return obj as SuggestResult<TModel, TFields>;\n  });\n\n  const result: SuggestDocumentsResult<TModel, TFields> = {\n    results: results,\n    coverage: searchDocumentsResult.coverage,\n  };\n\n  return result;\n}\n\nexport function publicIndexToGeneratedIndex(index: SearchIndex): GeneratedSearchIndex {\n  const { encryptionKey, tokenFilters, analyzers, tokenizers, fields, similarity } = index;\n\n  return {\n    ...index,\n    encryptionKey: convertEncryptionKeyToGenerated(encryptionKey),\n    tokenFilters: convertTokenFiltersToGenerated(tokenFilters),\n    analyzers: convertAnalyzersToGenerated(analyzers),\n    tokenizers: convertTokenizersToGenerated(tokenizers),\n    fields: convertFieldsToGenerated(fields),\n    similarity: convertSimilarityToGenerated(similarity),\n  };\n}\n\nexport function generatedSkillsetToPublicSkillset(\n  generatedSkillset: GeneratedSearchIndexerSkillset,\n): SearchIndexerSkillset {\n  const { skills, cognitiveServicesAccount, encryptionKey, indexProjection, ...props } =\n    generatedSkillset;\n  return {\n    ...props,\n    skills: convertSkillsToPublic(skills),\n    cognitiveServicesAccount: convertCognitiveServicesAccountToPublic(cognitiveServicesAccount),\n    encryptionKey: convertEncryptionKeyToPublic(encryptionKey),\n    indexProjection: indexProjection as SearchIndexerIndexProjection,\n  };\n}\n\nexport function publicSkillsetToGeneratedSkillset(\n  skillset: SearchIndexerSkillset,\n): GeneratedSearchIndexerSkillset {\n  return {\n    ...skillset,\n    name: skillset.name,\n    description: skillset.description,\n    etag: skillset.etag,\n    skills: skillset.skills,\n    cognitiveServicesAccount: convertCognitiveServicesAccountToGenerated(\n      skillset.cognitiveServicesAccount,\n    ),\n    knowledgeStore: skillset.knowledgeStore,\n    encryptionKey: convertEncryptionKeyToGenerated(skillset.encryptionKey),\n  };\n}\n\nexport function generatedSynonymMapToPublicSynonymMap(synonymMap: GeneratedSynonymMap): SynonymMap {\n  const result: SynonymMap = {\n    name: synonymMap.name,\n    encryptionKey: convertEncryptionKeyToPublic(synonymMap.encryptionKey),\n    etag: synonymMap.etag,\n    synonyms: [],\n  };\n\n  if (synonymMap.synonyms) {\n    result.synonyms = synonymMap.synonyms.split(\"\\n\");\n  }\n\n  return result;\n}\n\nexport function publicSynonymMapToGeneratedSynonymMap(synonymMap: SynonymMap): GeneratedSynonymMap {\n  const result: GeneratedSynonymMap = {\n    name: synonymMap.name,\n    format: \"solr\",\n    encryptionKey: convertEncryptionKeyToGenerated(synonymMap.encryptionKey),\n    etag: synonymMap.etag,\n    synonyms: synonymMap.synonyms.join(\"\\n\"),\n  };\n\n  result.encryptionKey = convertEncryptionKeyToGenerated(synonymMap.encryptionKey);\n\n  return result;\n}\n\nexport function publicSearchIndexerToGeneratedSearchIndexer(\n  indexer: SearchIndexer,\n): GeneratedSearchIndexer {\n  return {\n    ...indexer,\n    encryptionKey: convertEncryptionKeyToGenerated(indexer.encryptionKey),\n  };\n}\n\nexport function generatedSearchIndexerToPublicSearchIndexer(\n  indexer: GeneratedSearchIndexer,\n): SearchIndexer {\n  const {\n    parsingMode,\n    dataToExtract,\n    imageAction,\n    pdfTextRotationAlgorithm,\n    executionEnvironment,\n  } = indexer.parameters?.configuration ?? {};\n\n  const configuration: IndexingParametersConfiguration | undefined = indexer.parameters\n    ?.configuration && {\n    ...indexer.parameters?.configuration,\n    parsingMode: parsingMode as BlobIndexerParsingMode | undefined,\n    dataToExtract: dataToExtract as BlobIndexerDataToExtract | undefined,\n    imageAction: imageAction as BlobIndexerImageAction | undefined,\n    pdfTextRotationAlgorithm: pdfTextRotationAlgorithm as\n      | BlobIndexerPDFTextRotationAlgorithm\n      | undefined,\n    executionEnvironment: executionEnvironment as IndexerExecutionEnvironment | undefined,\n  };\n  const parameters: IndexingParameters = {\n    ...indexer.parameters,\n    configuration,\n  };\n\n  return {\n    ...indexer,\n    parameters,\n    encryptionKey: convertEncryptionKeyToPublic(indexer.encryptionKey),\n  };\n}\n\nexport function publicDataSourceToGeneratedDataSource(\n  dataSource: SearchIndexerDataSourceConnection,\n): GeneratedSearchIndexerDataSourceConnection {\n  return {\n    name: dataSource.name,\n    description: dataSource.description,\n    type: dataSource.type,\n    credentials: {\n      connectionString: dataSource.connectionString,\n    },\n    container: dataSource.container,\n    etag: dataSource.etag,\n    dataChangeDetectionPolicy: dataSource.dataChangeDetectionPolicy,\n    dataDeletionDetectionPolicy: dataSource.dataDeletionDetectionPolicy,\n    encryptionKey: convertEncryptionKeyToGenerated(dataSource.encryptionKey),\n  };\n}\n\nexport function generatedDataSourceToPublicDataSource(\n  dataSource: GeneratedSearchIndexerDataSourceConnection,\n): SearchIndexerDataSourceConnection {\n  return {\n    name: dataSource.name,\n    description: dataSource.name,\n    type: dataSource.type as SearchIndexerDataSourceType,\n    connectionString: dataSource.credentials.connectionString,\n    container: dataSource.container,\n    etag: dataSource.etag,\n    dataChangeDetectionPolicy: convertDataChangeDetectionPolicyToPublic(\n      dataSource.dataChangeDetectionPolicy,\n    ),\n    dataDeletionDetectionPolicy: convertDataDeletionDetectionPolicyToPublic(\n      dataSource.dataDeletionDetectionPolicy,\n    ),\n    encryptionKey: convertEncryptionKeyToPublic(dataSource.encryptionKey),\n  };\n}\n\nexport function convertSearchIndexerDataIdentityToPublic(\n  searchIndexerDataIdentity?: SearchIndexerDataIdentityUnion,\n): SearchIndexerDataIdentity | undefined {\n  if (!searchIndexerDataIdentity) {\n    return searchIndexerDataIdentity;\n  }\n\n  if (searchIndexerDataIdentity.odatatype === \"#Microsoft.Azure.Search.DataNoneIdentity\") {\n    return searchIndexerDataIdentity as SearchIndexerDataNoneIdentity;\n  } else {\n    return searchIndexerDataIdentity as SearchIndexerDataUserAssignedIdentity;\n  }\n}\n\nexport function convertDataChangeDetectionPolicyToPublic(\n  dataChangeDetectionPolicy?: DataChangeDetectionPolicyUnion,\n): DataChangeDetectionPolicy | undefined {\n  if (!dataChangeDetectionPolicy) {\n    return dataChangeDetectionPolicy;\n  }\n\n  if (\n    dataChangeDetectionPolicy.odatatype ===\n    \"#Microsoft.Azure.Search.HighWaterMarkChangeDetectionPolicy\"\n  ) {\n    return dataChangeDetectionPolicy as HighWaterMarkChangeDetectionPolicy;\n  } else {\n    return dataChangeDetectionPolicy as SqlIntegratedChangeTrackingPolicy;\n  }\n}\n\nexport function convertDataDeletionDetectionPolicyToPublic(\n  dataDeletionDetectionPolicy?: DataDeletionDetectionPolicyUnion,\n): DataDeletionDetectionPolicy | undefined {\n  if (!dataDeletionDetectionPolicy) {\n    return dataDeletionDetectionPolicy;\n  }\n\n  return dataDeletionDetectionPolicy as SoftDeleteColumnDeletionDetectionPolicy;\n}\n\nexport function getRandomIntegerInclusive(min: number, max: number): number {\n  // Make sure inputs are integers.\n  min = Math.ceil(min);\n  max = Math.floor(max);\n  // Pick a random offset from zero to the size of the range.\n  // Since Math.random() can never return 1, we have to make the range one larger\n  // in order to be inclusive of the maximum value after we take the floor.\n  const offset = Math.floor(Math.random() * (max - min + 1));\n  return offset + min;\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8ClC,OAAO,EAAE,MAAM,EAAE,MAAM,UAAU,CAAC;AAClC,OAAO,EAcL,cAAc,GA0Bf,MAAM,iBAAiB,CAAC;;;;AAElB,MAAM,qBAAqB,GAAG,YAAY,CAAC;AAElD,MAAM,WAAW,GAA4D;IAC3E,sCAAsC,EAAE,IAAI;IAC5C,kDAAkD,EAAE,IAAI;IACxD,gDAAgD,EAAE,IAAI;IACtD,+CAA+C,EAAE,IAAI;IACrD,iDAAiD,EAAE,IAAI;IACvD,+CAA+C,EAAE,IAAI;IACrD,mCAAmC,EAAE,IAAI;IACzC,0CAA0C,EAAE,IAAI;IAChD,uCAAuC,EAAE,IAAI;IAC7C,mCAAmC,EAAE,IAAI;IACzC,yCAAyC,EAAE,IAAI;IAC/C,8CAA8C,EAAE,IAAI;IACpD,kDAAkD,EAAE,IAAI;IACxD,0CAA0C,EAAE,IAAI;IAChD,yCAAyC,EAAE,IAAI;IAC/C,gDAAgD,EAAE,IAAI;IACtD,oCAAoC,EAAE,IAAI;IAC1C,6CAA6C,EAAE,IAAI;IACnD,mCAAmC,EAAE,IAAI;CAC1C,CAAC;AAEI,SAAU,qBAAqB,CAAC,MAAiC;IACrE,IAAI,CAAC,MAAM,EAAE,CAAC;QACZ,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,mCAAmC;IACnC,OAAO,MAAM,CAAC,MAAM,CAAC,CAAC,KAAK,EAA+B,CAAG,CAAD,UAAY,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC,CAAC;AAC7F,CAAC;AAEK,SAAU,0CAA0C,CACxD,wBAAmD;IAEnD,IAAI,CAAC,wBAAwB,EAAE,CAAC;QAC9B,OAAO,wBAAwB,CAAC;IAClC,CAAC;IAED,OAAO,wBAAyD,CAAC;AACnE,CAAC;AAEK,SAAU,uCAAuC,CACrD,wBAAwD;IAExD,IAAI,CAAC,wBAAwB,EAAE,CAAC;QAC9B,OAAO,wBAAwB,CAAC;IAClC,CAAC;IAED,IAAI,wBAAwB,CAAC,SAAS,KAAK,kDAAkD,EAAE,CAAC;QAC9F,OAAO,wBAA2D,CAAC;IACrE,CAAC,MAAM,CAAC;QACN,OAAO,wBAAuD,CAAC;IACjE,CAAC;AACH,CAAC;AAEK,SAAU,8BAA8B,CAC5C,YAA4B;IAE5B,IAAI,CAAC,YAAY,EAAE,CAAC;QAClB,OAAO,YAAY,CAAC;IACtB,CAAC;IAED,MAAM,MAAM,GAAuB,EAAE,CAAC;IACtC,KAAK,MAAM,MAAM,IAAI,YAAY,CAAE,CAAC;QAClC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;IACtB,CAAC;IAED,OAAO,MAAM,CAAC;AAChB,CAAC;AAED,SAAS,2BAA2B,CAClC,SAA6B;IAE7B,IAAI,CAAC,SAAS,EAAE,CAAC;QACf,OAAO,SAAS,CAAC;IACnB,CAAC;IAED,MAAM,MAAM,GAA2B,EAAE,CAAC;IAC1C,KAAK,MAAM,QAAQ,IAAI,SAAS,CAAE,CAAC;QACjC,OAAQ,QAAQ,CAAC,SAAS,EAAE,CAAC;YAC3B,KAAK,0CAA0C,CAAC;YAChD,KAAK,sCAAsC;gBACzC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;gBACtB,MAAM;YACR,KAAK,yCAAyC;gBAC5C,MAAM,CAAC,IAAI,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACN,QAAQ,GAAA;oBACX,KAAK,EAAE,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,SAAS;gBAAA,GAC5D,CAAC;gBACH,MAAM;YACR,KAAK,wCAAwC;gBAC3C,MAAM,CAAC,IAAI,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACN,QAAQ,GAAA;oBACX,aAAa,EAAE,QAAQ,CAAC,aAAa;gBAAA,GACrC,CAAC;gBACH,MAAM;QACV,CAAC;IACH,CAAC;IACD,OAAO,MAAM,CAAC;AAChB,CAAC;AAED,SAAS,wBAAwB,CAC/B,SAAkC;IAElC,IAAI,CAAC,SAAS,EAAE,CAAC;QACf,OAAO,SAAS,CAAC;IACnB,CAAC;IAED,MAAM,MAAM,GAAsB,EAAE,CAAC;IACrC,KAAK,MAAM,QAAQ,IAAI,SAAS,CAAE,CAAC;QACjC,OAAQ,QAAQ,CAAC,SAAS,EAAE,CAAC;YAC3B,KAAK,0CAA0C;gBAC7C,MAAM,CAAC,IAAI,CAAC,QAAkC,CAAC,CAAC;gBAChD,MAAM;YACR,KAAK,sCAAsC;gBACzC,MAAM,CAAC,IAAI,CAAC,QAAwB,CAAC,CAAC;gBACtC,MAAM;YACR,KAAK,yCAAyC;gBAC5C,MAAM,CAAC,IAAI,CAAC,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACP,QAAQ,GAAA;oBACX,KAAK,EAAG,QAAqC,CAAC,KAAK,GAC7C,QAAqC,CAAC,KAAM,CAAC,KAAK,CAAC,GAAG,CAAkB,GAC1E,SAAS;gBAAA,EACK,CAAC,CAAC;gBACtB,MAAM;YACR,KAAK,wCAAwC;gBAC3C,MAAM,CAAC,IAAI,CAAC,QAA8B,CAAC,CAAC;gBAC5C,MAAM;QACV,CAAC;IACH,CAAC;IACD,OAAO,MAAM,CAAC;AAChB,CAAC;AAEK,SAAU,qBAAqB,CAAC,MAA8B;IAClE,IAAI,CAAC,MAAM,EAAE,CAAC;QACZ,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,OAAO,MAAM,CAAC,GAAG,CAAc,CAAC,KAAK,EAAe,EAAE;QACpD,IAAI,KAAK,CAAC,IAAI,KAAK,6BAA6B,IAAI,KAAK,CAAC,IAAI,KAAK,iBAAiB,EAAE,CAAC;YACrF,MAAM,MAAM,GAAiB;gBAC3B,IAAI,EAAE,KAAK,CAAC,IAAI;gBAChB,IAAI,EAAE,KAAK,CAAC,IAAI;gBAChB,MAAM,EAAE,qBAAqB,CAAC,KAAK,CAAC,MAAO,CAAC;aAC7C,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,MAAM,CAAC;YACN,MAAM,IAAI,GAAwB,KAAK,CAAC,IAA2B,CAAC;YACpE,MAAM,eAAe,GAAyB,KAAK,CAAC,WAAW,CAAC;YAEhE,MAAM,EAAE,WAAW,EAAE,QAAQ,EAAE,cAAc,EAAE,aAAa,EAAA,GAAmB,KAAK,EAAnB,SAAS,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAAK,KAAK,EAA9E;gBAAA;gBAAA;gBAAA;gBAAA;aAAsE,CAAQ,CAAC;YACrF,MAAM,MAAM,GAAG,OAAO,WAAW,KAAK,SAAS,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,WAAW,CAAC;YAE7E,MAAM,MAAM,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACP,SAAS,GAAA;gBACZ,IAAI;gBACJ,MAAM;gBACN,YAAY,EAAE,QAAQ;gBACtB,kBAAkB,EAAE,cAAc;gBAClC,iBAAiB,EAAE,aAAa;gBAChC,eAAe;YAAA,EAChB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC;IACH,CAAC,CAAC,CAAC;AACL,CAAC;AAEK,SAAU,wBAAwB,CAAC,MAAqB;IAC5D,OAAO,MAAM,CAAC,GAAG,CAAuB,CAAC,KAAK,EAAE,EAAE;;QAChD,gMAAI,iBAAc,AAAd,EAAe,KAAK,CAAC,EAAE,CAAC;YAC1B,OAAO;gBACL,IAAI,EAAE,KAAK,CAAC,IAAI;gBAChB,IAAI,EAAE,KAAK,CAAC,IAAI;gBAChB,MAAM,EAAE,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,wBAAwB,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,MAAM;aAC7E,CAAC;QACJ,CAAC,MAAM,CAAC;YACN,MAAM,EAAE,MAAM,EAAA,GAAmB,KAAK,EAAnB,SAAS,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAAK,KAAK,EAAhC;gBAAA;aAAwB,CAAQ,CAAC;YACvC,MAAM,WAAW,GAAG,OAAO,MAAM,KAAK,SAAS,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC;YACnE,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,SAAS,GAAA;gBACZ,WAAW;gBACX,2DAA2D;gBAC3D,UAAU,EAAE,CAAA,KAAA,KAAK,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK;gBACrC,UAAU,EAAE,CAAA,KAAA,KAAK,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK;gBACrC,SAAS,EAAE,CAAA,KAAA,KAAK,CAAC,SAAS,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK;gBACnC,QAAQ,EAAE,CAAA,KAAA,KAAK,CAAC,QAAQ,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK;gBACjC,QAAQ,EAAE,KAAK,CAAC,YAAY;gBAC5B,cAAc,EAAE,KAAK,CAAC,kBAAkB;gBACxC,aAAa,EAAE,KAAK,CAAC,iBAAiB;gBACtC,WAAW,EAAE,KAAK,CAAC,eAAe;YAAA,GAClC;QACJ,CAAC;IACH,CAAC,CAAC,CAAC;AACL,CAAC;AAED,SAAS,4BAA4B,CACnC,UAA+B;IAE/B,IAAI,CAAC,UAAU,EAAE,CAAC;QAChB,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,MAAM,MAAM,GAA4B,EAAE,CAAC;IAC3C,KAAK,MAAM,SAAS,IAAI,UAAU,CAAE,CAAC;QACnC,IAAI,SAAS,CAAC,SAAS,KAAK,0CAA0C,EAAE,CAAC;YACvE,MAAM,CAAC,IAAI,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACN,SAAS,GAAA;gBACZ,KAAK,EAAE,SAAS,CAAC,KAAK,CAAC,CAAC,CAAC,SAAS,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,SAAS;YAAA,GAC9D,CAAC;QACL,CAAC,MAAM,CAAC;YACN,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QACzB,CAAC;IACH,CAAC;IACD,OAAO,MAAM,CAAC;AAChB,CAAC;AAED,SAAS,yBAAyB,CAChC,UAAoC;;IAEpC,IAAI,CAAC,UAAU,EAAE,CAAC;QAChB,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,MAAM,MAAM,GAAuB,EAAE,CAAC;IACtC,KAAK,MAAM,SAAS,IAAI,UAAU,CAAE,CAAC;QACnC,IAAI,SAAS,CAAC,SAAS,KAAK,0CAA0C,EAAE,CAAC;YACvE,MAAM,gBAAgB,GAAG,SAA6B,CAAC;YACvD,MAAM,KAAK,GAAG,CAAA,KAAA,gBAAgB,CAAC,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,KAAK,CAAC,GAAG,CAA6B,CAAC;YAC7E,MAAM,CAAC,IAAI,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACN,SAAS,GAAA;gBACZ,KAAK;YAAA,GACL,CAAC;QACL,CAAC,MAAM,CAAC;YACN,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QACzB,CAAC;IACH,CAAC;IACD,OAAO,MAAM,CAAC;AAChB,CAAC;AAEK,SAAU,4BAA4B,CAC1C,UAAgC;IAEhC,IAAI,CAAC,UAAU,EAAE,CAAC;QAChB,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,OAAO,UAA6B,CAAC;AACvC,CAAC;AAEK,SAAU,yBAAyB,CACvC,UAA4B;IAE5B,IAAI,CAAC,UAAU,EAAE,CAAC;QAChB,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,IAAI,UAAU,CAAC,SAAS,KAAK,2CAA2C,EAAE,CAAC;QACzE,OAAO,UAA+B,CAAC;IACzC,CAAC,MAAM,CAAC;QACN,OAAO,UAA4B,CAAC;IACtC,CAAC;AACH,CAAC;AAED,SAAS,4BAA4B,CACnC,aAAoD;IAEpD,IAAI,CAAC,aAAa,EAAE,CAAC;QACnB,OAAO,aAAa,CAAC;IACvB,CAAC;IAED,MAAM,MAAM,GAAgC;QAC1C,OAAO,EAAE,aAAa,CAAC,OAAO;QAC9B,UAAU,EAAE,aAAa,CAAC,UAAU;QACpC,QAAQ,EAAE,aAAa,CAAC,QAAQ;KACjC,CAAC;IAEF,IAAI,aAAa,CAAC,iBAAiB,EAAE,CAAC;QACpC,MAAM,CAAC,aAAa,GAAG,aAAa,CAAC,iBAAiB,CAAC,aAAa,CAAC;QACrE,MAAM,CAAC,iBAAiB,GAAG,aAAa,CAAC,iBAAiB,CAAC,iBAAiB,CAAC;IAC/E,CAAC;IAED,OAAO,MAAM,CAAC;AAChB,CAAC;AAED,SAAS,+BAA+B,CACtC,aAA2C;IAE3C,IAAI,CAAC,aAAa,EAAE,CAAC;QACnB,OAAO,aAAa,CAAC;IACvB,CAAC;IAED,MAAM,MAAM,GAAyC;QACnD,OAAO,EAAE,aAAa,CAAC,OAAO;QAC9B,UAAU,EAAE,aAAa,CAAC,UAAU;QACpC,QAAQ,EAAE,aAAa,CAAC,QAAQ;KACjC,CAAC;IAEF,IAAI,aAAa,CAAC,aAAa,EAAE,CAAC;QAChC,MAAM,CAAC,iBAAiB,GAAG;YACzB,aAAa,EAAE,aAAa,CAAC,aAAa;YAC1C,iBAAiB,EAAE,aAAa,CAAC,iBAAiB;SACnD,CAAC;IACJ,CAAC;IAED,OAAO,MAAM,CAAC;AAChB,CAAC;AAEK,SAAU,2BAA2B,CAAC,cAAoC;IAC9E,OAAO;QACL,IAAI,EAAE,cAAc,CAAC,IAAI;QACzB,qBAAqB,EAAE,cAAc,CAAC,qBAAqB;QAC3D,WAAW,EAAE,cAAc,CAAC,WAAW;QACvC,UAAU,EAAE,cAAc,CAAC,UAAU;QACrC,aAAa,EAAE,4BAA4B,CAAC,cAAc,CAAC,aAAa,CAAC;QACzE,IAAI,EAAE,cAAc,CAAC,IAAI;QACzB,SAAS,EAAE,wBAAwB,CAAC,cAAc,CAAC,SAAS,CAAC;QAC7D,UAAU,EAAE,yBAAyB,CAAC,cAAc,CAAC,UAAU,CAAC;QAChE,YAAY,EAAE,cAAc,CAAC,YAA6B;QAC1D,WAAW,EAAE,cAAc,CAAC,WAA2B;QACvD,eAAe,EAAE,cAAc,CAAC,eAAmC;QACnE,MAAM,EAAE,qBAAqB,CAAC,cAAc,CAAC,MAAM,CAAC;QACpD,UAAU,EAAE,yBAAyB,CAAC,cAAc,CAAC,UAAU,CAAC;QAChE,cAAc,EAAE,cAAc,CAAC,cAAc;QAC7C,YAAY,EAAE,yCAAyC,CAAC,cAAc,CAAC,YAAY,CAAC;KACrF,CAAC;AACJ,CAAC;AAMK,SAAU,iDAAiD,CAC/D,mBAAqD;IAErD,IAAI,CAAC,mBAAmB,EAAE,CAAC;QACzB,OAAO,mBAAmB,CAAC;IAC7B,CAAC;IAED,OAAQ,mBAAmB,CAAC,IAAI,EAAE,CAAC;QACjC,KAAK,aAAa,CAAC;YAAC,CAAC;gBACnB,MAAM,EAAE,UAAU,EAAE,GAAG,mBAAqD,CAAC;gBAC7E,MAAM,YAAY,GAAG,wCAAwC,CAAC,UAAU,KAAA,QAAV,UAAU,KAAA,KAAA,IAAA,KAAA,IAAV,UAAU,CAAE,YAAY,CAAC,CAAC;gBACxF,MAAM,UAAU,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACV,mBAAsD,GAAA;oBAC1D,UAAU,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,UAAU,GAAA;wBAAE,YAAY;oBAAA;gBAAA,EAC1C,CAAC;gBACF,OAAO,UAAU,CAAC;YACpB,CAAC;QACD,KAAK,cAAc,CAAC;YAAC,CAAC;gBACpB,MAAM,EAAE,UAAU,EAAE,GAAG,mBAAgD,CAAC;gBACxE,MAAM,YAAY,GAAG,wCAAwC,CAAC,UAAU,KAAA,QAAV,UAAU,KAAA,KAAA,IAAA,KAAA,IAAV,UAAU,CAAE,YAAY,CAAC,CAAC;gBACxF,MAAM,UAAU,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACV,mBAAiD,GAAA;oBACrD,UAAU,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,UAAU,GAAA;wBAAE,YAAY;oBAAA;gBAAA,EAC1C,CAAC;gBACF,OAAO,UAAU,CAAC;YACpB,CAAC;IACH,CAAC;qLACD,SAAM,CAAC,OAAO,CAAC,CAAA,6BAAA,EAAiC,mBAA2B,CAAC,IAAI,EAAE,CAAC,CAAC;IACpF,OAAO,mBAA0B,CAAC;AACpC,CAAC;AAMK,SAAU,qFAAqF,CACnG,+BAA6E;;IAE7E,IAAI,CAAC,+BAA+B,EAAE,CAAC;QACrC,OAAO,+BAA+B,CAAC;IACzC,CAAC;IAED,IAAI;QAAC,MAAM;QAAE,eAAe;KAAC,CAAC,QAAQ,CAAC,+BAA+B,CAAC,IAAI,CAAC,EAAE,CAAC;QAC7E,MAAM,sBAAsB,GAAG,+BAEiB,CAAC;QACjD,MAAM,MAAM,GAAG,CAAA,KAAA,sBAAsB,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,MAAqC,CAAC;QACxF,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,sBAAsB,GAAA;YACzB,UAAU,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,sBAAsB,CAAC,UAAU,GAAA;gBAAE,MAAM;YAAA;QAAA,GAC1D;IACJ,CAAC;IAED,MAAM,KAAK,CAAC,qCAAqC,CAAC,CAAC;AACrD,CAAC;AAEK,SAAU,yCAAyC,CACvD,YAAoC;;IAEpC,IAAI,CAAC,YAAY,EAAE,CAAC;QAClB,OAAO,YAAY,CAAC;IACtB,CAAC;IAED,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,YAAY,GAAA;QACf,UAAU,EAAE,CAAA,KAAA,YAAY,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,GAAG,CACtC,qFAAqF,CACtF;QACD,WAAW,EAAE,CAAA,KAAA,YAAY,CAAC,WAAW,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,GAAG,CAAC,iDAAiD,CAAC;IAAA,GAC7F;AACJ,CAAC;AAEK,SAAU,yCAAyC,CAGvD,OAAgC;IAChC,MAAM,YAAY,GAAoC,OAAO,CAAC,GAAG,CAC/D,CAAC,MAAM,EAAE,EAAE;QACT,MAAM,EACJ,MAAM,EAAE,KAAK,EACb,WAAW,EAAE,UAAU,EACvB,cAAc,EAAE,aAAa,EAC7B,SAAS,EAAE,QAAQ,EAAA,GAEjB,MAAM,EADL,SAAS,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EACV,MAAM,EANJ;YAAA;YAAA;YAAA;YAAA;SAML,CAAS,CAAC;QACX,MAAM,GAAG,GAAG;YACV,KAAK;YACL,UAAU;YACV,aAAa;YACb,QAAQ;YACR,QAAQ,EAAE,SAAS;SACpB,CAAC;QACF,OAAO,GAAoC,CAAC;IAC9C,CAAC,CACF,CAAC;IACF,OAAO,YAAY,CAAC;AACtB,CAAC;AAEK,SAAU,6DAA6D,CAG3E,qBAAsD;IACtD,MAAM,OAAO,GAAG,qBAAqB,CAAC,OAAO,CAAC,GAAG,CAAiC,CAAC,OAAO,EAAE,EAAE;QAC5F,MAAM,EAAE,KAAK,EAAA,GAAmB,OAAO,EAArB,SAAS,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAAK,OAAO,EAAjC;YAAA;SAAuB,CAAU,CAAC;QAExC,MAAM,GAAG,GAAG;YACV,IAAI,EAAE,KAAK;YACX,QAAQ,EAAE,SAAS;SACpB,CAAC;QAEF,OAAO,GAAqC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,MAAM,MAAM,GAA4C;QACtD,OAAO,EAAE,OAAO;QAChB,QAAQ,EAAE,qBAAqB,CAAC,QAAQ;KACzC,CAAC;IAEF,OAAO,MAAM,CAAC;AAChB,CAAC;AAEK,SAAU,2BAA2B,CAAC,KAAkB;IAC5D,MAAM,EAAE,aAAa,EAAE,YAAY,EAAE,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,UAAU,EAAE,GAAG,KAAK,CAAC;IAEzF,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,KAAK,GAAA;QACR,aAAa,EAAE,+BAA+B,CAAC,aAAa,CAAC;QAC7D,YAAY,EAAE,8BAA8B,CAAC,YAAY,CAAC;QAC1D,SAAS,EAAE,2BAA2B,CAAC,SAAS,CAAC;QACjD,UAAU,EAAE,4BAA4B,CAAC,UAAU,CAAC;QACpD,MAAM,EAAE,wBAAwB,CAAC,MAAM,CAAC;QACxC,UAAU,EAAE,4BAA4B,CAAC,UAAU,CAAC;IAAA,GACpD;AACJ,CAAC;AAEK,SAAU,iCAAiC,CAC/C,iBAAiD;IAEjD,MAAM,EAAE,MAAM,EAAE,wBAAwB,EAAE,aAAa,EAAE,eAAe,EAAA,GACtE,iBAAiB,EAD0D,KAAK,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAChF,iBAAiB,EADb;QAAA;QAAA;QAAA;QAAA;KAA8E,CACjE,CAAC;IACpB,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,KAAK,GAAA;QACR,MAAM,EAAE,qBAAqB,CAAC,MAAM,CAAC;QACrC,wBAAwB,EAAE,uCAAuC,CAAC,wBAAwB,CAAC;QAC3F,aAAa,EAAE,4BAA4B,CAAC,aAAa,CAAC;QAC1D,eAAe,EAAE,eAA+C;IAAA,GAChE;AACJ,CAAC;AAEK,SAAU,iCAAiC,CAC/C,QAA+B;IAE/B,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,QAAQ,GAAA;QACX,IAAI,EAAE,QAAQ,CAAC,IAAI;QACnB,WAAW,EAAE,QAAQ,CAAC,WAAW;QACjC,IAAI,EAAE,QAAQ,CAAC,IAAI;QACnB,MAAM,EAAE,QAAQ,CAAC,MAAM;QACvB,wBAAwB,EAAE,0CAA0C,CAClE,QAAQ,CAAC,wBAAwB,CAClC;QACD,cAAc,EAAE,QAAQ,CAAC,cAAc;QACvC,aAAa,EAAE,+BAA+B,CAAC,QAAQ,CAAC,aAAa,CAAC;IAAA,GACtE;AACJ,CAAC;AAEK,SAAU,qCAAqC,CAAC,UAA+B;IACnF,MAAM,MAAM,GAAe;QACzB,IAAI,EAAE,UAAU,CAAC,IAAI;QACrB,aAAa,EAAE,4BAA4B,CAAC,UAAU,CAAC,aAAa,CAAC;QACrE,IAAI,EAAE,UAAU,CAAC,IAAI;QACrB,QAAQ,EAAE,EAAE;KACb,CAAC;IAEF,IAAI,UAAU,CAAC,QAAQ,EAAE,CAAC;QACxB,MAAM,CAAC,QAAQ,GAAG,UAAU,CAAC,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACpD,CAAC;IAED,OAAO,MAAM,CAAC;AAChB,CAAC;AAEK,SAAU,qCAAqC,CAAC,UAAsB;IAC1E,MAAM,MAAM,GAAwB;QAClC,IAAI,EAAE,UAAU,CAAC,IAAI;QACrB,MAAM,EAAE,MAAM;QACd,aAAa,EAAE,+BAA+B,CAAC,UAAU,CAAC,aAAa,CAAC;QACxE,IAAI,EAAE,UAAU,CAAC,IAAI;QACrB,QAAQ,EAAE,UAAU,CAAC,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC;KACzC,CAAC;IAEF,MAAM,CAAC,aAAa,GAAG,+BAA+B,CAAC,UAAU,CAAC,aAAa,CAAC,CAAC;IAEjF,OAAO,MAAM,CAAC;AAChB,CAAC;AAEK,SAAU,2CAA2C,CACzD,OAAsB;IAEtB,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,OAAO,GAAA;QACV,aAAa,EAAE,+BAA+B,CAAC,OAAO,CAAC,aAAa,CAAC;IAAA,GACrE;AACJ,CAAC;AAEK,SAAU,2CAA2C,CACzD,OAA+B;;IAE/B,MAAM,EACJ,WAAW,EACX,aAAa,EACb,WAAW,EACX,wBAAwB,EACxB,oBAAoB,EACrB,GAAG,CAAA,KAAA,CAAA,KAAA,OAAO,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,aAAa,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,CAAA,CAAE,CAAC;IAE5C,MAAM,aAAa,GAAgD,CAAA,CAAA,KAAA,OAAO,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GACjF,aAAa,KAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACZ,CAAA,KAAA,OAAO,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,aAAa,GAAA;QACpC,WAAW,EAAE,WAAiD;QAC9D,aAAa,EAAE,aAAqD;QACpE,WAAW,EAAE,WAAiD;QAC9D,wBAAwB,EAAE,wBAEb;QACb,oBAAoB,EAAE,oBAA+D;IAAA,EACtF,CAAC;IACF,MAAM,UAAU,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACX,OAAO,CAAC,UAAU,GAAA;QACrB,aAAa;IAAA,EACd,CAAC;IAEF,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,OAAO,GAAA;QACV,UAAU;QACV,aAAa,EAAE,4BAA4B,CAAC,OAAO,CAAC,aAAa,CAAC;IAAA,GAClE;AACJ,CAAC;AAEK,SAAU,qCAAqC,CACnD,UAA6C;IAE7C,OAAO;QACL,IAAI,EAAE,UAAU,CAAC,IAAI;QACrB,WAAW,EAAE,UAAU,CAAC,WAAW;QACnC,IAAI,EAAE,UAAU,CAAC,IAAI;QACrB,WAAW,EAAE;YACX,gBAAgB,EAAE,UAAU,CAAC,gBAAgB;SAC9C;QACD,SAAS,EAAE,UAAU,CAAC,SAAS;QAC/B,IAAI,EAAE,UAAU,CAAC,IAAI;QACrB,yBAAyB,EAAE,UAAU,CAAC,yBAAyB;QAC/D,2BAA2B,EAAE,UAAU,CAAC,2BAA2B;QACnE,aAAa,EAAE,+BAA+B,CAAC,UAAU,CAAC,aAAa,CAAC;KACzE,CAAC;AACJ,CAAC;AAEK,SAAU,qCAAqC,CACnD,UAAsD;IAEtD,OAAO;QACL,IAAI,EAAE,UAAU,CAAC,IAAI;QACrB,WAAW,EAAE,UAAU,CAAC,IAAI;QAC5B,IAAI,EAAE,UAAU,CAAC,IAAmC;QACpD,gBAAgB,EAAE,UAAU,CAAC,WAAW,CAAC,gBAAgB;QACzD,SAAS,EAAE,UAAU,CAAC,SAAS;QAC/B,IAAI,EAAE,UAAU,CAAC,IAAI;QACrB,yBAAyB,EAAE,wCAAwC,CACjE,UAAU,CAAC,yBAAyB,CACrC;QACD,2BAA2B,EAAE,0CAA0C,CACrE,UAAU,CAAC,2BAA2B,CACvC;QACD,aAAa,EAAE,4BAA4B,CAAC,UAAU,CAAC,aAAa,CAAC;KACtE,CAAC;AACJ,CAAC;AAEK,SAAU,wCAAwC,CACtD,yBAA0D;IAE1D,IAAI,CAAC,yBAAyB,EAAE,CAAC;QAC/B,OAAO,yBAAyB,CAAC;IACnC,CAAC;IAED,IAAI,yBAAyB,CAAC,SAAS,KAAK,0CAA0C,EAAE,CAAC;QACvF,OAAO,yBAA0D,CAAC;IACpE,CAAC,MAAM,CAAC;QACN,OAAO,yBAAkE,CAAC;IAC5E,CAAC;AACH,CAAC;AAEK,SAAU,wCAAwC,CACtD,yBAA0D;IAE1D,IAAI,CAAC,yBAAyB,EAAE,CAAC;QAC/B,OAAO,yBAAyB,CAAC;IACnC,CAAC;IAED,IACE,yBAAyB,CAAC,SAAS,KACnC,4DAA4D,EAC5D,CAAC;QACD,OAAO,yBAA+D,CAAC;IACzE,CAAC,MAAM,CAAC;QACN,OAAO,yBAA8D,CAAC;IACxE,CAAC;AACH,CAAC;AAEK,SAAU,0CAA0C,CACxD,2BAA8D;IAE9D,IAAI,CAAC,2BAA2B,EAAE,CAAC;QACjC,OAAO,2BAA2B,CAAC;IACrC,CAAC;IAED,OAAO,2BAAsE,CAAC;AAChF,CAAC;AAEK,SAAU,yBAAyB,CAAC,GAAW,EAAE,GAAW;IAChE,iCAAiC;IACjC,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;IACrB,GAAG,GAAG,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;IACtB,2DAA2D;IAC3D,+EAA+E;IAC/E,yEAAyE;IACzE,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC;IAC3D,OAAO,MAAM,GAAG,GAAG,CAAC;AACtB,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3939, "column": 0}, "map": {"version":3,"file":"tracing.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/tracing.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport { createTracingClient } from \"@azure/core-tracing\";\n\n/**\n * Creates a tracing client using the global tracer.\n * @internal\n */\nconst tracingClient = createTracingClient({\n  namespace: \"Microsoft.Search\",\n  packageName: \"Azure.Search\",\n});\n\nexport const createSpan = tracingClient.startSpan;\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;;AAElC,OAAO,EAAE,mBAAmB,EAAE,MAAM,qBAAqB,CAAC;;AAE1D;;;GAGG,CACH,MAAM,aAAa,oLAAG,sBAAA,AAAmB,EAAC;IACxC,SAAS,EAAE,kBAAkB;IAC7B,WAAW,EAAE,cAAc;CAC5B,CAAC,CAAC;AAEI,MAAM,UAAU,GAAG,aAAa,CAAC,SAAS,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3961, "column": 0}, "map": {"version":3,"file":"searchClient.js","sourceRoot":"","sources":["file:///C:/app/agentset/node_modules/%40azure/search-documents/src/searchClient.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/// <reference lib=\"esnext.asynciterable\" />\n\nimport { isTokenCredential, KeyCredential, TokenCredential } from \"@azure/core-auth\";\nimport { InternalClientPipelineOptions } from \"@azure/core-client\";\nimport { ExtendedCommonClientOptions } from \"@azure/core-http-compat\";\nimport { bearerTokenAuthenticationPolicy } from \"@azure/core-rest-pipeline\";\nimport { decode, encode } from \"./base64\";\nimport {\n  AutocompleteRequest,\n  AutocompleteResult,\n  IndexDocumentsResult,\n  QueryAnswerType as BaseAnswers,\n  QueryCaptionType as BaseCaptions,\n  SearchRequest as GeneratedSearchRequest,\n  SuggestRequest,\n  VectorQueryUnion as GeneratedVectorQuery,\n} from \"./generated/data/models\";\nimport { SearchClient as GeneratedClient } from \"./generated/data/searchClient\";\nimport { IndexDocumentsBatch } from \"./indexDocumentsBatch\";\nimport {\n  AutocompleteOptions,\n  CountDocumentsOptions,\n  DeleteDocumentsOptions,\n  GetDocumentOptions,\n  IndexDocumentsOptions,\n  ListSearchResultsPageSettings,\n  MergeDocumentsOptions,\n  MergeOrUploadDocumentsOptions,\n  NarrowedModel,\n  QueryAnswer,\n  QueryCaption,\n  SearchDocumentsPageResult,\n  SearchDocumentsResult,\n  SearchFieldArray,\n  SearchIterator,\n  SearchOptions,\n  SearchResult,\n  SelectArray,\n  SelectFields,\n  SemanticErrorReason,\n  SemanticSearchResultsType,\n  SuggestDocumentsResult,\n  SuggestOptions,\n  UploadDocumentsOptions,\n  VectorQuery,\n} from \"./indexModels\";\nimport { logger } from \"./logger\";\nimport { createOdataMetadataPolicy } from \"./odataMetadataPolicy\";\nimport { createSearchApiKeyCredentialPolicy } from \"./searchApiKeyCredentialPolicy\";\nimport { KnownSearchAudience } from \"./searchAudience\";\nimport { IndexDocumentsClient } from \"./searchIndexingBufferedSender\";\nimport { deserialize, serialize } from \"./serialization\";\nimport * as utils from \"./serviceUtils\";\nimport { createSpan } from \"./tracing\";\n\n/**\n * Client options used to configure Cognitive Search API requests.\n */\nexport interface SearchClientOptions extends ExtendedCommonClientOptions {\n  /**\n   * The API version to use when communicating with the service.\n   * @deprecated use {@link serviceVersion} instead\n   */\n  apiVersion?: string;\n\n  /**\n   * The service version to use when communicating with the service.\n   */\n  serviceVersion?: string;\n\n  /**\n   * The Audience to use for authentication with Azure Active Directory (AAD). The\n   * audience is not considered when using a shared key.\n   * {@link KnownSearchAudience} can be used interchangeably with audience\n   */\n  audience?: string;\n}\n\n/**\n * Class used to perform operations against a search index,\n * including querying documents in the index as well as\n * adding, updating, and removing them.\n */\nexport class SearchClient<TModel extends object> implements IndexDocumentsClient<TModel> {\n  /// Maintenance note: when updating supported API versions,\n  /// the ContinuationToken logic will need to be updated below.\n\n  /**\n   *  The service version to use when communicating with the service.\n   */\n  public readonly serviceVersion: string = utils.defaultServiceVersion;\n\n  /**\n   * The API version to use when communicating with the service.\n   * @deprecated use {@Link serviceVersion} instead\n   */\n  public readonly apiVersion: string = utils.defaultServiceVersion;\n\n  /**\n   * The endpoint of the search service\n   */\n  public readonly endpoint: string;\n\n  /**\n   * The name of the index\n   */\n  public readonly indexName: string;\n\n  /**\n   * @hidden\n   * A reference to the auto-generated SearchClient\n   */\n  private readonly client: GeneratedClient;\n\n  /**\n   * Creates an instance of SearchClient.\n   *\n   * Example usage:\n   * ```ts\n   * const { SearchClient, AzureKeyCredential } = require(\"@azure/search-documents\");\n   *\n   * const client = new SearchClient(\n   *   \"<endpoint>\",\n   *   \"<indexName>\",\n   *   new AzureKeyCredential(\"<Admin Key>\")\n   * );\n   * ```\n   *\n   * Optionally, the type of the model can be used to enable strong typing and type hints:\n   * ```ts\n   * type TModel = {\n   *   keyName: string;\n   *   field1?: string | null;\n   *   field2?: { anotherField?: string | null } | null;\n   * };\n   *\n   * const client = new SearchClient<TModel>(\n   *   ...\n   * );\n   * ```\n   *\n   * @param endpoint - The endpoint of the search service\n   * @param indexName - The name of the index\n   * @param credential - Used to authenticate requests to the service.\n   * @param options - Used to configure the Search client.\n   *\n   * @typeParam TModel - An optional type that represents the documents stored in\n   * the search index. For the best typing experience, all non-key fields should\n   * be marked optional and nullable, and the key property should have the\n   * non-nullable type `string`.\n   */\n  constructor(\n    endpoint: string,\n    indexName: string,\n    credential: KeyCredential | TokenCredential,\n    options: SearchClientOptions = {},\n  ) {\n    this.endpoint = endpoint;\n    this.indexName = indexName;\n\n    const internalClientPipelineOptions: InternalClientPipelineOptions = {\n      ...options,\n      ...{\n        loggingOptions: {\n          logger: logger.info,\n          additionalAllowedHeaderNames: [\n            \"elapsed-time\",\n            \"Location\",\n            \"OData-MaxVersion\",\n            \"OData-Version\",\n            \"Prefer\",\n            \"throttle-reason\",\n          ],\n        },\n      },\n    };\n\n    this.serviceVersion =\n      options.serviceVersion ?? options.apiVersion ?? utils.defaultServiceVersion;\n    this.apiVersion = this.serviceVersion;\n\n    this.client = new GeneratedClient(\n      this.endpoint,\n      this.indexName,\n      this.serviceVersion,\n      internalClientPipelineOptions,\n    );\n\n    if (isTokenCredential(credential)) {\n      const scope: string = options.audience\n        ? `${options.audience}/.default`\n        : `${KnownSearchAudience.AzurePublicCloud}/.default`;\n\n      this.client.pipeline.addPolicy(\n        bearerTokenAuthenticationPolicy({ credential, scopes: scope }),\n      );\n    } else {\n      this.client.pipeline.addPolicy(createSearchApiKeyCredentialPolicy(credential));\n    }\n\n    this.client.pipeline.addPolicy(createOdataMetadataPolicy(\"none\"));\n  }\n\n  /**\n   * Retrieves the number of documents in the index.\n   * @param options - Options to the count operation.\n   */\n  public async getDocumentsCount(options: CountDocumentsOptions = {}): Promise<number> {\n    const { span, updatedOptions } = createSpan(\"SearchClient-getDocumentsCount\", options);\n    try {\n      let documentsCount: number = 0;\n      await this.client.documents.count({\n        ...updatedOptions,\n        onResponse: (rawResponse, flatResponse) => {\n          documentsCount = Number(rawResponse.bodyAsText);\n          if (updatedOptions.onResponse) {\n            updatedOptions.onResponse(rawResponse, flatResponse);\n          }\n        },\n      });\n\n      return documentsCount;\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  /**\n   * Based on a partial searchText from the user, return a list\n   * of potential completion strings based on a specified suggester.\n   * @param searchText - The search text on which to base autocomplete results.\n   * @param suggesterName - The name of the suggester as specified in the suggesters collection that's part of the index definition.\n   * @param options - Options to the autocomplete operation.\n   * @example\n   * ```ts\n   * import {\n   *   AzureKeyCredential,\n   *   SearchClient,\n   *   SearchFieldArray,\n   * } from \"@azure/search-documents\";\n   *\n   * type TModel = {\n   *   key: string;\n   *   azure?: { sdk: string | null } | null;\n   * };\n   *\n   * const client = new SearchClient<TModel>(\n   *   \"endpoint.azure\",\n   *   \"indexName\",\n   *   new AzureKeyCredential(\"key\")\n   * );\n   *\n   * const searchFields: SearchFieldArray<TModel> = [\"azure/sdk\"];\n   *\n   * const autocompleteResult = await client.autocomplete(\n   *   \"searchText\",\n   *   \"suggesterName\",\n   *   { searchFields }\n   * );\n   * ```\n   */\n  public async autocomplete(\n    searchText: string,\n    suggesterName: string,\n    options: AutocompleteOptions<TModel> = {},\n  ): Promise<AutocompleteResult> {\n    const { searchFields, ...nonFieldOptions } = options;\n    const fullOptions: AutocompleteRequest = {\n      searchText: searchText,\n      suggesterName: suggesterName,\n      searchFields: this.convertSearchFields(searchFields),\n      ...nonFieldOptions,\n    };\n\n    if (!fullOptions.searchText) {\n      throw new RangeError(\"searchText must be provided.\");\n    }\n\n    if (!fullOptions.suggesterName) {\n      throw new RangeError(\"suggesterName must be provided.\");\n    }\n\n    const { span, updatedOptions } = createSpan(\"SearchClient-autocomplete\", options);\n\n    try {\n      const result = await this.client.documents.autocompletePost(fullOptions, updatedOptions);\n      return result;\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  private async searchDocuments<TFields extends SelectFields<TModel>>(\n    searchText?: string,\n    options: SearchOptions<TModel, TFields> = {},\n    nextPageParameters: GeneratedSearchRequest = {},\n  ): Promise<SearchDocumentsPageResult<TModel, TFields>> {\n    const {\n      includeTotalCount,\n      orderBy,\n      searchFields,\n      select,\n      vectorSearchOptions,\n      semanticSearchOptions,\n      ...restOptions\n    } = options as typeof options & { queryType: \"semantic\" };\n\n    const { configurationName, errorMode, answers, captions, ...restSemanticOptions } =\n      semanticSearchOptions ?? {};\n    const { queries, filterMode, ...restVectorOptions } = vectorSearchOptions ?? {};\n\n    const fullOptions: GeneratedSearchRequest = {\n      ...restSemanticOptions,\n      ...restVectorOptions,\n      ...restOptions,\n      ...nextPageParameters,\n      searchFields: this.convertSearchFields(searchFields),\n      select: this.convertSelect<TFields>(select) || \"*\",\n      orderBy: this.convertOrderBy(orderBy),\n      includeTotalResultCount: includeTotalCount,\n      vectorQueries: queries?.map(this.convertVectorQuery.bind(this)),\n      answers: this.convertQueryAnswers(answers),\n      captions: this.convertQueryCaptions(captions),\n      semanticErrorHandling: errorMode,\n      semanticConfigurationName: configurationName,\n      vectorFilterMode: filterMode,\n    };\n\n    const { span, updatedOptions } = createSpan(\"SearchClient-searchDocuments\", options);\n\n    try {\n      const result = await this.client.documents.searchPost(\n        {\n          ...fullOptions,\n          searchText: searchText,\n        },\n        updatedOptions,\n      );\n\n      const {\n        results,\n        nextLink,\n        nextPageParameters: resultNextPageParameters,\n        semanticPartialResponseReason: semanticErrorReason,\n        semanticPartialResponseType: semanticSearchResultsType,\n        ...restResult\n      } = result as typeof result & {\n        semanticPartialResponseReason: SemanticErrorReason | undefined;\n        semanticPartialResponseType: SemanticSearchResultsType | undefined;\n      };\n\n      const modifiedResults = utils.generatedSearchResultToPublicSearchResult<TModel, TFields>(\n        results,\n      );\n\n      const converted: SearchDocumentsPageResult<TModel, TFields> = {\n        ...restResult,\n        results: modifiedResults,\n        semanticErrorReason,\n        semanticSearchResultsType,\n        continuationToken: this.encodeContinuationToken(nextLink, resultNextPageParameters),\n      };\n\n      return deserialize<SearchDocumentsPageResult<TModel, TFields>>(converted);\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  private async *listSearchResultsPage<TFields extends SelectFields<TModel>>(\n    searchText?: string,\n    options: SearchOptions<TModel, TFields> = {},\n    settings: ListSearchResultsPageSettings = {},\n  ): AsyncIterableIterator<SearchDocumentsPageResult<TModel, TFields>> {\n    let decodedContinuation = this.decodeContinuationToken(settings.continuationToken);\n    let result = await this.searchDocuments(\n      searchText,\n      options,\n      decodedContinuation?.nextPageParameters,\n    );\n\n    yield result;\n\n    // Technically, we should also leverage nextLink, but the generated code\n    // doesn't support this yet.\n    while (result.continuationToken) {\n      decodedContinuation = this.decodeContinuationToken(result.continuationToken);\n      result = await this.searchDocuments(\n        searchText,\n        options,\n        decodedContinuation?.nextPageParameters,\n      );\n      yield result;\n    }\n  }\n\n  private async *listSearchResultsAll<TFields extends SelectFields<TModel>>(\n    firstPage: SearchDocumentsPageResult<TModel, TFields>,\n    searchText?: string,\n    options: SearchOptions<TModel, TFields> = {},\n  ): AsyncIterableIterator<SearchResult<TModel, TFields>> {\n    yield* firstPage.results;\n    if (firstPage.continuationToken) {\n      for await (const page of this.listSearchResultsPage(searchText, options, {\n        continuationToken: firstPage.continuationToken,\n      })) {\n        yield* page.results;\n      }\n    }\n  }\n\n  private listSearchResults<TFields extends SelectFields<TModel>>(\n    firstPage: SearchDocumentsPageResult<TModel, TFields>,\n    searchText?: string,\n    options: SearchOptions<TModel, TFields> = {},\n  ): SearchIterator<TModel, TFields> {\n    const iter = this.listSearchResultsAll(firstPage, searchText, options);\n\n    return {\n      next() {\n        return iter.next();\n      },\n      [Symbol.asyncIterator]() {\n        return this;\n      },\n      byPage: (settings: ListSearchResultsPageSettings = {}) => {\n        return this.listSearchResultsPage(searchText, options, settings);\n      },\n    };\n  }\n\n  /**\n   * Performs a search on the current index given\n   * the specified arguments.\n   * @param searchText - Text to search\n   * @param options - Options for the search operation.\n   * @example\n   * ```ts\n   * import {\n   *   AzureKeyCredential,\n   *   SearchClient,\n   *   SearchFieldArray,\n   * } from \"@azure/search-documents\";\n   *\n   * type TModel = {\n   *   key: string;\n   *   azure?: { sdk: string | null } | null;\n   * };\n   *\n   * const client = new SearchClient<TModel>(\n   *   \"endpoint.azure\",\n   *   \"indexName\",\n   *   new AzureKeyCredential(\"key\")\n   * );\n   *\n   * const select = [\"azure/sdk\"] as const;\n   * const searchFields: SearchFieldArray<TModel> = [\"azure/sdk\"];\n   *\n   * const searchResult = await client.search(\"searchText\", {\n   *   select,\n   *   searchFields,\n   * });\n   * ```\n   */\n  public async search<TFields extends SelectFields<TModel>>(\n    searchText?: string,\n    options?: SearchOptions<TModel, TFields>,\n  ): Promise<SearchDocumentsResult<TModel, TFields>> {\n    const { span, updatedOptions } = createSpan(\"SearchClient-search\", options);\n\n    try {\n      const pageResult = await this.searchDocuments<TFields>(searchText, updatedOptions);\n\n      return {\n        ...pageResult,\n        results: this.listSearchResults(pageResult, searchText, updatedOptions),\n      };\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  /**\n   * Returns a short list of suggestions based on the searchText\n   * and specified suggester.\n   * @param searchText - The search text to use to suggest documents. Must be at least 1 character, and no more than 100 characters.\n   * @param suggesterName - The name of the suggester as specified in the suggesters collection that's part of the index definition.\n   * @param options - Options for the suggest operation\n   * @example\n   * ```ts\n   * import {\n   *   AzureKeyCredential,\n   *   SearchClient,\n   *   SearchFieldArray,\n   * } from \"@azure/search-documents\";\n   *\n   * type TModel = {\n   *   key: string;\n   *   azure?: { sdk: string | null } | null;\n   * };\n   *\n   * const client = new SearchClient<TModel>(\n   *   \"endpoint.azure\",\n   *   \"indexName\",\n   *   new AzureKeyCredential(\"key\")\n   * );\n   *\n   * const select = [\"azure/sdk\"] as const;\n   * const searchFields: SearchFieldArray<TModel> = [\"azure/sdk\"];\n   *\n   * const suggestResult = await client.suggest(\"searchText\", \"suggesterName\", {\n   *   select,\n   *   searchFields,\n   * });\n   * ```\n   */\n  public async suggest<TFields extends SelectFields<TModel> = never>(\n    searchText: string,\n    suggesterName: string,\n    options: SuggestOptions<TModel, TFields> = {},\n  ): Promise<SuggestDocumentsResult<TModel, TFields>> {\n    const { select, searchFields, orderBy, ...nonFieldOptions } = options;\n    const fullOptions: SuggestRequest = {\n      searchText: searchText,\n      suggesterName: suggesterName,\n      searchFields: this.convertSearchFields(searchFields),\n      select: this.convertSelect<TFields>(select),\n      orderBy: this.convertOrderBy(orderBy),\n      ...nonFieldOptions,\n    };\n\n    if (!fullOptions.searchText) {\n      throw new RangeError(\"searchText must be provided.\");\n    }\n\n    if (!fullOptions.suggesterName) {\n      throw new RangeError(\"suggesterName must be provided.\");\n    }\n\n    const { span, updatedOptions } = createSpan(\"SearchClient-suggest\", options);\n\n    try {\n      const result = await this.client.documents.suggestPost(fullOptions, updatedOptions);\n\n      const modifiedResult = utils.generatedSuggestDocumentsResultToPublicSuggestDocumentsResult<\n        TModel,\n        TFields\n      >(result);\n\n      return deserialize<SuggestDocumentsResult<TModel, TFields>>(modifiedResult);\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  /**\n   * Retrieve a particular document from the index by key.\n   * @param key - The primary key value of the document\n   * @param options - Additional options\n   */\n  public async getDocument<TFields extends SelectFields<TModel>>(\n    key: string,\n    options: GetDocumentOptions<TModel, TFields> = {},\n  ): Promise<NarrowedModel<TModel, TFields>> {\n    const { span, updatedOptions } = createSpan(\"SearchClient-getDocument\", options);\n    try {\n      const result = await this.client.documents.get(key, {\n        ...updatedOptions,\n        selectedFields: updatedOptions.selectedFields as string[] | undefined,\n      });\n      return deserialize<NarrowedModel<TModel, TFields>>(result);\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  /**\n   * Perform a set of index modifications (upload, merge, mergeOrUpload, delete)\n   * for the given set of documents.\n   * This operation may partially succeed and not all document operations will\n   * be reflected in the index. If you would like to treat this as an exception,\n   * set the `throwOnAnyFailure` option to true.\n   * For more details about how merging works, see: https://docs.microsoft.com/en-us/rest/api/searchservice/AddUpdate-or-Delete-Documents\n   * @param batch - An array of actions to perform on the index.\n   * @param options - Additional options.\n   */\n  public async indexDocuments(\n    // eslint-disable-next-line @azure/azure-sdk/ts-use-interface-parameters\n    batch: IndexDocumentsBatch<TModel>,\n    options: IndexDocumentsOptions = {},\n  ): Promise<IndexDocumentsResult> {\n    const { span, updatedOptions } = createSpan(\"SearchClient-indexDocuments\", options);\n    try {\n      let status: number = 0;\n      const result = await this.client.documents.index(\n        { actions: serialize(batch.actions) },\n        {\n          ...updatedOptions,\n          onResponse: (rawResponse, flatResponse) => {\n            status = rawResponse.status;\n            if (updatedOptions.onResponse) {\n              updatedOptions.onResponse(rawResponse, flatResponse);\n            }\n          },\n        },\n      );\n      if (options.throwOnAnyFailure && status === 207) {\n        throw result;\n      }\n      return result;\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  /**\n   * Upload an array of documents to the index.\n   * @param documents - The documents to upload.\n   * @param options - Additional options.\n   */\n  public async uploadDocuments(\n    documents: TModel[],\n    options: UploadDocumentsOptions = {},\n  ): Promise<IndexDocumentsResult> {\n    const { span, updatedOptions } = createSpan(\"SearchClient-uploadDocuments\", options);\n\n    const batch = new IndexDocumentsBatch<TModel>();\n    batch.upload(documents);\n\n    try {\n      return await this.indexDocuments(batch, updatedOptions);\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  /**\n   * Update a set of documents in the index.\n   * For more details about how merging works, see https://docs.microsoft.com/en-us/rest/api/searchservice/AddUpdate-or-Delete-Documents\n   * @param documents - The updated documents.\n   * @param options - Additional options.\n   */\n  public async mergeDocuments(\n    documents: TModel[],\n    options: MergeDocumentsOptions = {},\n  ): Promise<IndexDocumentsResult> {\n    const { span, updatedOptions } = createSpan(\"SearchClient-mergeDocuments\", options);\n\n    const batch = new IndexDocumentsBatch<TModel>();\n    batch.merge(documents);\n\n    try {\n      return await this.indexDocuments(batch, updatedOptions);\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  /**\n   * Update a set of documents in the index or upload them if they don't exist.\n   * For more details about how merging works, see https://docs.microsoft.com/en-us/rest/api/searchservice/AddUpdate-or-Delete-Documents\n   * @param documents - The updated documents.\n   * @param options - Additional options.\n   */\n  public async mergeOrUploadDocuments(\n    documents: TModel[],\n    options: MergeOrUploadDocumentsOptions = {},\n  ): Promise<IndexDocumentsResult> {\n    const { span, updatedOptions } = createSpan(\"SearchClient-mergeDocuments\", options);\n\n    const batch = new IndexDocumentsBatch<TModel>();\n    batch.mergeOrUpload(documents);\n\n    try {\n      return await this.indexDocuments(batch, updatedOptions);\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  /**\n   * Delete a set of documents.\n   * @param documents - Documents to be deleted.\n   * @param options - Additional options.\n   */\n  public async deleteDocuments(\n    documents: TModel[],\n    options?: DeleteDocumentsOptions,\n  ): Promise<IndexDocumentsResult>;\n\n  /**\n   * Delete a set of documents.\n   * @param keyName - The name of their primary key in the index.\n   * @param keyValues - The primary key values of documents to delete.\n   * @param options - Additional options.\n   */\n  public async deleteDocuments(\n    keyName: keyof TModel,\n    keyValues: string[],\n    options?: DeleteDocumentsOptions,\n  ): Promise<IndexDocumentsResult>;\n\n  public async deleteDocuments(\n    keyNameOrDocuments: keyof TModel | TModel[],\n    keyValuesOrOptions?: string[] | DeleteDocumentsOptions,\n    options: DeleteDocumentsOptions = {},\n  ): Promise<IndexDocumentsResult> {\n    const { span, updatedOptions } = createSpan(\"SearchClient-deleteDocuments\", options);\n\n    const batch = new IndexDocumentsBatch<TModel>();\n    if (typeof keyNameOrDocuments === \"string\") {\n      batch.delete(keyNameOrDocuments, keyValuesOrOptions as string[]);\n    } else {\n      batch.delete(keyNameOrDocuments as TModel[]);\n    }\n\n    try {\n      return await this.indexDocuments(batch, updatedOptions);\n    } catch (e: any) {\n      span.setStatus({\n        status: \"error\",\n        error: e.message,\n      });\n      throw e;\n    } finally {\n      span.end();\n    }\n  }\n\n  private encodeContinuationToken(\n    nextLink: string | undefined,\n    nextPageParameters: GeneratedSearchRequest | undefined,\n  ): string | undefined {\n    if (!nextLink || !nextPageParameters) {\n      return undefined;\n    }\n    const payload = JSON.stringify({\n      apiVersion: this.apiVersion,\n      nextLink,\n      nextPageParameters,\n    });\n    return encode(payload);\n  }\n\n  private decodeContinuationToken(\n    token?: string,\n  ): { nextPageParameters: GeneratedSearchRequest; nextLink: string } | undefined {\n    if (!token) {\n      return undefined;\n    }\n\n    const decodedToken = decode(token);\n\n    try {\n      const result: {\n        apiVersion: string;\n        nextLink: string;\n        nextPageParameters: GeneratedSearchRequest;\n      } = JSON.parse(decodedToken);\n\n      if (result.apiVersion !== this.apiVersion) {\n        throw new RangeError(`Continuation token uses unsupported apiVersion \"${this.apiVersion}\"`);\n      }\n\n      return {\n        nextLink: result.nextLink,\n        nextPageParameters: result.nextPageParameters,\n      };\n    } catch (e: any) {\n      throw new Error(`Corrupted or invalid continuation token: ${decodedToken}`);\n    }\n  }\n\n  private convertSelect<TFields extends SelectFields<TModel>>(\n    select?: SelectArray<TFields>,\n  ): string | undefined {\n    if (select) {\n      return select.join(\",\");\n    }\n    return select;\n  }\n\n  private convertVectorQueryFields(fields?: SearchFieldArray<TModel>): string | undefined {\n    if (fields) {\n      return fields.join(\",\");\n    }\n    return fields;\n  }\n\n  private convertSearchFields(searchFields?: SearchFieldArray<TModel>): string | undefined {\n    if (searchFields) {\n      return searchFields.join(\",\");\n    }\n    return searchFields;\n  }\n\n  private convertOrderBy(orderBy?: string[]): string | undefined {\n    if (orderBy) {\n      return orderBy.join(\",\");\n    }\n    return orderBy;\n  }\n\n  private convertQueryAnswers(answers?: QueryAnswer): BaseAnswers | undefined {\n    if (!answers) {\n      return answers;\n    }\n\n    const config = [];\n    const { answerType: output, count, threshold } = answers;\n\n    if (count) {\n      config.push(`count-${count}`);\n    }\n\n    if (threshold) {\n      config.push(`threshold-${threshold}`);\n    }\n\n    if (config.length) {\n      return output + `|${config.join(\",\")}`;\n    }\n\n    return output;\n  }\n\n  private convertQueryCaptions(captions?: QueryCaption): BaseCaptions | undefined {\n    if (!captions) {\n      return captions;\n    }\n\n    const config = [];\n    const { captionType: output, highlight } = captions;\n\n    if (highlight !== undefined) {\n      config.push(`highlight-${highlight}`);\n    }\n\n    if (config.length) {\n      return output + `|${config.join(\",\")}`;\n    }\n\n    return output;\n  }\n\n  private convertVectorQuery<T extends VectorQuery<TModel>>(vectorQuery: T): GeneratedVectorQuery {\n    return { ...vectorQuery, fields: this.convertVectorQueryFields(vectorQuery?.fields) };\n  }\n}\n"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;;;;AAElC,4CAA4C;AAE5C,OAAO,EAAE,iBAAiB,EAAkC,MAAM,kBAAkB,CAAC;;;AAGrF,OAAO,EAAE,+BAA+B,EAAE,MAAM,2BAA2B,CAAC;AAC5E,OAAO,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,UAAU,CAAC;AAW1C,OAAO,EAAE,YAAY,IAAI,eAAe,EAAE,MAAM,+BAA+B,CAAC;AAChF,OAAO,EAAE,mBAAmB,EAAE,MAAM,uBAAuB,CAAC;AA4B5D,OAAO,EAAE,MAAM,EAAE,MAAM,UAAU,CAAC;AAClC,OAAO,EAAE,yBAAyB,EAAE,MAAM,uBAAuB,CAAC;AAClE,OAAO,EAAE,kCAAkC,EAAE,MAAM,gCAAgC,CAAC;AACpF,OAAO,EAAE,mBAAmB,EAAE,MAAM,kBAAkB,CAAC;AAEvD,OAAO,EAAE,WAAW,EAAE,SAAS,EAAE,MAAM,iBAAiB,CAAC;AACzD,OAAO,KAAK,KAAK,MAAM,gBAAgB,CAAC;AACxC,OAAO,EAAE,UAAU,EAAE,MAAM,WAAW,CAAC;;;;;;;;;;;;;;AA8BjC,MAAO,YAAY;IA+BvB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAoCG,CACH,YACE,QAAgB,EAChB,SAAiB,EACjB,UAA2C,EAC3C,UAA+B,CAAA,CAAE,CAAA;;QAvEnC,2DAA2D;QAC3D,8DAA8D;QAE9D;;WAEG,CACa,IAAA,CAAA,cAAc,0LAAW,KAAK,CAAC,kBAAqB,CAAC;QAErE;;;WAGG,CACa,IAAA,CAAA,UAAU,0LAAW,KAAK,CAAC,kBAAqB,CAAC;QA6D/D,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;QACzB,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;QAE3B,MAAM,6BAA6B,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAC9B,OAAO,GACP;YACD,cAAc,EAAE;gBACd,MAAM,mLAAE,SAAM,CAAC,IAAI;gBACnB,4BAA4B,EAAE;oBAC5B,cAAc;oBACd,UAAU;oBACV,kBAAkB;oBAClB,eAAe;oBACf,QAAQ;oBACR,iBAAiB;iBAClB;aACF;SACF,CACF,CAAC;QAEF,IAAI,CAAC,cAAc,GACjB,CAAA,KAAA,CAAA,KAAA,OAAO,CAAC,cAAc,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,OAAO,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK,CAAC,yMAAqB,CAAC;QAC9E,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,cAAc,CAAC;QAEtC,IAAI,CAAC,MAAM,GAAG,gNAAI,eAAe,CAC/B,IAAI,CAAC,QAAQ,EACb,IAAI,CAAC,SAAS,EACd,IAAI,CAAC,cAAc,EACnB,6BAA6B,CAC9B,CAAC;QAEF,oLAAI,oBAAA,AAAiB,EAAC,UAAU,CAAC,EAAE,CAAC;YAClC,MAAM,KAAK,GAAW,OAAO,CAAC,QAAQ,GAClC,GAAG,OAAO,CAAC,QAAQ,CAAA,SAAA,CAAW,GAC9B,4LAAG,sBAAmB,CAAC,gBAAgB,CAAA,SAAA,CAAW,CAAC;YAEvD,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,SAAS,yNAC5B,kCAAA,AAA+B,EAAC;gBAAE,UAAU;gBAAE,MAAM,EAAE,KAAK;YAAA,CAAE,CAAC,CAC/D,CAAC;QACJ,CAAC,MAAM,CAAC;YACN,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,SAAS,4MAAC,qCAAA,AAAkC,EAAC,UAAU,CAAC,CAAC,CAAC;QACjF,CAAC;QAED,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,SAAS,mMAAC,4BAAA,AAAyB,EAAC,MAAM,CAAC,CAAC,CAAC;IACpE,CAAC;IAED;;;OAGG,CACI,KAAK,CAAC,iBAAiB,CAAC,UAAiC,CAAA,CAAE,EAAA;QAChE,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,yLAAG,aAAA,AAAU,EAAC,gCAAgC,EAAE,OAAO,CAAC,CAAC;QACvF,IAAI,CAAC;YACH,IAAI,cAAc,GAAW,CAAC,CAAC;YAC/B,MAAM,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,KAAK,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAC5B,cAAc,GAAA;gBACjB,UAAU,EAAE,CAAC,WAAW,EAAE,YAAY,EAAE,EAAE;oBACxC,cAAc,GAAG,MAAM,CAAC,WAAW,CAAC,UAAU,CAAC,CAAC;oBAChD,IAAI,cAAc,CAAC,UAAU,EAAE,CAAC;wBAC9B,cAAc,CAAC,UAAU,CAAC,WAAW,EAAE,YAAY,CAAC,CAAC;oBACvD,CAAC;gBACH,CAAC;YAAA,GACD,CAAC;YAEH,OAAO,cAAc,CAAC;QACxB,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAiCG,CACI,KAAK,CAAC,YAAY,CACvB,UAAkB,EAClB,aAAqB,EACrB,UAAuC,CAAA,CAAE,EAAA;QAEzC,MAAM,EAAE,YAAY,EAAA,GAAyB,OAAO,EAA3B,eAAe,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAAK,OAAO,EAA9C;YAAA;SAAoC,CAAU,CAAC;QACrD,MAAM,WAAW,GAAA,OAAA,MAAA,CAAA;YACf,UAAU,EAAE,UAAU;YACtB,aAAa,EAAE,aAAa;YAC5B,YAAY,EAAE,IAAI,CAAC,mBAAmB,CAAC,YAAY,CAAC;QAAA,GACjD,eAAe,CACnB,CAAC;QAEF,IAAI,CAAC,WAAW,CAAC,UAAU,EAAE,CAAC;YAC5B,MAAM,IAAI,UAAU,CAAC,8BAA8B,CAAC,CAAC;QACvD,CAAC;QAED,IAAI,CAAC,WAAW,CAAC,aAAa,EAAE,CAAC;YAC/B,MAAM,IAAI,UAAU,CAAC,iCAAiC,CAAC,CAAC;QAC1D,CAAC;QAED,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,yLAAG,aAAA,AAAU,EAAC,2BAA2B,EAAE,OAAO,CAAC,CAAC;QAElF,IAAI,CAAC;YACH,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,gBAAgB,CAAC,WAAW,EAAE,cAAc,CAAC,CAAC;YACzF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAEO,KAAK,CAAC,eAAe,CAC3B,UAAmB,EACnB,UAA0C,CAAA,CAAE,EAC5C,qBAA6C,CAAA,CAAE,EAAA;QAE/C,MAAM,KAQF,OAAqD,EARnD,EACJ,iBAAiB,EACjB,OAAO,EACP,YAAY,EACZ,MAAM,EACN,mBAAmB,EACnB,qBAAqB,EAAA,GAAA,EAEkC,EADpD,WAAW,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAAA,IAPV;YAAA;YAAA;YAAA;YAAA;YAAA;YAAA;SAQL,CAAwD,CAAC;QAE1D,MAAM,KACJ,qBAAqB,KAAA,QAArB,qBAAqB,KAAA,KAAA,IAArB,qBAAqB,GAAI,CAAA,CAAE,EADvB,EAAE,iBAAiB,EAAE,SAAS,EAAE,OAAO,EAAE,QAAQ,EAAA,GAAA,EAC1B,EAD+B,mBAAmB,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAAA,IAAzE;YAAA;YAAA;YAAA;YAAA;SAA2E,CACpD,CAAC;QAC9B,MAAM,KAAgD,mBAAmB,KAAA,QAAnB,mBAAmB,KAAA,KAAA,IAAnB,mBAAmB,GAAI,CAAA,CAAE,EAAzE,EAAE,OAAO,EAAE,UAAU,EAAA,GAAA,EAAoD,EAA/C,iBAAiB,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAAA,IAA3C;YAAA;YAAA;SAA6C,CAA4B,CAAC;QAEhF,MAAM,WAAW,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACZ,mBAAmB,GACnB,iBAAiB,GACjB,WAAW,GACX,kBAAkB,GAAA;YACrB,YAAY,EAAE,IAAI,CAAC,mBAAmB,CAAC,YAAY,CAAC;YACpD,MAAM,EAAE,IAAI,CAAC,aAAa,CAAU,MAAM,CAAC,IAAI,GAAG;YAClD,OAAO,EAAE,IAAI,CAAC,cAAc,CAAC,OAAO,CAAC;YACrC,uBAAuB,EAAE,iBAAiB;YAC1C,aAAa,EAAE,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,GAAG,CAAC,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAC/D,OAAO,EAAE,IAAI,CAAC,mBAAmB,CAAC,OAAO,CAAC;YAC1C,QAAQ,EAAE,IAAI,CAAC,oBAAoB,CAAC,QAAQ,CAAC;YAC7C,qBAAqB,EAAE,SAAS;YAChC,yBAAyB,EAAE,iBAAiB;YAC5C,gBAAgB,EAAE,UAAU;QAAA,EAC7B,CAAC;QAEF,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,yLAAG,aAAA,AAAU,EAAC,8BAA8B,EAAE,OAAO,CAAC,CAAC;QAErF,IAAI,CAAC;YACH,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,UAAU,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAE9C,WAAW,GAAA;gBACd,UAAU,EAAE,UAAU;YAAA,IAExB,cAAc,CACf,CAAC;YAEF,MAAM,KAOF,MAGH,EAVK,EACJ,OAAO,EACP,QAAQ,EACR,kBAAkB,EAAE,wBAAwB,EAC5C,6BAA6B,EAAE,mBAAmB,EAClD,2BAA2B,EAAE,yBAAyB,EAAA,GAAA,EAKvD,EAJI,UAAU,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAAA,IANT;gBAAA;gBAAA;gBAAA;gBAAA;gBAAA;aAOL,CAGA,CAAC;YAEF,MAAM,eAAe,8LAAG,KAAK,CAAC,sCAAA,AAAyC,EACrE,OAAO,CACR,CAAC;YAEF,MAAM,SAAS,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACV,UAAU,GAAA;gBACb,OAAO,EAAE,eAAe;gBACxB,mBAAmB;gBACnB,yBAAyB;gBACzB,iBAAiB,EAAE,IAAI,CAAC,uBAAuB,CAAC,QAAQ,EAAE,wBAAwB,CAAC;YAAA,EACpF,CAAC;YAEF,mMAAO,cAAA,AAAW,EAA6C,SAAS,CAAC,CAAC;QAC5E,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAEc,qBAAqB,CAClC,UAAmB,EACnB,UAA0C,CAAA,CAAE,EAC5C,WAA0C,CAAA,CAAE,EAAA;;YAE5C,IAAI,mBAAmB,GAAG,IAAI,CAAC,uBAAuB,CAAC,QAAQ,CAAC,iBAAiB,CAAC,CAAC;YACnF,IAAI,MAAM,GAAG,MAAA,CAAA,GAAA,wIAAA,CAAA,UAAA,EAAM,IAAI,CAAC,eAAe,CACrC,UAAU,EACV,OAAO,EACP,mBAAmB,KAAA,QAAnB,mBAAmB,KAAA,KAAA,IAAA,KAAA,IAAnB,mBAAmB,CAAE,kBAAkB,CACxC,CAAA,CAAC;YAEF,MAAA,MAAA,CAAA,GAAA,wIAAA,CAAA,UAAA,EAAM,MAAM,CAAA,CAAC;YAEb,wEAAwE;YACxE,4BAA4B;YAC5B,MAAO,MAAM,CAAC,iBAAiB,CAAE,CAAC;gBAChC,mBAAmB,GAAG,IAAI,CAAC,uBAAuB,CAAC,MAAM,CAAC,iBAAiB,CAAC,CAAC;gBAC7E,MAAM,GAAG,MAAA,CAAA,GAAA,wIAAA,CAAA,UAAA,EAAM,IAAI,CAAC,eAAe,CACjC,UAAU,EACV,OAAO,EACP,mBAAmB,KAAA,QAAnB,mBAAmB,KAAA,KAAA,IAAA,KAAA,IAAnB,mBAAmB,CAAE,kBAAkB,CACxC,CAAA,CAAC;gBACF,MAAA,MAAA,CAAA,GAAA,wIAAA,CAAA,UAAA,EAAM,MAAM,CAAA,CAAC;YACf,CAAC;QACH,CAAC;KAAA;IAEc,oBAAoB,CACjC,SAAqD,EACrD,UAAmB,EACnB,UAA0C,CAAA,CAAE,EAAA;;;YAE5C,MAAA,CAAA,GAAA,wIAAA,CAAA,UAAA,GAAA,KAAK,CAAC,8IAAC,mBAAA,GAAA,4JAAA,EAAA,SAAS,CAAC,OAAO,EAAA,CAAA,CAAA,CAAC;YACzB,IAAI,SAAS,CAAC,iBAAiB,EAAE,CAAC;;oBAChC,IAAyB,IAAA,KAAA,MAAA,kJAAA,gBAAA,EAAA,IAAI,CAAC,qBAAqB,CAAC,UAAU,EAAE,OAAO,EAAE;wBACvE,iBAAiB,EAAE,SAAS,CAAC,iBAAiB;qBAC/C,CAAC,CAAA,EAAA,EAAA,EAAA,KAAA,MAAA,CAAA,GAAA,wIAAA,CAAA,UAAA,EAAA,GAAA,IAAA,KAAA,KAAA,GAAA,IAAA,EAAA,CAAA,IAAA,KAAA,KAAE,CAAC;wBAFoB,KAAA,GAAA,KAAA,CAEvB;wBAFuB,KAAA,MAEvB;wBAFS,MAAM,IAAI,GAAA,EAAA,CAAA;wBAGnB,MAAA,CAAA,GAAA,wIAAA,CAAA,UAAA,GAAA,KAAK,CAAC,CAAC,gKAAA,+IAAA,gBAAA,EAAA,IAAI,CAAC,OAAO,EAAA,CAAA,CAAA,CAAC;oBACtB,CAAC;;;;;;;;;;;;YACH,CAAC;QACH,CAAC;KAAA;IAEO,iBAAiB,CACvB,SAAqD,EACrD,UAAmB,EACnB,UAA0C,CAAA,CAAE,EAAA;QAE5C,MAAM,IAAI,GAAG,IAAI,CAAC,oBAAoB,CAAC,SAAS,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC;QAEvE,OAAO;YACL,IAAI;gBACF,OAAO,IAAI,CAAC,IAAI,EAAE,CAAC;YACrB,CAAC;YACD,CAAC,MAAM,CAAC,aAAa,CAAC;gBACpB,OAAO,IAAI,CAAC;YACd,CAAC;YACD,MAAM,EAAE,CAAC,WAA0C,CAAA,CAAE,EAAE,EAAE;gBACvD,OAAO,IAAI,CAAC,qBAAqB,CAAC,UAAU,EAAE,OAAO,EAAE,QAAQ,CAAC,CAAC;YACnE,CAAC;SACF,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAgCG,CACI,KAAK,CAAC,MAAM,CACjB,UAAmB,EACnB,OAAwC,EAAA;QAExC,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,yLAAG,aAAA,AAAU,EAAC,qBAAqB,EAAE,OAAO,CAAC,CAAC;QAE5E,IAAI,CAAC;YACH,MAAM,UAAU,GAAG,MAAM,IAAI,CAAC,eAAe,CAAU,UAAU,EAAE,cAAc,CAAC,CAAC;YAEnF,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACK,UAAU,GAAA;gBACb,OAAO,EAAE,IAAI,CAAC,iBAAiB,CAAC,UAAU,EAAE,UAAU,EAAE,cAAc,CAAC;YAAA,GACvE;QACJ,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAiCG,CACI,KAAK,CAAC,OAAO,CAClB,UAAkB,EAClB,aAAqB,EACrB,UAA2C,CAAA,CAAE,EAAA;QAE7C,MAAM,EAAE,MAAM,EAAE,YAAY,EAAE,OAAO,EAAA,GAAyB,OAAO,EAA3B,eAAe,GAAA,CAAA,GAAA,wIAAA,CAAA,SAAA,EAAK,OAAO,EAA/D;YAAA;YAAA;YAAA;SAAqD,CAAU,CAAC;QACtE,MAAM,WAAW,GAAA,OAAA,MAAA,CAAA;YACf,UAAU,EAAE,UAAU;YACtB,aAAa,EAAE,aAAa;YAC5B,YAAY,EAAE,IAAI,CAAC,mBAAmB,CAAC,YAAY,CAAC;YACpD,MAAM,EAAE,IAAI,CAAC,aAAa,CAAU,MAAM,CAAC;YAC3C,OAAO,EAAE,IAAI,CAAC,cAAc,CAAC,OAAO,CAAC;QAAA,GAClC,eAAe,CACnB,CAAC;QAEF,IAAI,CAAC,WAAW,CAAC,UAAU,EAAE,CAAC;YAC5B,MAAM,IAAI,UAAU,CAAC,8BAA8B,CAAC,CAAC;QACvD,CAAC;QAED,IAAI,CAAC,WAAW,CAAC,aAAa,EAAE,CAAC;YAC/B,MAAM,IAAI,UAAU,CAAC,iCAAiC,CAAC,CAAC;QAC1D,CAAC;QAED,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,yLAAG,aAAU,AAAV,EAAW,sBAAsB,EAAE,OAAO,CAAC,CAAC;QAE7E,IAAI,CAAC;YACH,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,WAAW,CAAC,WAAW,EAAE,cAAc,CAAC,CAAC;YAEpF,MAAM,cAAc,IAAG,KAAK,CAAC,oPAAA,AAA6D,EAGxF,MAAM,CAAC,CAAC;YAEV,mMAAO,cAAA,AAAW,EAA0C,cAAc,CAAC,CAAC;QAC9E,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAED;;;;OAIG,CACI,KAAK,CAAC,WAAW,CACtB,GAAW,EACX,UAA+C,CAAA,CAAE,EAAA;QAEjD,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,GAAG,mMAAA,AAAU,EAAC,0BAA0B,EAAE,OAAO,CAAC,CAAC;QACjF,IAAI,CAAC;YACH,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAC7C,cAAc,GAAA;gBACjB,cAAc,EAAE,cAAc,CAAC,cAAsC;YAAA,GACrE,CAAC;YACH,OAAO,0MAAA,AAAW,EAAiC,MAAM,CAAC,CAAC;QAC7D,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAED;;;;;;;;;OASG,CACI,KAAK,CAAC,cAAc,CACzB,wEAAwE;IACxE,KAAkC,EAClC,UAAiC,CAAA,CAAE,EAAA;QAEnC,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,yLAAG,aAAA,AAAU,EAAC,6BAA6B,EAAE,OAAO,CAAC,CAAC;QACpF,IAAI,CAAC;YACH,IAAI,MAAM,GAAW,CAAC,CAAC;YACvB,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,KAAK,CAC9C;gBAAE,OAAO,GAAE,uMAAA,AAAS,EAAC,KAAK,CAAC,OAAO,CAAC;YAAA,CAAE,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAEhC,cAAc,GAAA;gBACjB,UAAU,EAAE,CAAC,WAAW,EAAE,YAAY,EAAE,EAAE;oBACxC,MAAM,GAAG,WAAW,CAAC,MAAM,CAAC;oBAC5B,IAAI,cAAc,CAAC,UAAU,EAAE,CAAC;wBAC9B,cAAc,CAAC,UAAU,CAAC,WAAW,EAAE,YAAY,CAAC,CAAC;oBACvD,CAAC;gBACH,CAAC;YAAA,GAEJ,CAAC;YACF,IAAI,OAAO,CAAC,iBAAiB,IAAI,MAAM,KAAK,GAAG,EAAE,CAAC;gBAChD,MAAM,MAAM,CAAC;YACf,CAAC;YACD,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAED;;;;OAIG,CACI,KAAK,CAAC,eAAe,CAC1B,SAAmB,EACnB,UAAkC,CAAA,CAAE,EAAA;QAEpC,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,yLAAG,aAAA,AAAU,EAAC,8BAA8B,EAAE,OAAO,CAAC,CAAC;QAErF,MAAM,KAAK,GAAG,kMAAI,sBAAmB,EAAU,CAAC;QAChD,KAAK,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;QAExB,IAAI,CAAC;YACH,OAAO,MAAM,IAAI,CAAC,cAAc,CAAC,KAAK,EAAE,cAAc,CAAC,CAAC;QAC1D,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAED;;;;;OAKG,CACI,KAAK,CAAC,cAAc,CACzB,SAAmB,EACnB,UAAiC,CAAA,CAAE,EAAA;QAEnC,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,yLAAG,aAAA,AAAU,EAAC,6BAA6B,EAAE,OAAO,CAAC,CAAC;QAEpF,MAAM,KAAK,GAAG,IAAI,oNAAmB,EAAU,CAAC;QAChD,KAAK,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC;QAEvB,IAAI,CAAC;YACH,OAAO,MAAM,IAAI,CAAC,cAAc,CAAC,KAAK,EAAE,cAAc,CAAC,CAAC;QAC1D,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAED;;;;;OAKG,CACI,KAAK,CAAC,sBAAsB,CACjC,SAAmB,EACnB,UAAyC,CAAA,CAAE,EAAA;QAE3C,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,yLAAG,aAAA,AAAU,EAAC,6BAA6B,EAAE,OAAO,CAAC,CAAC;QAEpF,MAAM,KAAK,GAAG,kMAAI,sBAAmB,EAAU,CAAC;QAChD,KAAK,CAAC,aAAa,CAAC,SAAS,CAAC,CAAC;QAE/B,IAAI,CAAC;YACH,OAAO,MAAM,IAAI,CAAC,cAAc,CAAC,KAAK,EAAE,cAAc,CAAC,CAAC;QAC1D,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAwBM,KAAK,CAAC,eAAe,CAC1B,kBAA2C,EAC3C,kBAAsD,EACtD,UAAkC,CAAA,CAAE,EAAA;QAEpC,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,wLAAG,cAAA,AAAU,EAAC,8BAA8B,EAAE,OAAO,CAAC,CAAC;QAErF,MAAM,KAAK,GAAG,kMAAI,sBAAmB,EAAU,CAAC;QAChD,IAAI,OAAO,kBAAkB,KAAK,QAAQ,EAAE,CAAC;YAC3C,KAAK,CAAC,MAAM,CAAC,kBAAkB,EAAE,kBAA8B,CAAC,CAAC;QACnE,CAAC,MAAM,CAAC;YACN,KAAK,CAAC,MAAM,CAAC,kBAA8B,CAAC,CAAC;QAC/C,CAAC;QAED,IAAI,CAAC;YACH,OAAO,MAAM,IAAI,CAAC,cAAc,CAAC,KAAK,EAAE,cAAc,CAAC,CAAC;QAC1D,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,IAAI,CAAC,SAAS,CAAC;gBACb,MAAM,EAAE,OAAO;gBACf,KAAK,EAAE,CAAC,CAAC,OAAO;aACjB,CAAC,CAAC;YACH,MAAM,CAAC,CAAC;QACV,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,GAAG,EAAE,CAAC;QACb,CAAC;IACH,CAAC;IAEO,uBAAuB,CAC7B,QAA4B,EAC5B,kBAAsD,EAAA;QAEtD,IAAI,CAAC,QAAQ,IAAI,CAAC,kBAAkB,EAAE,CAAC;YACrC,OAAO,SAAS,CAAC;QACnB,CAAC;QACD,MAAM,OAAO,GAAG,IAAI,CAAC,SAAS,CAAC;YAC7B,UAAU,EAAE,IAAI,CAAC,UAAU;YAC3B,QAAQ;YACR,kBAAkB;SACnB,CAAC,CAAC;QACH,4LAAO,SAAA,AAAM,EAAC,OAAO,CAAC,CAAC;IACzB,CAAC;IAEO,uBAAuB,CAC7B,KAAc,EAAA;QAEd,IAAI,CAAC,KAAK,EAAE,CAAC;YACX,OAAO,SAAS,CAAC;QACnB,CAAC;QAED,MAAM,YAAY,wLAAG,SAAA,AAAM,EAAC,KAAK,CAAC,CAAC;QAEnC,IAAI,CAAC;YACH,MAAM,MAAM,GAIR,IAAI,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC;YAE7B,IAAI,MAAM,CAAC,UAAU,KAAK,IAAI,CAAC,UAAU,EAAE,CAAC;gBAC1C,MAAM,IAAI,UAAU,CAAC,CAAA,gDAAA,EAAmD,IAAI,CAAC,UAAU,CAAA,CAAA,CAAG,CAAC,CAAC;YAC9F,CAAC;YAED,OAAO;gBACL,QAAQ,EAAE,MAAM,CAAC,QAAQ;gBACzB,kBAAkB,EAAE,MAAM,CAAC,kBAAkB;aAC9C,CAAC;QACJ,CAAC,CAAC,OAAO,CAAM,EAAE,CAAC;YAChB,MAAM,IAAI,KAAK,CAAC,CAAA,yCAAA,EAA4C,YAAY,EAAE,CAAC,CAAC;QAC9E,CAAC;IACH,CAAC;IAEO,aAAa,CACnB,MAA6B,EAAA;QAE7B,IAAI,MAAM,EAAE,CAAC;YACX,OAAO,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAC1B,CAAC;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAEO,wBAAwB,CAAC,MAAiC,EAAA;QAChE,IAAI,MAAM,EAAE,CAAC;YACX,OAAO,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAC1B,CAAC;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAEO,mBAAmB,CAAC,YAAuC,EAAA;QACjE,IAAI,YAAY,EAAE,CAAC;YACjB,OAAO,YAAY,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAChC,CAAC;QACD,OAAO,YAAY,CAAC;IACtB,CAAC;IAEO,cAAc,CAAC,OAAkB,EAAA;QACvC,IAAI,OAAO,EAAE,CAAC;YACZ,OAAO,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAC3B,CAAC;QACD,OAAO,OAAO,CAAC;IACjB,CAAC;IAEO,mBAAmB,CAAC,OAAqB,EAAA;QAC/C,IAAI,CAAC,OAAO,EAAE,CAAC;YACb,OAAO,OAAO,CAAC;QACjB,CAAC;QAED,MAAM,MAAM,GAAG,EAAE,CAAC;QAClB,MAAM,EAAE,UAAU,EAAE,MAAM,EAAE,KAAK,EAAE,SAAS,EAAE,GAAG,OAAO,CAAC;QAEzD,IAAI,KAAK,EAAE,CAAC;YACV,MAAM,CAAC,IAAI,CAAC,CAAA,MAAA,EAAS,KAAK,EAAE,CAAC,CAAC;QAChC,CAAC;QAED,IAAI,SAAS,EAAE,CAAC;YACd,MAAM,CAAC,IAAI,CAAC,CAAA,UAAA,EAAa,SAAS,EAAE,CAAC,CAAC;QACxC,CAAC;QAED,IAAI,MAAM,CAAC,MAAM,EAAE,CAAC;YAClB,OAAO,MAAM,GAAG,CAAA,CAAA,EAAI,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC;QACzC,CAAC;QAED,OAAO,MAAM,CAAC;IAChB,CAAC;IAEO,oBAAoB,CAAC,QAAuB,EAAA;QAClD,IAAI,CAAC,QAAQ,EAAE,CAAC;YACd,OAAO,QAAQ,CAAC;QAClB,CAAC;QAED,MAAM,MAAM,GAAG,EAAE,CAAC;QAClB,MAAM,EAAE,WAAW,EAAE,MAAM,EAAE,SAAS,EAAE,GAAG,QAAQ,CAAC;QAEpD,IAAI,SAAS,KAAK,SAAS,EAAE,CAAC;YAC5B,MAAM,CAAC,IAAI,CAAC,CAAA,UAAA,EAAa,SAAS,EAAE,CAAC,CAAC;QACxC,CAAC;QAED,IAAI,MAAM,CAAC,MAAM,EAAE,CAAC;YAClB,OAAO,MAAM,GAAG,CAAA,CAAA,EAAI,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC;QACzC,CAAC;QAED,OAAO,MAAM,CAAC;IAChB,CAAC;IAEO,kBAAkB,CAAgC,WAAc,EAAA;QACtE,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAY,WAAW,GAAA;YAAE,MAAM,EAAE,IAAI,CAAC,wBAAwB,CAAC,WAAW,KAAA,QAAX,WAAW,KAAA,KAAA,IAAA,KAAA,IAAX,WAAW,CAAE,MAAM,CAAC;QAAA,GAAG;IACxF,CAAC;CACF","ignoreList":[0],"debugId":null}}]
}